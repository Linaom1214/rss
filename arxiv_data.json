[
  {
    "title": "Robust infrared small target detection using self-supervised and a contrario paradigms",
    "author": "Alina Ciocarlan, Sylvie Le H\u00e9garat-Mascle, Sidonie Lefebvre, Arnaud Woiselle",
    "summary": "Detecting small targets in infrared images poses significant challenges in defense applications due to the presence of complex backgrounds and the small size of the targets. Traditional object detection methods often struggle to balance high detection rates with low false alarm rates, especially when dealing with small objects. In this paper, we introduce a novel approach that combines a contrario paradigm with Self-Supervised Learning (SSL) to improve Infrared Small Target Detection (IRSTD). On the one hand, the integration of an a contrario criterion into a YOLO detection head enhances feature map responses for small and unexpected objects while effectively controlling false alarms. On the other hand, we explore SSL techniques to overcome the challenges of limited annotated data, common in IRSTD tasks. Specifically, we benchmark several representative SSL strategies for their effectiveness in improving small object detection performance. Our findings show that instance discrimination methods outperform masked image modeling strategies when applied to YOLO-based small object detection. Moreover, the combination of the a contrario and SSL paradigms leads to significant performance improvements, narrowing the gap with state-of-the-art segmentation methods and even outperforming them in frugal settings. This two-pronged approach offers a robust solution for improving IRSTD performance, particularly under challenging conditions.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.07437v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Gradient is All You Need: Gradient-Based Attention Fusion for Infrared Small Target Detection",
    "author": "Chen Hu, Yian Huang, Kexuan Li, Luping Zhang, Yiming Zhu, Yufei Peng, Tian Pu, Zhenming Peng",
    "summary": "Infrared small target detection (IRSTD) is widely used in civilian and military applications. However, IRSTD encounters several challenges, including the tendency for small and dim targets to be obscured by complex backgrounds. To address this issue, we propose the Gradient Network (GaNet), which aims to extract and preserve edge and gradient information of small targets. GaNet employs the Gradient Transformer (GradFormer) module, simulating central difference convolutions (CDC) to extract and integrate gradient features with deeper features. Furthermore, we propose a global feature extraction model (GFEM) that offers a comprehensive perspective to prevent the network from focusing solely on details while neglecting the background information. We compare the network with state-of-the-art (SOTA) approaches, and the results demonstrate that our method performs effectively. Our source code is available at https://github.com/greekinRoma/Gradient-Transformer.",
    "published": "2024-09-29",
    "link": "http://arxiv.org/abs/2409.19599v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Infrared Small Target Detection in Satellite Videos: A New Dataset and A Novel Recurrent Feature Refinement Framework",
    "author": "Xinyi Ying, Li Liu, Zaipin Lin, Yangsi Shi, Yingqian Wang, Ruojing Li, Xu Cao, Boyang Li, Shilin Zhou",
    "summary": "Multi-frame infrared small target (MIRST) detection in satellite videos is a long-standing, fundamental yet challenging task for decades, and the challenges can be summarized as: First, extremely small target size, highly complex clutters & noises, various satellite motions result in limited feature representation, high false alarms, and difficult motion analyses. Second, the lack of large-scale public available MIRST dataset in satellite videos greatly hinders the algorithm development. To address the aforementioned challenges, in this paper, we first build a large-scale dataset for MIRST detection in satellite videos (namely IRSatVideo-LEO), and then develop a recurrent feature refinement (RFR) framework as the baseline method. Specifically, IRSatVideo-LEO is a semi-simulated dataset with synthesized satellite motion, target appearance, trajectory and intensity, which can provide a standard toolbox for satellite video generation and a reliable evaluation platform to facilitate the algorithm development. For baseline method, RFR is proposed to be equipped with existing powerful CNN-based methods for long-term temporal dependency exploitation and integrated motion compensation & MIRST detection. Specifically, a pyramid deformable alignment (PDA) module and a temporal-spatial-frequency modulation (TSFM) module are proposed to achieve effective and efficient feature alignment, propagation, aggregation and refinement. Extensive experiments have been conducted to demonstrate the effectiveness and superiority of our scheme. The comparative results show that ResUNet equipped with RFR outperforms the state-of-the-art MIRST detection methods. Dataset and code are released at https://github.com/XinyiYing/RFR.",
    "published": "2024-09-19",
    "link": "http://arxiv.org/abs/2409.12448v2",
    "code_url": "https://github.com/xinyiying/rfr",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Unleashing the Power of Generic Segmentation Models: A Simple Baseline for Infrared Small Target Detection",
    "author": "Mingjin Zhang, Chi Zhang, Qiming Zhang, Yunsong Li, Xinbo Gao, Jing Zhang",
    "summary": "Recent advancements in deep learning have greatly advanced the field of infrared small object detection (IRSTD). Despite their remarkable success, a notable gap persists between these IRSTD methods and generic segmentation approaches in natural image domains. This gap primarily arises from the significant modality differences and the limited availability of infrared data. In this study, we aim to bridge this divergence by investigating the adaptation of generic segmentation models, such as the Segment Anything Model (SAM), to IRSTD tasks. Our investigation reveals that many generic segmentation models can achieve comparable performance to state-of-the-art IRSTD methods. However, their full potential in IRSTD remains untapped. To address this, we propose a simple, lightweight, yet effective baseline model for segmenting small infrared objects. Through appropriate distillation strategies, we empower smaller student models to outperform state-of-the-art methods, even surpassing fine-tuned teacher results. Furthermore, we enhance the model's performance by introducing a novel query design comprising dense and sparse queries to effectively encode multi-scale features. Through extensive experimentation across four popular IRSTD datasets, our model demonstrates significantly improved performance in both accuracy and throughput compared to existing approaches, surpassing SAM and Semantic-SAM by over 14 IoU on NUDT and 4 IoU on IRSTD1k. The source code and models will be released at https://github.com/O937-blip/SimIR.",
    "published": "2024-09-07",
    "link": "http://arxiv.org/abs/2409.04714v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Hybrid Mask Generation for Infrared Small Target Detection with Single-Point Supervision",
    "author": "Weijie He, Mushui Liu, Yunlong Yu, Zheming Lu, Xi Li",
    "summary": "Single-frame infrared small target (SIRST) detection poses a significant challenge due to the requirement to discern minute targets amidst complex infrared background clutter. Recently, deep learning approaches have shown promising results in this domain. However, these methods heavily rely on extensive manual annotations, which are particularly cumbersome and resource-intensive for infrared small targets owing to their minute sizes. To address this limitation, we introduce a Hybrid Mask Generation (HMG) approach that recovers high-quality masks for each target from only a single-point label for network training. Specifically, our HMG approach consists of a handcrafted Points-to-Mask Generation strategy coupled with a pseudo mask updating strategy to recover and refine pseudo masks from point labels. The Points-to-Mask Generation strategy divides two distinct stages: Points-to-Box conversion, where individual point labels are transformed into bounding boxes, and subsequently, Box-to-Mask prediction, where these bounding boxes are elaborated into precise masks. The mask updating strategy integrates the complementary strengths of handcrafted and deep-learning algorithms to iteratively refine the initial pseudo masks. Experimental results across three datasets demonstrate that our method outperforms the existing methods for infrared small target detection with single-point supervision.",
    "published": "2024-09-06",
    "link": "http://arxiv.org/abs/2409.04011v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "WorldMedQA-V: a multilingual, multimodal medical examination dataset for multimodal language models evaluation",
    "author": "Jo\u00e3o Matos, Shan Chen, Siena Placino, Yingya Li, Juan Carlos Climent Pardo, Daphna Idan, Takeshi Tohyama, David Restrepo, Luis F. Nakayama, Jose M. M. Pascual-Leone, Guergana Savova, Hugo Aerts, Leo A. Celi, A. Ian Wong, Danielle S. Bitterman, Jack Gallifant",
    "summary": "Multimodal/vision language models (VLMs) are increasingly being deployed in healthcare settings worldwide, necessitating robust benchmarks to ensure their safety, efficacy, and fairness. Multiple-choice question and answer (QA) datasets derived from national medical examinations have long served as valuable evaluation tools, but existing datasets are largely text-only and available in a limited subset of languages and countries. To address these challenges, we present WorldMedQA-V, an updated multilingual, multimodal benchmarking dataset designed to evaluate VLMs in healthcare. WorldMedQA-V includes 568 labeled multiple-choice QAs paired with 568 medical images from four countries (Brazil, Israel, Japan, and Spain), covering original languages and validated English translations by native clinicians, respectively. Baseline performance for common open- and closed-source models are provided in the local language and English translations, and with and without images provided to the model. The WorldMedQA-V benchmark aims to better match AI systems to the diverse healthcare environments in which they are deployed, fostering more equitable, effective, and representative applications.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12722v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "VividMed: Vision Language Model with Versatile Visual Grounding for Medicine",
    "author": "Lingxiao Luo, Bingda Tang, Xuanzhong Chen, Rong Han, Ting Chen",
    "summary": "Recent advancements in Vision Language Models (VLMs) have demonstrated remarkable promise in generating visually grounded responses. However, their application in the medical domain is hindered by unique challenges. For instance, most VLMs rely on a single method of visual grounding, whereas complex medical tasks demand more versatile approaches. Additionally, while most VLMs process only 2D images, a large portion of medical images are 3D. The lack of medical data further compounds these obstacles. To address these challenges, we present VividMed, a vision language model with versatile visual grounding for medicine. Our model supports generating both semantic segmentation masks and instance-level bounding boxes, and accommodates various imaging modalities, including both 2D and 3D data. We design a three-stage training procedure and an automatic data synthesis pipeline based on open datasets and models. Besides visual grounding tasks, VividMed also excels in other common downstream tasks, including Visual Question Answering (VQA) and report generation. Ablation studies empirically show that the integration of visual grounding ability leads to improved performance on these tasks. Our code is publicly available at https://github.com/function2-llx/MMMM.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12694v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Machine Learning Approach to Brain Tumor Detection and Classification",
    "author": "Alice Oh, Inyoung Noh, Jian Choo, Jihoo Lee, Justin Park, Kate Hwang, Sanghyeon Kim, Soo Min Oh",
    "summary": "Brain tumor detection and classification are critical tasks in medical image analysis, particularly in early-stage diagnosis, where accurate and timely detection can significantly improve treatment outcomes. In this study, we apply various statistical and machine learning models to detect and classify brain tumors using brain MRI images. We explore a variety of statistical models including linear, logistic, and Bayesian regressions, and the machine learning models including decision tree, random forest, single-layer perceptron, multi-layer perceptron, convolutional neural network (CNN), recurrent neural network, and long short-term memory. Our findings show that CNN outperforms other models, achieving the best performance. Additionally, we confirm that the CNN model can also work for multi-class classification, distinguishing between four categories of brain MRI images such as normal, glioma, meningioma, and pituitary tumor images. This study demonstrates that machine learning approaches are suitable for brain tumor detection and classification, facilitating real-world medical applications in assisting radiologists with early and accurate diagnosis.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12692v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2",
    "author": "Mohamad Abdi, Gerardo Hemosillo Valadez, Halid Ziya Yerebakan",
    "summary": "Anatomical landmarks are vital in medical imaging for navigation and anomaly detection. Modern large language models (LLMs), like Llama-2, offer promise for automating the mapping of these landmarks in free-text radiology reports to corresponding positions in image data. Recent studies propose LLMs may develop coherent representations of generative processes. Motivated by these insights, we investigated whether LLMs accurately represent the spatial positions of anatomical landmarks. Through experiments with Llama-2 models, we found that they can linearly represent anatomical landmarks in space with considerable robustness to different prompts. These results underscore the potential of LLMs to enhance the efficiency and accuracy of medical imaging workflows.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12686v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Cascade learning in multi-task encoder-decoder networks for concurrent bone segmentation and glenohumeral joint assessment in shoulder CT scans",
    "author": "Luca Marsilio, Davide Marzorati, Matteo Rossi, Andrea Moglia, Luca Mainardi, Alfonso Manzotti, Pietro Cerveri",
    "summary": "Osteoarthritis is a degenerative condition affecting bones and cartilage, often leading to osteophyte formation, bone density loss, and joint space narrowing. Treatment options to restore normal joint function vary depending on the severity of the condition. This work introduces an innovative deep-learning framework processing shoulder CT scans. It features the semantic segmentation of the proximal humerus and scapula, the 3D reconstruction of bone surfaces, the identification of the glenohumeral (GH) joint region, and the staging of three common osteoarthritic-related pathologies: osteophyte formation (OS), GH space reduction (JS), and humeroscapular alignment (HSA). The pipeline comprises two cascaded CNN architectures: 3D CEL-UNet for segmentation and 3D Arthro-Net for threefold classification. A retrospective dataset of 571 CT scans featuring patients with various degrees of GH osteoarthritic-related pathologies was used to train, validate, and test the pipeline. Root mean squared error and Hausdorff distance median values for 3D reconstruction were 0.22mm and 1.48mm for the humerus and 0.24mm and 1.48mm for the scapula, outperforming state-of-the-art architectures and making it potentially suitable for a PSI-based shoulder arthroplasty preoperative plan context. The classification accuracy for OS, JS, and HSA consistently reached around 90% across all three categories. The computational time for the inference pipeline was less than 15s, showcasing the framework's efficiency and compatibility with orthopedic radiology practice. The outcomes represent a promising advancement toward the medical translation of artificial intelligence tools. This progress aims to streamline the preoperative planning pipeline delivering high-quality bone surfaces and supporting surgeons in selecting the most suitable surgical approach according to the unique patient joint conditions.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12641v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MambaBEV: An efficient 3D detection model with Mamba2",
    "author": "Zihan You, Hao Wang, Qichao Zhao, Jinxiang Wang",
    "summary": "A stable 3D object detection model based on BEV paradigm with temporal information is very important for autonomous driving systems. However, current temporal fusion model use convolutional layer or deformable self-attention is not conducive to the exchange of global information of BEV space and has more computational cost. Recently, a newly proposed based model specialized in processing sequence called mamba has shown great potential in multiple downstream task. In this work, we proposed a mamba2-based BEV 3D object detection model named MambaBEV. We also adapt an end to end self driving paradigm to test the performance of the model. Our work performs pretty good results on nucences datasets:Our base version achieves 51.7% NDS. Our code will be available soon.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12673v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Adaptive Prompt Learning with SAM for Few-shot Scanning Probe Microscope Image Segmentation",
    "author": "Yao Shen, Ziwei Wei, Chunmeng Liu, Shuming Wei, Qi Zhao, Kaiyang Zeng, Guangyao Li",
    "summary": "The Segment Anything Model (SAM) has demonstrated strong performance in image segmentation of natural scene images. However, its effectiveness diminishes markedly when applied to specific scientific domains, such as Scanning Probe Microscope (SPM) images. This decline in accuracy can be attributed to the distinct data distribution and limited availability of the data inherent in the scientific images. On the other hand, the acquisition of adequate SPM datasets is both time-intensive and laborious as well as skill-dependent. To address these challenges, we propose an Adaptive Prompt Learning with SAM (APL-SAM) framework tailored for few-shot SPM image segmentation. Our approach incorporates two key innovations to enhance SAM: 1) An Adaptive Prompt Learning module leverages few-shot embeddings derived from limited support set to learn adaptively central representatives, serving as visual prompts. This innovation eliminates the need for time-consuming online user interactions for providing prompts, such as exhaustively marking points and bounding boxes slice by slice; 2) A multi-source, multi-level mask decoder specifically designed for few-shot SPM image segmentation is introduced, which can effectively capture the correspondence between the support and query images. To facilitate comprehensive training and evaluation, we introduce a new dataset, SPM-Seg, curated for SPM image segmentation. Extensive experiments on this dataset reveal that the proposed APL-SAM framework significantly outperforms the original SAM, achieving over a 30% improvement in terms of Dice Similarity Coefficient with only one-shot guidance. Moreover, APL-SAM surpasses state-of-the-art few-shot segmentation methods and even fully supervised approaches in performance. Code and dataset used in this study will be made available upon acceptance.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12562v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "UmambaTSF: A U-shaped Multi-Scale Long-Term Time Series Forecasting Method Using Mamba",
    "author": "Li Wu, Wenbin Pei, Jiulong Jiao, Qiang Zhang",
    "summary": "Multivariate Time series forecasting is crucial in domains such as transportation, meteorology, and finance, especially for predicting extreme weather events. State-of-the-art methods predominantly rely on Transformer architectures, which utilize attention mechanisms to capture temporal dependencies. However, these methods are hindered by quadratic time complexity, limiting the model's scalability with respect to input sequence length. This significantly restricts their practicality in the real world. Mamba, based on state space models (SSM), provides a solution with linear time complexity, increasing the potential for efficient forecasting of sequential data. In this study, we propose UmambaTSF, a novel long-term time series forecasting framework that integrates multi-scale feature extraction capabilities of U-shaped encoder-decoder multilayer perceptrons (MLP) with Mamba's long sequence representation. To improve performance and efficiency, the Mamba blocks introduced in the framework adopt a refined residual structure and adaptable design, enabling the capture of unique temporal signals and flexible channel processing. In the experiments, UmambaTSF achieves state-of-the-art performance and excellent generality on widely used benchmark datasets while maintaining linear time complexity and low memory consumption.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.11278v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Mimetic Initialization Helps State Space Models Learn to Recall",
    "author": "Asher Trockman, Hrayr Harutyunyan, J. Zico Kolter, Sanjiv Kumar, Srinadh Bhojanapalli",
    "summary": "Recent work has shown that state space models such as Mamba are significantly worse than Transformers on recall-based tasks due to the fact that their state size is constant with respect to their input sequence length. But in practice, state space models have fairly large state sizes, and we conjecture that they should be able to perform much better at these tasks than previously reported. We investigate whether their poor copying and recall performance could be due in part to training difficulties rather than fundamental capacity constraints. Based on observations of their \"attention\" maps, we propose a structured initialization technique that allows state space layers to more readily mimic attention. Across a variety of architecture settings, our initialization makes it substantially easier for Mamba to learn to copy and do associative recall from scratch.",
    "published": "2024-10-14",
    "link": "http://arxiv.org/abs/2410.11135v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "CleanUMamba: A Compact Mamba Network for Speech Denoising using Channel Pruning",
    "author": "Sjoerd Groot, Qinyu Chen, Jan C. van Gemert, Chang Gao",
    "summary": "This paper presents CleanUMamba, a time-domain neural network architecture designed for real-time causal audio denoising directly applied to raw waveforms. CleanUMamba leverages a U-Net encoder-decoder structure, incorporating the Mamba state-space model in the bottleneck layer. By replacing conventional self-attention and LSTM mechanisms with Mamba, our architecture offers superior denoising performance while maintaining a constant memory footprint, enabling streaming operation. To enhance efficiency, we applied structured channel pruning, achieving an 8X reduction in model size without compromising audio quality. Our model demonstrates strong results in the Interspeech 2020 Deep Noise Suppression challenge. Specifically, CleanUMamba achieves a PESQ score of 2.42 and STOI of 95.1% with only 442K parameters and 468M MACs, matching or outperforming larger models in real-time performance. Code will be available at: https://github.com/lab-emi/CleanUMamba",
    "published": "2024-10-14",
    "link": "http://arxiv.org/abs/2410.11062v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "The First Competition on Resource-Limited Infrared Small Target Detection Challenge: Methods and Results",
    "author": "Boyang Li, Xinyi Ying, Ruojing Li, Yongxian Liu, Yangsi Shi, Miao Li",
    "summary": "In this paper, we briefly summarize the first competition on resource-limited infrared small target detection (namely, LimitIRSTD). This competition has two tracks, including weakly-supervised infrared small target detection (Track 1) and lightweight infrared small target detection (Track 2). 46 and 60 teams successfully registered and took part in Tracks 1 and Track 2, respectively. The top-performing methods and their results in each track are described with details. This competition inspires the community to explore the tough problems in the application of infrared small target detection, and ultimately promote the deployment of this technology under limited resource.",
    "published": "2024-08-18",
    "link": "http://arxiv.org/abs/2408.09615v1",
    "code_url": "https://github.com/xinyiying/basicirstd",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Beyond Full Label: Single-Point Prompt for Infrared Small Target Label Generation",
    "author": "Shuai Yuan, Hanlin Qin, Renke Kou, Xiang Yan, Zechuan Li, Chenxu Peng, Abd-Krim Seghouane",
    "summary": "In this work, we make the first attempt to construct a learning-based single-point annotation paradigm for infrared small target label generation (IRSTLG). Our intuition is that label generation requires just one more point prompt than target detection: IRSTLG can be regarded as an infrared small target detection (IRSTD) task with the target location hint. Based on this insight, we introduce an energy double guided single-point prompt (EDGSP) framework, which adeptly transforms the target detection network into a refined label generation method. Specifically, the proposed EDGSP includes: 1) target energy initialization (TEI) to create a foundational outline for sufficient shape evolution of pseudo label, 2) double prompt embedding (DPE) for rapid localization of interested regions and reinforcement of individual differences to avoid label adhesion, and 3) bounding box-based matching (BBM) to eliminate false alarms. Experimental results show that pseudo labels generated by three baselines equipped with EDGSP achieve 100% object-level probability of detection (Pd) and 0% false-alarm rate (Fa) on SIRST, NUDT-SIRST, and IRSTD-1k datasets, with a pixel-level intersection over union (IoU) improvement of 13.28% over state-of-the-art (SOTA) label generation methods. In the practical application of downstream IRSTD, EDGSP realizes, for the first time, a single-point generated pseudo mask beyond the full label. Even with coarse single-point annotations, it still achieves 99.5% performance of full labeling.",
    "published": "2024-08-15",
    "link": "http://arxiv.org/abs/2408.08191v4",
    "code_url": "https://github.com/xdfai/edgsp",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "One Shot is Enough for Sequential Infrared Small Target Segmentation",
    "author": "Bingbing Dan, Meihui Li, Tao Tang, Jing Zhang",
    "summary": "Infrared small target sequences exhibit strong similarities between frames and contain rich contextual information, which motivates us to achieve sequential infrared small target segmentation (IRSTS) with minimal data. Inspired by the success of Segment Anything Model (SAM) across various downstream tasks, we propose a one-shot and training-free method that perfectly adapts SAM's zero-shot generalization capability to sequential IRSTS. Specifically, we first obtain a confidence map through local feature matching (LFM). The highest point in the confidence map is used as the prompt to replace the manual prompt. Then, to address the over-segmentation issue caused by the domain gap, we design the point prompt-centric focusing (PPCF) module. Subsequently, to prevent miss and false detections, we introduce the triple-level ensemble (TLE) module to produce the final mask. Experiments demonstrate that our method requires only one shot to achieve comparable performance to state-of-the-art IRSTS methods and significantly outperforms other one-shot segmentation methods. Moreover, ablation studies confirm the robustness of our method in the type of annotations and the selection of reference images.",
    "published": "2024-08-09",
    "link": "http://arxiv.org/abs/2408.04823v2",
    "code_url": "https://github.com/d-iceice/one-shot-irsts",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Pick of the Bunch: Detecting Infrared Small Targets Beyond Hit-Miss Trade-Offs via Selective Rank-Aware Attention",
    "author": "Yimian Dai, Peiwen Pan, Yulei Qian, Yuxuan Li, Xiang Li, Jian Yang, Huan Wang",
    "summary": "Infrared small target detection faces the inherent challenge of precisely localizing dim targets amidst complex background clutter. Traditional approaches struggle to balance detection precision and false alarm rates. To break this dilemma, we propose SeRankDet, a deep network that achieves high accuracy beyond the conventional hit-miss trade-off, by following the ``Pick of the Bunch'' principle. At its core lies our Selective Rank-Aware Attention (SeRank) module, employing a non-linear Top-K selection process that preserves the most salient responses, preventing target signal dilution while maintaining constant complexity. Furthermore, we replace the static concatenation typical in U-Net structures with our Large Selective Feature Fusion (LSFF) module, a dynamic fusion strategy that empowers SeRankDet with adaptive feature integration, enhancing its ability to discriminate true targets from false alarms. The network's discernment is further refined by our Dilated Difference Convolution (DDC) module, which merges differential convolution aimed at amplifying subtle target characteristics with dilated convolution to expand the receptive field, thereby substantially improving target-background separation. Despite its lightweight architecture, the proposed SeRankDet sets new benchmarks in state-of-the-art performance across multiple public datasets. The code is available at https://github.com/GrokCV/SeRankDet.",
    "published": "2024-08-07",
    "link": "http://arxiv.org/abs/2408.03717v2",
    "code_url": "https://github.com/grokcv/serankdet",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "LR-Net: A Lightweight and Robust Network for Infrared Small Target Detection",
    "author": "Chuang Yu, Yunpeng Liu, Jinmiao Zhao, Zelin Shi",
    "summary": "Limited by equipment limitations and the lack of target intrinsic features, existing infrared small target detection methods have difficulty meeting actual comprehensive performance requirements. Therefore, we propose an innovative lightweight and robust network (LR-Net), which abandons the complex structure and achieves an effective balance between detection accuracy and resource consumption. Specifically, to ensure the lightweight and robustness, on the one hand, we construct a lightweight feature extraction attention (LFEA) module, which can fully extract target features and strengthen information interaction across channels. On the other hand, we construct a simple refined feature transfer (RFT) module. Compared with direct cross-layer connections, the RFT module can improve the network's feature refinement extraction capability with little resource consumption. Meanwhile, to solve the problem of small target loss in high-level feature maps, on the one hand, we propose a low-level feature distribution (LFD) strategy to use low-level features to supplement the information of high-level features. On the other hand, we introduce an efficient simplified bilinear interpolation attention module (SBAM) to promote the guidance constraints of low-level features on high-level features and the fusion of the two. In addition, We abandon the traditional resizing method and adopt a new training and inference cropping strategy, which is more robust to datasets with multi-scale samples. Extensive experimental results show that our LR-Net achieves state-of-the-art (SOTA) performance. Notably, on the basis of the proposed LR-Net, we achieve 3rd place in the \"ICPR 2024 Resource-Limited Infrared Small Target Detection Challenge Track 2: Lightweight Infrared Small Target Detection\".",
    "published": "2024-08-05",
    "link": "http://arxiv.org/abs/2408.02780v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Refined Infrared Small Target Detection Scheme with Single-Point Supervision",
    "author": "Jinmiao Zhao, Zelin Shi, Chuang Yu, Yunpeng Liu",
    "summary": "Recently, infrared small target detection with single-point supervision has attracted extensive attention. However, the detection accuracy of existing methods has difficulty meeting actual needs. Therefore, we propose an innovative refined infrared small target detection scheme with single-point supervision, which has excellent segmentation accuracy and detection rate. Specifically, we introduce label evolution with single point supervision (LESPS) framework and explore the performance of various excellent infrared small target detection networks based on this framework. Meanwhile, to improve the comprehensive performance, we construct a complete post-processing strategy. On the one hand, to improve the segmentation accuracy, we use a combination of test-time augmentation (TTA) and conditional random field (CRF) for post-processing. On the other hand, to improve the detection rate, we introduce an adjustable sensitivity (AS) strategy for post-processing, which fully considers the advantages of multiple detection results and reasonably adds some areas with low confidence to the fine segmentation image in the form of centroid points. In addition, to further improve the performance and explore the characteristics of this task, on the one hand, we construct and find that a multi-stage loss is helpful for fine-grained detection. On the other hand, we find that a reasonable sliding window cropping strategy for test samples has better performance for actual multi-size samples. Extensive experimental results show that the proposed scheme achieves state-of-the-art (SOTA) performance. Notably, the proposed scheme won the third place in the \"ICPR 2024 Resource-Limited Infrared Small Target Detection Challenge Track 1: Weakly Supervised Infrared Small Target Detection\".",
    "published": "2024-08-05",
    "link": "http://arxiv.org/abs/2408.02773v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Single-Point Supervised High-Resolution Dynamic Network for Infrared Small Target Detection",
    "author": "Jing Wu, Rixiang Ni, Feng Huang, Zhaobing Qiu, Liqiong Chen, Changhai Luo, Yunxiang Li, Youli Li",
    "summary": "Infrared small target detection (IRSTD) tasks are extremely challenging for two main reasons: 1) it is difficult to obtain accurate labelling information that is critical to existing methods, and 2) infrared (IR) small target information is easily lost in deep networks. To address these issues, we propose a single-point supervised high-resolution dynamic network (SSHD-Net). In contrast to existing methods, we achieve state-of-the-art (SOTA) detection performance using only single-point supervision. Specifically, we first design a high-resolution cross-feature extraction module (HCEM), that achieves bi-directional feature interaction through stepped feature cascade channels (SFCC). It balances network depth and feature resolution to maintain deep IR small-target information. Secondly, the effective integration of global and local features is achieved through the dynamic coordinate fusion module (DCFM), which enhances the anti-interference ability in complex backgrounds. In addition, we introduce the high-resolution multilevel residual module (HMRM) to enhance the semantic information extraction capability. Finally, we design the adaptive target localization detection head (ATLDH) to improve detection accuracy. Experiments on the publicly available datasets NUDT-SIRST and IRSTD-1k demonstrate the effectiveness of our method. Compared to other SOTA methods, our method can achieve better detection performance with only a single point of supervision.",
    "published": "2024-08-04",
    "link": "http://arxiv.org/abs/2408.01976v2",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Infrared Small Target Detection based on Adjustable Sensitivity Strategy and Multi-Scale Fusion",
    "author": "Jinmiao Zhao, Zelin Shi, Chuang Yu, Yunpeng Liu",
    "summary": "Recently, deep learning-based single-frame infrared small target (SIRST) detection technology has made significant progress. However, existing infrared small target detection methods are often optimized for a fixed image resolution, a single wavelength, or a specific imaging system, limiting their breadth and flexibility in practical applications. Therefore, we propose a refined infrared small target detection scheme based on an adjustable sensitivity (AS) strategy and multi-scale fusion. Specifically, a multi-scale model fusion framework based on multi-scale direction-aware network (MSDA-Net) is constructed, which uses input images of multiple scales to train multiple models and fuses them. Multi-scale fusion helps characterize the shape, edge, and texture features of the target from different scales, making the model more accurate and reliable in locating the target. At the same time, we fully consider the characteristics of the infrared small target detection task and construct an edge enhancement difficulty mining (EEDM) loss. The EEDM loss helps alleviate the problem of category imbalance and guides the network to pay more attention to difficult target areas and edge features during training. In addition, we propose an adjustable sensitivity strategy for post-processing. This strategy significantly improves the detection rate of infrared small targets while ensuring segmentation accuracy. Extensive experimental results show that the proposed scheme achieves the best performance. Notably, this scheme won the first prize in the PRCV 2024 wide-area infrared small target detection competition.",
    "published": "2024-07-29",
    "link": "http://arxiv.org/abs/2407.20090v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Background Semantics Matter: Cross-Task Feature Exchange Network for Clustered Infrared Small Target Detection With Sky-Annotated Dataset",
    "author": "Yimian Dai, Mengxuan Xiao, Yiming Zhu, Huan Wang, Kehua Guo, Jian Yang",
    "summary": "Infrared small target detection poses unique challenges due to the scarcity of intrinsic target features and the abundance of similar background distractors. We argue that background semantics play a pivotal role in distinguishing visually similar objects for this task. To address this, we introduce a new task -- clustered infrared small target detection, and present DenseSIRST, a novel benchmark dataset that provides per-pixel semantic annotations for background regions, enabling the transition from sparse to dense target detection. Leveraging this dataset, we propose the Background-Aware Feature Exchange Network (BAFE-Net), which transforms the detection paradigm from a single task focused on the foreground to a multi-task architecture that jointly performs target detection and background semantic segmentation. BAFE-Net introduces a cross-task feature hard-exchange mechanism to embed target and background semantics between the two tasks. Furthermore, we propose the Background-Aware Gaussian Copy-Paste (BAG-CP) method, which selectively pastes small targets into sky regions during training, avoiding the creation of false alarm targets in complex non-sky backgrounds. Extensive experiments validate the effectiveness of BAG-CP and BAFE-Net in improving target detection accuracy while reducing false alarms. The DenseSIRST dataset, code, and trained models are available at https://github.com/GrokCV/BAFE-Net.",
    "published": "2024-07-29",
    "link": "http://arxiv.org/abs/2407.20078v1",
    "code_url": "https://github.com/grokcv/bafe-net",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Sparse Prior Is Not All You Need: When Differential Directionality Meets Saliency Coherence for Infrared Small Target Detection",
    "author": "Fei Zhou, Maixia Fu, Yulei Qian, Jian Yang, Yimian Dai",
    "summary": "Infrared small target detection is crucial for the efficacy of infrared search and tracking systems. Current tensor decomposition methods emphasize representing small targets with sparsity but struggle to separate targets from complex backgrounds due to insufficient use of intrinsic directional information and reduced target visibility during decomposition. To address these challenges, this study introduces a Sparse Differential Directionality prior (SDD) framework. SDD leverages the distinct directional characteristics of targets to differentiate them from the background, applying mixed sparse constraints on the differential directional images and continuity difference matrix of the temporal component, both derived from Tucker decomposition. We further enhance target detectability with a saliency coherence strategy that intensifies target contrast against the background during hierarchical decomposition. A Proximal Alternating Minimization-based (PAM) algorithm efficiently solves our proposed model. Experimental results on several real-world datasets validate our method's effectiveness, outperforming ten state-of-the-art methods in target detection and clutter suppression. Our code is available at https://github.com/GrokCV/SDD.",
    "published": "2024-07-22",
    "link": "http://arxiv.org/abs/2407.15369v1",
    "code_url": "https://github.com/grokcv/sdd",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "IRSAM: Advancing Segment Anything Model for Infrared Small Target Detection",
    "author": "Mingjin Zhang, Yuchun Wang, Jie Guo, Yunsong Li, Xinbo Gao, Jing Zhang",
    "summary": "The recent Segment Anything Model (SAM) is a significant advancement in natural image segmentation, exhibiting potent zero-shot performance suitable for various downstream image segmentation tasks. However, directly utilizing the pretrained SAM for Infrared Small Target Detection (IRSTD) task falls short in achieving satisfying performance due to a notable domain gap between natural and infrared images. Unlike a visible light camera, a thermal imager reveals an object's temperature distribution by capturing infrared radiation. Small targets often show a subtle temperature transition at the object's boundaries. To address this issue, we propose the IRSAM model for IRSTD, which improves SAM's encoder-decoder architecture to learn better feature representation of infrared small objects. Specifically, we design a Perona-Malik diffusion (PMD)-based block and incorporate it into multiple levels of SAM's encoder to help it capture essential structural features while suppressing noise. Additionally, we devise a Granularity-Aware Decoder (GAD) to fuse the multi-granularity feature from the encoder to capture structural information that may be lost in long-distance modeling. Extensive experiments on the public datasets, including NUAA-SIRST, NUDT-SIRST, and IRSTD-1K, validate the design choice of IRSAM and its significant superiority over representative state-of-the-art methods. The source code are available at: github.com/IPIC-Lab/IRSAM.",
    "published": "2024-07-10",
    "link": "http://arxiv.org/abs/2407.07520v1",
    "code_url": "https://github.com/ipic-lab/irsam",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Lost in UNet: Improving Infrared Small Target Detection by Underappreciated Local Features",
    "author": "Wuzhou Quan, Wei Zhao, Weiming Wang, Haoran Xie, Fu Lee Wang, Mingqiang Wei",
    "summary": "Many targets are often very small in infrared images due to the long-distance imaging meachnism. UNet and its variants, as popular detection backbone networks, downsample the local features early and cause the irreversible loss of these local features, leading to both the missed and false detection of small targets in infrared images. We propose HintU, a novel network to recover the local features lost by various UNet-based methods for effective infrared small target detection. HintU has two key contributions. First, it introduces the \"Hint\" mechanism for the first time, i.e., leveraging the prior knowledge of target locations to highlight critical local features. Second, it improves the mainstream UNet-based architecture to preserve target pixels even after downsampling. HintU can shift the focus of various networks (e.g., vanilla UNet, UNet++, UIUNet, MiM+, and HCFNet) from the irrelevant background pixels to a more restricted area from the beginning. Experimental results on three datasets NUDT-SIRST, SIRSTv2 and IRSTD1K demonstrate that HintU enhances the performance of existing methods with only an additional 1.88 ms cost (on RTX Titan). Additionally, the explicit constraints of HintU enhance the generalization ability of UNet-based methods. Code is available at https://github.com/Wuzhou-Quan/HintU.",
    "published": "2024-06-19",
    "link": "http://arxiv.org/abs/2406.13445v1",
    "code_url": "https://github.com/wuzhou-quan/hintu",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Triple-domain Feature Learning with Frequency-aware Memory Enhancement for Moving Infrared Small Target Detection",
    "author": "Weiwei Duan, Luping Ji, Shengjia Chen, Sicheng Zhu, Mao Ye",
    "summary": "As a sub-field of object detection, moving infrared small target detection presents significant challenges due to tiny target sizes and low contrast against backgrounds. Currently-existing methods primarily rely on the features extracted only from spatio-temporal domain. Frequency domain has hardly been concerned yet, although it has been widely applied in image processing. To extend feature source domains and enhance feature representation, we propose a new Triple-domain Strategy (Tridos) with the frequency-aware memory enhancement on spatio-temporal domain for infrared small target detection. In this scheme, it effectively detaches and enhances frequency features by a local-global frequency-aware module with Fourier transform. Inspired by human visual system, our memory enhancement is designed to capture the spatial relations of infrared targets among video frames. Furthermore, it encodes temporal dynamics motion features via differential learning and residual enhancing. Additionally, we further design a residual compensation to reconcile possible cross-domain feature mismatches. To our best knowledge, proposed Tridos is the first work to explore infrared target feature learning comprehensively in spatio-temporal-frequency domains. The extensive experiments on three datasets (i.e., DAUB, ITSDT-15K and IRDST) validate that our triple-domain infrared feature learning scheme could often be obviously superior to state-of-the-art ones. Source codes are available at https://github.com/UESTC-nnLab/Tridos.",
    "published": "2024-06-11",
    "link": "http://arxiv.org/abs/2406.06949v2",
    "code_url": "https://github.com/uestc-nnlab/tridos",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Multi-Scale Direction-Aware Network for Infrared Small Target Detection",
    "author": "Jinmiao Zhao, Zelin Shi, Chuang Yu, Yunpeng Liu",
    "summary": "Infrared small target detection faces the problem that it is difficult to effectively separate the background and the target. Existing deep learning-based methods focus on appearance features and ignore high-frequency directional features. Therefore, we propose a multi-scale direction-aware network (MSDA-Net), which is the first attempt to integrate the high-frequency directional features of infrared small targets as domain prior knowledge into neural networks. Specifically, an innovative multi-directional feature awareness (MDFA) module is constructed, which fully utilizes the prior knowledge of targets and emphasizes the focus on high-frequency directional features. On this basis, combined with the multi-scale local relation learning (MLRL) module, a multi-scale direction-aware (MSDA) module is further constructed. The MSDA module promotes the full extraction of local relations at different scales and the full perception of key features in different directions. Meanwhile, a high-frequency direction injection (HFDI) module without training parameters is constructed to inject the high-frequency directional information of the original image into the network. This helps guide the network to pay attention to detailed information such as target edges and shapes. In addition, we propose a feature aggregation (FA) structure that aggregates multi-level features to solve the problem of small targets disappearing in deep feature maps. Furthermore, a lightweight feature alignment fusion (FAF) module is constructed, which can effectively alleviate the pixel offset existing in multi-level feature map fusion. Extensive experimental results show that our MSDA-Net achieves state-of-the-art (SOTA) results on the public NUDT-SIRST, SIRST and IRSTD-1k datasets.",
    "published": "2024-06-04",
    "link": "http://arxiv.org/abs/2406.02037v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Diff-Mosaic: Augmenting Realistic Representations in Infrared Small Target Detection via Diffusion Prior",
    "author": "Yukai Shi, Yupei Lin, Pengxu Wei, Xiaoyu Xian, Tianshui Chen, Liang Lin",
    "summary": "Recently, researchers have proposed various deep learning methods to accurately detect infrared targets with the characteristics of indistinct shape and texture. Due to the limited variety of infrared datasets, training deep learning models with good generalization poses a challenge. To augment the infrared dataset, researchers employ data augmentation techniques, which often involve generating new images by combining images from different datasets. However, these methods are lacking in two respects. In terms of realism, the images generated by mixup-based methods lack realism and are difficult to effectively simulate complex real-world scenarios. In terms of diversity, compared with real-world scenes, borrowing knowledge from another dataset inherently has a limited diversity. Currently, the diffusion model stands out as an innovative generative approach. Large-scale trained diffusion models have a strong generative prior that enables real-world modeling of images to generate diverse and realistic images. In this paper, we propose Diff-Mosaic, a data augmentation method based on the diffusion model. This model effectively alleviates the challenge of diversity and realism of data augmentation methods via diffusion prior. Specifically, our method consists of two stages. Firstly, we introduce an enhancement network called Pixel-Prior, which generates highly coordinated and realistic Mosaic images by harmonizing pixels. In the second stage, we propose an image enhancement strategy named Diff-Prior. This strategy utilizes diffusion priors to model images in the real-world scene, further enhancing the diversity and realism of the images. Extensive experiments have demonstrated that our approach significantly improves the performance of the detection network. The code is available at https://github.com/YupeiLin2388/Diff-Mosaic",
    "published": "2024-06-02",
    "link": "http://arxiv.org/abs/2406.00632v1",
    "code_url": "https://github.com/yupeilin2388/diff-mosaic",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Infrared Small Target Detection with Scale and Location Sensitivity",
    "author": "Qiankun Liu, Rui Liu, Bolun Zheng, Hongkui Wang, Ying Fu",
    "summary": "Recently, infrared small target detection (IRSTD) has been dominated by deep-learning-based methods. However, these methods mainly focus on the design of complex model structures to extract discriminative features, leaving the loss functions for IRSTD under-explored. For example, the widely used Intersection over Union (IoU) and Dice losses lack sensitivity to the scales and locations of targets, limiting the detection performance of detectors. In this paper, we focus on boosting detection performance with a more effective loss but a simpler model structure. Specifically, we first propose a novel Scale and Location Sensitive (SLS) loss to handle the limitations of existing losses: 1) for scale sensitivity, we compute a weight for the IoU loss based on target scales to help the detector distinguish targets with different scales: 2) for location sensitivity, we introduce a penalty term based on the center points of targets to help the detector localize targets more precisely. Then, we design a simple Multi-Scale Head to the plain U-Net (MSHNet). By applying SLS loss to each scale of the predictions, our MSHNet outperforms existing state-of-the-art methods by a large margin. In addition, the detection performance of existing detectors can be further improved when trained with our SLS loss, demonstrating the effectiveness and generalization of our SLS loss. The code is available at https://github.com/ying-fu/MSHNet.",
    "published": "2024-03-28",
    "link": "http://arxiv.org/abs/2403.19366v1",
    "code_url": "https://github.com/ying-fu/mshnet",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Mitigate Target-level Insensitivity of Infrared Small Target Detection via Posterior Distribution Modeling",
    "author": "Haoqing Li, Jinfu Yang, Yifei Xu, Runshi Wang",
    "summary": "Infrared Small Target Detection (IRSTD) aims to segment small targets from infrared clutter background. Existing methods mainly focus on discriminative approaches, i.e., a pixel-level front-background binary segmentation. Since infrared small targets are small and low signal-to-clutter ratio, empirical risk has few disturbances when a certain false alarm and missed detection exist, which seriously affect the further improvement of such methods. Motivated by the dense prediction generative methods, in this paper, we propose a diffusion model framework for Infrared Small Target Detection which compensates pixel-level discriminant with mask posterior distribution modeling. Furthermore, we design a Low-frequency Isolation in the wavelet domain to suppress the interference of intrinsic infrared noise on the diffusion noise estimation. This transition from the discriminative paradigm to generative one enables us to bypass the target-level insensitivity. Experiments show that the proposed method achieves competitive performance gains over state-of-the-art methods on NUAA-SIRST, IRSTD-1k, and NUDT-SIRST datasets. Code are available at https://github.com/Li-Haoqing/IRSTD-Diff.",
    "published": "2024-03-13",
    "link": "http://arxiv.org/abs/2403.08380v1",
    "code_url": "https://github.com/li-haoqing/irstd-diff",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "SIRST-5K: Exploring Massive Negatives Synthesis with Self-supervised Learning for Robust Infrared Small Target Detection",
    "author": "Yahao Lu, Yupei Lin, Han Wu, Xiaoyu Xian, Yukai Shi, Liang Lin",
    "summary": "Single-frame infrared small target (SIRST) detection aims to recognize small targets from clutter backgrounds. Recently, convolutional neural networks have achieved significant advantages in general object detection. With the development of Transformer, the scale of SIRST models is constantly increasing. Due to the limited training samples, performance has not been improved accordingly. The quality, quantity, and diversity of the infrared dataset are critical to the detection of small targets. To highlight this issue, we propose a negative sample augmentation method in this paper. Specifically, a negative augmentation approach is proposed to generate massive negatives for self-supervised learning. Firstly, we perform a sequential noise modeling technology to generate realistic infrared data. Secondly, we fuse the extracted noise with the original data to facilitate diversity and fidelity in the generated data. Lastly, we proposed a negative augmentation strategy to enrich diversity as well as maintain semantic invariance. The proposed algorithm produces a synthetic SIRST-5K dataset, which contains massive pseudo-data and corresponding labels. With a rich diversity of infrared small target data, our algorithm significantly improves the model performance and convergence speed. Compared with other state-of-the-art (SOTA) methods, our method achieves outstanding performance in terms of probability of detection (Pd), false-alarm rate (Fa), and intersection over union (IoU).",
    "published": "2024-03-08",
    "link": "http://arxiv.org/abs/2403.05416v1",
    "code_url": "https://github.com/luy0222/sirst-5k",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection",
    "author": "Tianxiang Chen, Zi Ye, Zhentao Tan, Tao Gong, Yue Wu, Qi Chu, Bin Liu, Nenghai Yu, Jieping Ye",
    "summary": "Recently, infrared small target detection (ISTD) has made significant progress, thanks to the development of basic models. Specifically, the models combining CNNs with transformers can successfully extract both local and global features. However, the disadvantage of the transformer is also inherited, i.e., the quadratic computational complexity to sequence length. Inspired by the recent basic model with linear complexity for long-distance modeling, Mamba, we explore the potential of this state space model for ISTD task in terms of effectiveness and efficiency in the paper. However, directly applying Mamba achieves suboptimal performances due to the insufficient harnessing of local features, which are imperative for detecting small targets. Instead, we tailor a nested structure, Mamba-in-Mamba (MiM-ISTD), for efficient ISTD. It consists of Outer and Inner Mamba blocks to adeptly capture both global and local features. Specifically, we treat the local patches as \"visual sentences\" and use the Outer Mamba to explore the global information. We then decompose each visual sentence into sub-patches as \"visual words\" and use the Inner Mamba to further explore the local information among words in the visual sentence with negligible computational costs. By aggregating the visual word and visual sentence features, our MiM-ISTD can effectively explore both global and local information. Experiments on NUAA-SIRST and IRSTD-1k show the superior accuracy and efficiency of our method. Specifically, MiM-ISTD is $8 \\times$ faster than the SOTA method and reduces GPU memory usage by 62.2$\\%$ when testing on $2048 \\times 2048$ images, overcoming the computation and memory constraints on high-resolution infrared images.",
    "published": "2024-03-04",
    "link": "http://arxiv.org/abs/2403.02148v4",
    "code_url": "https://github.com/txchen-ustc/mim-istd",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Infrared Small Target Detection via tensor $L_{2,1}$ norm minimization and ASSTV regularization: A Novel Tensor Recovery Approach",
    "author": "Jiqian Zhao, An-Bao Xu",
    "summary": "In recent years, there has been a noteworthy focus on infrared small target detection, given its vital importance in processing signals from infrared remote sensing. The considerable computational cost incurred by prior methods, relying excessively on nuclear norm for noise separation, necessitates the exploration of efficient alternatives. The aim of this research is to identify a swift and resilient tensor recovery method for the efficient extraction of infrared small targets from image sequences. Theoretical validation indicates that smaller singular values predominantly contribute to constructing noise information. In the exclusion process, tensor QR decomposition is employed to reasonably reduce the size of the target tensor. Subsequently, we address a tensor $L_{2,1}$ Norm Minimization via T-QR (TLNMTQR) based method to effectively isolate the noise, markedly improving computational speed without compromising accuracy. Concurrently, by integrating the asymmetric spatial-temporal total variation regularization method (ASSTV), our objective is to augment the flexibility and efficacy of our algorithm in handling time series data. Ultimately, our method underwent rigorous testing with real-world data, affirmatively showcasing the superiority of our algorithm in terms of speed, precision, and robustness.",
    "published": "2024-02-28",
    "link": "http://arxiv.org/abs/2402.18003v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "SpirDet: Towards Efficient, Accurate and Lightweight Infrared Small Target Detector",
    "author": "Qianchen Mao, Qiang Li, Bingshu Wang, Yongjun Zhang, Tao Dai, C. L. Philip Chen",
    "summary": "In recent years, the detection of infrared small targets using deep learning methods has garnered substantial attention due to notable advancements. To improve the detection capability of small targets, these methods commonly maintain a pathway that preserves high-resolution features of sparse and tiny targets. However, it can result in redundant and expensive computations. To tackle this challenge, we propose SpirDet, a novel approach for efficient detection of infrared small targets. Specifically, to cope with the computational redundancy issue, we employ a new dual-branch sparse decoder to restore the feature map. Firstly, the fast branch directly predicts a sparse map indicating potential small target locations (occupying only 0.5\\% area of the map). Secondly, the slow branch conducts fine-grained adjustments at the positions indicated by the sparse map. Additionally, we design an lightweight DO-RepEncoder based on reparameterization with the Downsampling Orthogonality, which can effectively reduce memory consumption and inference latency. Extensive experiments show that the proposed SpirDet significantly outperforms state-of-the-art models while achieving faster inference speed and fewer parameters. For example, on the IRSTD-1K dataset, SpirDet improves $MIoU$ by 4.7 and has a $7\\times$ $FPS$ acceleration compared to the previous state-of-the-art model. The code will be open to the public.",
    "published": "2024-02-08",
    "link": "http://arxiv.org/abs/2402.05410v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "$\\textit{A Contrario}$ Paradigm for YOLO-based Infrared Small Target Detection",
    "author": "Alina Ciocarlan, Sylvie Le H\u00e9garat-Mascle, Sidonie Lefebvre, Arnaud Woiselle, Clara Barbanson",
    "summary": "Detecting small to tiny targets in infrared images is a challenging task in computer vision, especially when it comes to differentiating these targets from noisy or textured backgrounds. Traditional object detection methods such as YOLO struggle to detect tiny objects compared to segmentation neural networks, resulting in weaker performance when detecting small targets. To reduce the number of false alarms while maintaining a high detection rate, we introduce an $\\textit{a contrario}$ decision criterion into the training of a YOLO detector. The latter takes advantage of the $\\textit{unexpectedness}$ of small targets to discriminate them from complex backgrounds. Adding this statistical criterion to a YOLOv7-tiny bridges the performance gap between state-of-the-art segmentation methods for infrared small target detection and object detection networks. It also significantly increases the robustness of YOLO towards few-shot settings.",
    "published": "2024-02-03",
    "link": "http://arxiv.org/abs/2402.02288v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "TCI-Former: Thermal Conduction-Inspired Transformer for Infrared Small Target Detection",
    "author": "Tianxiang Chen, Zhentao Tan, Qi Chu, Yue Wu, Bin Liu, Nenghai Yu",
    "summary": "Infrared small target detection (ISTD) is critical to national security and has been extensively applied in military areas. ISTD aims to segment small target pixels from background. Most ISTD networks focus on designing feature extraction blocks or feature fusion modules, but rarely describe the ISTD process from the feature map evolution perspective. In the ISTD process, the network attention gradually shifts towards target areas. We abstract this process as the directional movement of feature map pixels to target areas through convolution, pooling and interactions with surrounding pixels, which can be analogous to the movement of thermal particles constrained by surrounding variables and particles. In light of this analogy, we propose Thermal Conduction-Inspired Transformer (TCI-Former) based on the theoretical principles of thermal conduction. According to thermal conduction differential equation in heat dynamics, we derive the pixel movement differential equation (PMDE) in the image domain and further develop two modules: Thermal Conduction-Inspired Attention (TCIA) and Thermal Conduction Boundary Module (TCBM). TCIA incorporates finite difference method with PMDE to reach a numerical approximation so that target body features can be extracted. To further remove errors in boundary areas, TCBM is designed and supervised by boundary masks to refine target body features with fine boundary details. Experiments on IRSTD-1k and NUAA-SIRST demonstrate the superiority of our method.",
    "published": "2024-02-03",
    "link": "http://arxiv.org/abs/2402.02046v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "SCTransNet: Spatial-channel Cross Transformer Network for Infrared Small Target Detection",
    "author": "Shuai Yuan, Hanlin Qin, Xiang Yan, Naveed AKhtar, Ajmal Mian",
    "summary": "Infrared small target detection (IRSTD) has recently benefitted greatly from U-shaped neural models. However, largely overlooking effective global information modeling, existing techniques struggle when the target has high similarities with the background. We present a Spatial-channel Cross Transformer Network (SCTransNet) that leverages spatial-channel cross transformer blocks (SCTBs) on top of long-range skip connections to address the aforementioned challenge. In the proposed SCTBs, the outputs of all encoders are interacted with cross transformer to generate mixed features, which are redistributed to all decoders to effectively reinforce semantic differences between the target and clutter at full scales. Specifically, SCTB contains the following two key elements: (a) spatial-embedded single-head channel-cross attention (SSCA) for exchanging local spatial features and full-level global channel information to eliminate ambiguity among the encoders and facilitate high-level semantic associations of the images, and (b) a complementary feed-forward network (CFN) for enhancing the feature discriminability via a multi-scale strategy and cross-spatial-channel information interaction to promote beneficial information transfer. Our SCTransNet effectively encodes the semantic differences between targets and backgrounds to boost its internal representation for detecting small infrared targets accurately. Extensive experiments on three public datasets, NUDT-SIRST, NUAA-SIRST, and IRSTD-1k, demonstrate that the proposed SCTransNet outperforms existing IRSTD methods. Our code will be made public at https://github.com/xdFai.",
    "published": "2024-01-28",
    "link": "http://arxiv.org/abs/2401.15583v3",
    "code_url": "https://github.com/xdfai/sctransnet",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "ASCNet: Asymmetric Sampling Correction Network for Infrared Image Destriping",
    "author": "Shuai Yuan, Hanlin Qin, Xiang Yan, Shiqi Yang, Shuowen Yang, Naveed Akhtar",
    "summary": "In a real-world infrared imaging system, effectively learning a consistent stripe noise removal model is essential. Most existing destriping methods cannot precisely reconstruct images due to cross-level semantic gaps and insufficient characterization of the global column features. To tackle this problem, we propose a novel infrared image destriping method, called Asymmetric Sampling Correction Network (ASCNet), that can effectively capture global column relationships and embed them into a U-shaped framework, providing comprehensive discriminative representation and seamless semantic connectivity. Our ASCNet consists of three core elements: Residual Haar Discrete Wavelet Transform (RHDWT), Pixel Shuffle (PS), and Column Non-uniformity Correction Module (CNCM). Specifically, RHDWT is a novel downsampler that employs double-branch modeling to effectively integrate stripe-directional prior knowledge and data-driven semantic interaction to enrich the feature representation. Observing the semantic patterns crosstalk of stripe noise, PS is introduced as an upsampler to prevent excessive apriori decoding and performing semantic-bias-free image reconstruction. After each sampling, CNCM captures the column relationships in long-range dependencies. By incorporating column, spatial, and self-dependence information, CNCM well establishes a global context to distinguish stripes from the scene's vertical structures. Extensive experiments on synthetic data, real data, and infrared small target detection tasks demonstrate that the proposed method outperforms state-of-the-art single-image destriping methods both visually and quantitatively. Our code will be made publicly available at https://github.com/xdFai/ASCNet.",
    "published": "2024-01-28",
    "link": "http://arxiv.org/abs/2401.15578v2",
    "code_url": "https://github.com/xdfai/ascnet",
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "From Lab to Pocket: A Novel Continual Learning-based Mobile Application for Screening COVID-19",
    "author": "Danny Falero, Muhammad Ashad Kabir, Nusrat Homaira",
    "summary": "Artificial intelligence (AI) has emerged as a promising tool for predicting COVID-19 from medical images. In this paper, we propose a novel continual learning-based approach and present the design and implementation of a mobile application for screening COVID-19. Our approach demonstrates the ability to adapt to evolving datasets, including data collected from different locations or hospitals, varying virus strains, and diverse clinical presentations, without retraining from scratch. We have evaluated state-of-the-art continual learning methods for detecting COVID-19 from chest X-rays and selected the best-performing model for our mobile app. We evaluated various deep learning architectures to select the best-performing one as a foundation model for continual learning. Both regularization and memory-based methods for continual learning were tested, using different memory sizes to develop the optimal continual learning model for our app. DenseNet161 emerged as the best foundation model with 96.87\\% accuracy, and Learning without Forgetting (LwF) was the top continual learning method with an overall performance of 71.99\\%. The mobile app design considers both patient and doctor perspectives. It incorporates the continual learning DenseNet161 LwF model on a cloud server, enabling the model to learn from new instances of chest X-rays and their classifications as they are submitted. The app is designed, implemented, and evaluated to ensure it provides an efficient tool for COVID-19 screening. The app is available to download from https://github.com/DannyFGitHub/COVID-19PneumoCheckApp.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12589v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "REST API Testing in DevOps: A Study on an Evolving Healthcare IoT Application",
    "author": "Hassan Sartaj, Shaukat Ali, Julie Marie Gj\u00f8by",
    "summary": "Healthcare Internet of Things (IoT) applications often integrate various third-party healthcare applications and medical devices through REST APIs, resulting in complex and interdependent networks of REST APIs. Oslo City's healthcare department collaborates with various industry partners to develop such healthcare IoT applications enriched with a diverse set of REST APIs. Following the DevOps process, these REST APIs continuously evolve to accommodate evolving needs such as new features, services, and devices. Oslo City's primary goal is to utilize automated solutions for continuous testing of these REST APIs at each evolution stage, thereby ensuring their dependability. Although the literature offers various automated REST API testing tools, their effectiveness in regression testing of the evolving REST APIs of healthcare IoT applications within a DevOps context remains undetermined. This paper evaluates state-of-the-art and well-established REST API testing tools-specifically, RESTest, EvoMaster, Schemathesis, RESTler, and RestTestGen-for the regression testing of a real-world healthcare IoT application, considering failures, faults, coverage, regressions, and cost. We conducted experiments using all accessible REST APIs (17 APIs with 120 endpoints), and 14 releases evolved during DevOps. Overall, all tools generated tests leading to several failures, 18 potential faults, up to 84% coverage, 23 regressions, and over 80% cost overhead.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12547v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Evaluating Utility of Memory Efficient Medical Image Generation: A Study on Lung Nodule Segmentation",
    "author": "Kathrin Khadra, Utku T\u00fcrkbey",
    "summary": "The scarcity of publicly available medical imaging data limits the development of effective AI models. This work proposes a memory-efficient patch-wise denoising diffusion probabilistic model (DDPM) for generating synthetic medical images, focusing on CT scans with lung nodules. Our approach generates high-utility synthetic images with nodule segmentation while efficiently managing memory constraints, enabling the creation of training datasets. We evaluate the method in two scenarios: training a segmentation model exclusively on synthetic data, and augmenting real-world training data with synthetic images. In the first case, models trained solely on synthetic data achieve Dice scores comparable to those trained on real-world data benchmarks. In the second case, augmenting real-world data with synthetic images significantly improves segmentation performance. The generated images demonstrate their potential to enhance medical image datasets in scenarios with limited real-world data.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12542v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Radiation damage and recovery of plastic scintillators under ultra-high dose rate 200 MeV electrons at CERN CLEAR facility",
    "author": "Clo\u00e9 Gigu\u00e8re, Alexander Hart, Joseph Bateman, Pierre Korysko, Wilfrid Farabolini, Yoan LeChasseur, Magdalena Bazalova-Carter, Luc Beaulieu",
    "summary": "The FLASH effect holds significant potential in improving radiotherapy treatment outcomes. Very high energy electrons (VHEEs) can effectively target tumors deep in the body and can be accelerated to achieve ultra-high dose rates (UHDR), making them a promising modality for delivering FLASH radiotherapy in the clinic. However, apart from suitable VHEE sources, clinical translation requires accurate dosimetry, which is challenging due to the limitation of standard dosimeters under UHDR. Water-equivalent and real-time plastic scintillation dosimeters (PSDs) may offer a solution. In this study, a 4-channel PSD, consisting of polystyrene-based BCF12 and Medscint proprietary scintillators, polyvinyltoluene (PVT)-based EJ-212 and a clear plastic fiber channel for Cherenkov subtraction was exposed to the 200 MeV VHEE UHDR beam at the CLEAR CERN facility. The Hyperscint RP200 platform was used to assess linearity to dose pulses of up to 90 Gy and dose rates up to 4.6x10$^9$ Gy/s, and to investigate radiation damage and recovery after dose accumulation of 37.2 kGy. While clear fiber response was linear across the entire dose range studied, light output saturated above ~50 Gy/pulse for scintillators. Despite radiation damage, linearity was preserved, though it resulted in a decrease of scintillator and clear fiber light output of <1.85 %/kGy and a shift in spectra towards longer wavelengths. Short-term recovery (<100h) of these changes was observed and depended on rest duration and accumulated dose. After long-term rest (<172 days), light output recovery was partial, with 6-22% of residual permanent damage remaining, while spectral recovery was complete. We showed that PSDs are sensitive to radiation damage, but maintain dose linearity even after accumulated dose of 37.2 kGy, and exhibit significant response recovery. This work highlights the potential of PSDs for dosimetry in UHDR conditions.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12535v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Imaging neutrons with a position-sensitive monolithic CLYC detector",
    "author": "J. Lerendegui-Marco, G. Cisterna, J. Hallam, V. Babiano-Su\u00e1rez, J. Balibrea-Correa, D. Calvo, I. Ladarescu, G. de la Fuente, B. Gameiro, A. Sanchis-Molt\u00f3, P. Torres-S\u00e1nchez, C. Domingo-Pardo",
    "summary": "In this work, we have developed and characterized a position-sensitive CLYC detector that acts as the neutron imaging layer and $\\gamma$-ray Compton scatterer of the novel dual \\g-ray and neutron imaging system GN-Vision, which aims at simultaneously obtaining information about the spatial origin of \\g-ray and neutron sources. We first investigated the performance of large 50$\\times$50~mm$^{2}$ monolithic CLYC crystals coupled to a pixelated SiPM in terms of energy resolution and neutron-gamma discrimination. The response of two different 95\\% $^{6}$Li-enriched CLYC detectors coupled to an array of 8$\\times$8 SiPMs was studied in comparison to the results of a conventional photo-multiplier tube. Energy resolution ranging from 6-8\\% for the $^{137}$Cs peak and a figure of merit of 3-4 for the neutron-gamma discrimination have been obtained. The spatial response of the CLYC-SiPM detector to $\\gamma$-rays and neutrons has also been characterized using charge modulation-based multiplexing techniques based on a diode-coupled charge division circuit. Average resolutions close to 5~mm FWHM with good linearity are obtained in the transverse crystal plane. Last, this work presents the first proof-of-concept experiments of the neutron imaging capability using a neutron pinhole collimator attached to the developed position sensitive CLYC detector.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12533v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration",
    "author": "Jinjie Wei, Dingkang Yang, Yanshu Li, Qingyao Xu, Zhaoyu Chen, Mingcheng Li, Yue Jiang, Xiaolu Hou, Lihua Zhang",
    "summary": "Large Language Model (LLM)-driven interactive systems currently show potential promise in healthcare domains. Despite their remarkable capabilities, LLMs typically lack personalized recommendations and diagnosis analysis in sophisticated medical applications, causing hallucinations and performance bottlenecks. To address these challenges, this paper proposes MedAide, an LLM-based omni medical multi-agent collaboration framework for specialized healthcare services. Specifically, MedAide first performs query rewriting through retrieval-augmented generation to accomplish accurate medical intent understanding. Immediately, we devise a contextual encoder to obtain intent prototype embeddings, which are used to recognize fine-grained intents by similarity matching. According to the intent relevance, the activated agents collaborate effectively to provide integrated decision analysis. Extensive experiments are conducted on four medical benchmarks with composite intents. Experimental results from automated metrics and expert doctor evaluations show that MedAide outperforms current LLMs and improves their medical proficiency and strategic reasoning.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12532v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Thermal analysis of GaN-based photonic membranes for optoelectronics",
    "author": "Wilken Seemann, Mahmoud Elhajhasan, Julian Themann, Katharina Dudde, Guillaume W\u00fcrsch, Jana Lierath, Joachim Ciers, \u00c5sa Haglund, Nakib H. Protik, Giuseppe Romano, Rapha\u00ebl Butt\u00e9, Jean-Fran\u00e7ois Carlin, Nicolas Grandjean, Gordon Callsen",
    "summary": "Semiconductor membranes find their widespread use in various research fields targeting medical, biological, environmental, and optical applications. Often such membranes derive their functionality from an inherent nanopatterning, which renders the determination of their, e.g., optical, electronic, mechanical, and thermal properties a challenging task. In this work we demonstrate the non-invasive, all-optical thermal characterization of around 800-nm-thick and 150-$\\mu$m-wide membranes that consist of wurtzite GaN and a stack of In$_{0.15}$Ga$_{0.85}$N quantum wells as a built-in light source. Due to their application in photonics such membranes are bright light emitters, which challenges their non-invasive thermal characterization by only optical means. As a solution, we combine two-laser Raman thermometry with (time-resolved) photoluminescence measurements to extract the in-plane (i.e., $c$-plane) thermal conductivity $\\kappa_{\\text{in-plane}}$ of our membranes. Based on this approach, we can disentangle the entire laser-induced power balance during our thermal analysis, meaning that all fractions of reflected, scattered, transmitted, and reemitted light are considered. As a result of our thermal imaging via Raman spectroscopy, we obtain $\\kappa_{\\text{in-plane}}\\,=\\,165^{+16}_{-14}\\,$Wm$^{-1}$K$^{-1}$ for our best membrane, which compares well to our simulations yielding $\\kappa_{\\text{in-plane}}\\,=\\,177\\,$Wm$^{-1}$K$^{-1}$ based on an ab initio solution of the linearized phonon Boltzmann transport equation. Our work presents a promising pathway towards thermal imaging at cryogenic temperatures, e.g., when aiming to elucidate experimentally different phonon transport regimes via the recording of non-Fourier temperature distributions.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12515v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Synthetic Augmentation for Anatomical Landmark Localization using DDPMs",
    "author": "Arnela Hadzic, Lea Bogensperger, Simon Johannes Joham, Martin Urschler",
    "summary": "Deep learning techniques for anatomical landmark localization (ALL) have shown great success, but their reliance on large annotated datasets remains a problem due to the tedious and costly nature of medical data acquisition and annotation. While traditional data augmentation, variational autoencoders (VAEs), and generative adversarial networks (GANs) have already been used to synthetically expand medical datasets, diffusion-based generative models have recently started to gain attention for their ability to generate high-quality synthetic images. In this study, we explore the use of denoising diffusion probabilistic models (DDPMs) for generating medical images and their corresponding heatmaps of landmarks to enhance the training of a supervised deep learning model for ALL. Our novel approach involves a DDPM with a 2-channel input, incorporating both the original medical image and its heatmap of annotated landmarks. We also propose a novel way to assess the quality of the generated images using a Markov Random Field (MRF) model for landmark matching and a Statistical Shape Model (SSM) to check landmark plausibility, before we evaluate the DDPM-augmented dataset in the context of an ALL task involving hand X-Rays.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12489v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Attention-Guided Perturbation for Consistency Regularization in Semi-Supervised Medical Image Segmentation",
    "author": "Yuxuan Cheng, Chenxi Shao, Jie Ma, Guoliang Li",
    "summary": "Medical image segmentation is a pivotal step in diagnostic and therapeutic processes. However, the acquisition of high-quality annotated data is often constrained by scarcity and cost. Semi-supervised learning offers a promising approach to enhance model performance by using unlabeled data. While consistency regularization is a prevalent method in semi-supervised image segmentation, there is a dearth of research on perturbation strategies tailored for semi-supervised medical image segmentation tasks. This paper introduces an attention-guided perturbation strategy for semi-supervised consistency regularization in the context of medical image segmentation. We add the perturbation based on the attention from the model in the image and feature level to achieve consistency regularization. The method is adept at accommodating the intricate structures and high-dimensional semantics inherent in medical images, thereby enhancing the performance of semi-supervised segmentation tasks. Our method achieved state-of-the-art results on benchmark datasets, including a 90.4\\% Dice score on the ACDC dataset in the 7-case scenario.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12419v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "De-Identification of Medical Imaging Data: A Comprehensive Tool for Ensuring Patient Privacy",
    "author": "Moritz Rempe, Lukas Heine, Constantin Seibold, Fabian H\u00f6rst, Jens Kleesiek",
    "summary": "Medical data employed in research frequently comprises sensitive patient health information (PHI), which is subject to rigorous legal frameworks such as the General Data Protection Regulation (GDPR) or the Health Insurance Portability and Accountability Act (HIPAA). Consequently, these types of data must be pseudonymized prior to utilisation, which presents a significant challenge for many researchers. Given the vast array of medical data, it is necessary to employ a variety of de-identification techniques. To facilitate the anonymization process for medical imaging data, we have developed an open-source tool that can be used to de-identify DICOM magnetic resonance images, computer tomography images, whole slide images and magnetic resonance twix raw data. Furthermore, the implementation of a neural network enables the removal of text within the images. The proposed tool automates an elaborate anonymization pipeline for multiple types of inputs, reducing the need for additional tools used for de-identification of imaging data. We make our code publicly available at https://github.com/code-lukas/medical_image_deidentification.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12402v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Quantifying Treatment Effects: Estimating Risk Ratios in Causal Inference",
    "author": "Ahmed Boughdiri, Julie Josse, Erwan Scornet",
    "summary": "Randomized Controlled Trials (RCT) are the current gold standards to empirically measure the effect of a new drug. However, they may be of limited size and resorting to complementary non-randomized data, referred to as observational, is promising, as additional sources of evidence. In both RCT and observational data, the Risk Difference (RD) is often used to characterize the effect of a drug. Additionally, medical guidelines recommend to also report the Risk Ratio (RR), which may provide a different comprehension of the effect of the same drug. While different methods have been proposed and studied to estimate the RD, few methods exist to estimate the RR. In this paper, we propose estimators of the RR both in RCT and observational data and provide both asymptotical and finite-sample analyses. We show that, even in an RCT, estimating treatment allocation probability or adjusting for covariates leads to lower asymptotic variance. In observational studies, we propose weighting and outcome modeling estimators and derive their asymptotic bias and variance for well-specified models. Using semi-parametric theory, we define two doubly robusts estimators with minimal variances among unbiased estimators. We support our theoretical analysis with empirical evaluations and illustrate our findings through experiments.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12333v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Advancing Healthcare: Innovative ML Approaches for Improved Medical Imaging in Data-Constrained Environments",
    "author": "Al Amin, Kamrul Hasan, Saleh Zein-Sabatto, Liang Hong, Sachin Shetty, Imtiaz Ahmed, Tariqul Islam",
    "summary": "Healthcare industries face challenges when experiencing rare diseases due to limited samples. Artificial Intelligence (AI) communities overcome this situation to create synthetic data which is an ethical and privacy issue in the medical domain. This research introduces the CAT-U-Net framework as a new approach to overcome these limitations, which enhances feature extraction from medical images without the need for large datasets. The proposed framework adds an extra concatenation layer with downsampling parts, thereby improving its ability to learn from limited data while maintaining patient privacy. To validate, the proposed framework's robustness, different medical conditioning datasets were utilized including COVID-19, brain tumors, and wrist fractures. The framework achieved nearly 98% reconstruction accuracy, with a Dice coefficient close to 0.946. The proposed CAT-U-Net has the potential to make a big difference in medical image diagnostics in settings with limited data.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12245v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "In vivo high-resolution \u03c7-separation at 7T",
    "author": "Jiye Kim, Minjun Kim, Sooyeon Ji, Kyeongseon Min, Hwihun Jeong, Hyeong-Geol Shin, Chungseok Oh, Sina Straub, Seong-Gi Kim, Jongho Lee",
    "summary": "A recently introduced quantitative susceptibility mapping (QSM) technique, $\\chi$-separation, offers the capability to separate paramagnetic ($\\chi_{\\text{para}}$) and diamagnetic ($\\chi_{\\text{dia}}$) susceptibility distribution within the brain. In-vivo high-resolution mapping of iron and myelin distribution, estimated by $\\chi$-separation, could provide a deeper understanding of brain substructures, assisting the investigation of their functions and alterations. This can be achieved using 7T MRI, which benefits from a high signal-to-noise ratio and susceptibility effects. However, applying $\\chi$-separation at 7T presents difficulties due to the requirement of an $R_2$ map, coupled with issues such as high specific absorption rate (SAR), large $B_1$ transmit field inhomogeneities, and prolonged scan time.   To address these challenges, we developed a novel deep neural network, R2PRIMEnet7T, designed to convert a 7T $R_2^*$ map into a 3T $R_2'$ map. Building on this development, we present a new pipeline for $\\chi$-separation at 7T, enabling us to generate high-resolution $\\chi$-separation maps from multi-echo gradient-echo data. The proposed method is compared with alternative pipelines, such as an end-to-end network and linearly-scaled $R_2'$, and is validated against $\\chi$-separation maps at 3T, demonstrating its accuracy. The 7T $\\chi$-separation maps generated by the proposed method exhibit similar contrasts to those from 3T, while 7T high-resolution maps offer enhanced clarity and detail. Quantitative analysis confirms that the proposed method surpasses the alternative pipelines. The proposed method results well delineate the detailed brain structures associated with iron and myelin. This new pipeline holds promise for analyzing iron and myelin concentration changes in various neurodegenerative diseases through precise structural examination.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12239v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Implementation of EMR System in Indonesian Health Facilities: Benefits and Constraints",
    "author": "Rasyid Juliansyah, Bukhori Muhammad Aqid, Andien Putri Salsabila, Kurnia Nurfiyanti",
    "summary": "This paper delves into the widespread implementation of Electronic Medical Records (EMR) within healthcare facilities across Indonesia. It examines the driving forces behind EMR adoption, particularly the role of government regulations, and addresses the challenges encountered by clinic owners and healthcare providers in transitioning to these digital systems. Furthermore, this paper highlights the significant benefits and transformative advantages of EMR systems, such as enhanced decision-making through real-time data access (around 15-20 minutes time saved for patient waiting time and approximately saved 20-25 minutes for all service duration), reduction in healthcare costs over time due to improved resource management, and increased patient satisfaction by providing faster and more personalized care. EMR systems also ensure higher levels of data security and privacy, adhering to national healthcare standards, while supporting continuous monitoring and updates that enhance system resilience and functionality. The findings are substantiated through case studies, such as case study at LAPAS II Purwokerto Clinic and case study at PMI Purbalingga Clinic and user testimonials from clinics that have successfully implemented EMR solutions in compliance with the standards established by the Ministry of Communication and Informatics (Kominfo) and the Ministry of Health (Kemenkes).",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12226v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "AutoSimTTF: A Fully Automatic Pipeline for Electric Field Simulation and Treatment Planning of Tumor Treating Fields",
    "author": "Minmin Wang, Xu Xie, Zhengbo Fan, Yue Lan, Yun Pan, Guangdi Chen, Shaomin Zhang, Yuxing Wang",
    "summary": "Objective: Tumor Treating Fields (TTFields) is an emerging approach for cancer therapy that inhibits tumor cell proliferation by applying alternating electric fields (EF) of intermediate frequency and low intensity. The TTFields-induced electric field intensity at the tumor site is closely related to the therapeutic efficacy. Therefore, the EF simulation based on realistic head models have been utilized for the dosage analysis and treatment optimization of TTFields. However, current modeling methods require manual segmentation of tumors and rely on commercial software, which is time-consuming and labor-intensive. Approach: We introduce AutoSimTTF, a fully automatic pipeline for simulating and optimizing the EF distribution for TTFields. The main steps of AutoSimTTF utilize open-source toolkits, enabling fully automated processing of individual MRI data for TTFields. Additionally, AutoSimTTF allows for parameter optimization based on individual anatomical information, thereby achieving a more focused and higher EF distribution at the tumor site. Main results: Compared to conventional EF calculation processes, deviations in AutoSimTTF are below 20%. The optimal treatment parameters generated by AutoSimTTF produces a higher EF intensity at the tumor site (111.9%) and better focality (19.4%) compared to traditional TTFields settings. Significance: AutoSimTTF provides significant reference value and guidance for the clinical application and treatment planning of TTFields.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12196v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Segmented readout for Cherenkov time-of-flight positron emission tomography detectors based on bismuth germanate",
    "author": "Minseok Yi, Daehee Lee, Alberto Gola, Stefano Merzi, Michele Penna, Jae Sung Lee, Simon R. Cherry, Sun Il Kwon",
    "summary": "Positron emission tomography (PET) is the most sensitive biomedical imaging modality for non-invasively detecting and visualizing positron-emitting radiopharmaceuticals within a subject. In PET, measuring the time-of-flight (TOF) information for each pair of 511-keV annihilation photons improves effective sensitivity but requires high timing resolution. Hybrid materials that emit both scintillation and Cherenkov photons, such as bismuth germanate (BGO), recently offer the potential for more precise timing information from Cherenkov photons while maintaining adequate energy resolution from scintillation photons. However, a significant challenge in using such hybrid materials for TOF PET applications lies in the event-dependent timing spread caused by the mixed detection of Cherenkov and scintillation photons due to relatively lower production of Cherenkov photons. This study introduces an innovative approach by segmenting silicon photomultiplier (SiPM) pixels coupled to a single crystal, rather than using traditional SiPMs that are as large as or larger than the crystals they read. We demonstrated that multiple time stamps and photon counts obtained from the segmented SiPM can classify events by providing temporal photon density, effectively addressing this challenge. The approach and findings would lead to new opportunities in applications that require precise timing and photon counting, spanning the fields of medical imaging, high-energy physics, and optical physics.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12161v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Brush structures directly anchored to ion beam treated polymer surfaces without linker",
    "author": "Alexey Kondyurin",
    "summary": "A brush structure is an interesting object for future applications in medical and electronic devices. Usual substrate for the brushes is silicon wafer with linker molecules. In present study an ion beam treatment of polymer was used for attachment of brush structures without liker molecules. The goal of the study was a fabrication of carbonized active substrate and a direct attachment of different brush molecules. The carbonised coating on silicon wafer has been prepared from ion beam implanted polystyrene coating and characterised with AFM, XPS, ESR, Raman, FTIR and ellipsometry measurements. The brush structures based on polystyrene and polyacrylamide backbone with thiol, amine and carboxyl end groups have been synthesised on the carbonised substrates. The brush structures have been characterised with ellipsometry, XPS, FTIR and AFM. The swollen brush shows a thickness phase transition with temperature rise. The attachment of the brush structures is based on free radical reactions on the carbonised surface. The effect of impurity of the brush polymer was found significant. Thus, the brush structures of broad kinds of the end groups can be synthesised on the carbonised substrates without a linker.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12149v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "End-Stage Liver Disease Comorbidities in Patients Awaiting Transplantation: Identification and Impact on Liver Transplant Survival",
    "author": "Julia Tacherel, Kiruthika Balakrishnan, Gyorgy Simon, Lisiane Pruinelli",
    "summary": "End-Stage Liver Disease (ESLD), a complex condition, has high rates of co-occurring comorbidities affecting multiple organ systems. There is no clear evidence-based practice (EBP) guidelines addressing the progression of comorbidities in ESLD patients awaiting liver transplantation (LT) and their impact on survival, both pre- and post-transplant. This study aimed to identify and quantify the trajectory of the most common and deteriorating comorbidities in ESLD patients awaiting LT and to analyze their effect on patient outcomes. An initial exploratory phase to identify frequent comorbidities in ESLD patients. Relevant EBP-driven data for diagnosing and measuring the progression of these conditions were collected and organized into five research matrices. In the quantitative phase, a retrospective analysis was conducted using longitudinal de-identified data from electronic health records (EHR) for patients who underwent LT between 2011-2021. Data included demographics, labs, procedures, and medications. Descriptive statistics and survival analysis assessed the association of comorbidities with post-transplant survival. The five most frequent comorbidities identified were Diabetes Mellitus (DM), Chronic Kidney Disease (CKD), Malnutrition, Portal Hypertension (PH), and Ascites. Of the 722 patients analyzed, 68.2% were male, mean age of 54.81 (SD = 11.24), and 19.8% died post-LT. Survival analysis showed a gradual decline over time, with the most significant drop at five years post-LT. Significant predictors of post-LT survival were age at transplant (p=0.01), waitlist time (p=0.004), DM at listing (p=0.02), low albumin (p=0.03), and CKD stage 5 development after listing (p=0.04). This study highlights the variability in diagnosing and measuring comorbidities in ESLD patients and provides insights into their progression and impact on post-LT survival.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.12118v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Testing Causal Explanations: A Case Study for Understanding the Effect of Interventions on Chronic Kidney Disease",
    "author": "Panayiotis Petousis, David Gordon, Susanne B. Nicholas, Alex A. T. Bui",
    "summary": "Randomized controlled trials (RCTs) are the standard for evaluating the effectiveness of clinical interventions. To address the limitations of RCTs on real-world populations, we developed a methodology that uses a large observational electronic health record (EHR) dataset. Principles of regression discontinuity (rd) were used to derive randomized data subsets to test expert-driven interventions using dynamic Bayesian Networks (DBNs) do-operations. This combined method was applied to a chronic kidney disease (CKD) cohort of more than two million individuals and used to understand the associational and causal relationships of CKD variables with respect to a surrogate outcome of >=40% decline in estimated glomerular filtration rate (eGFR). The associational and causal analyses depicted similar findings across DBNs from two independent healthcare systems. The associational analysis showed that the most influential variables were eGFR, urine albumin-to-creatinine ratio, and pulse pressure, whereas the causal analysis showed eGFR as the most influential variable, followed by modifiable factors such as medications that may impact kidney function over time. This methodology demonstrates how real-world EHR data can be used to provide population-level insights to inform improved healthcare delivery.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.12047v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "The concentrated toroidal wave",
    "author": "Kevin J. Parker, Miguel A. Alonso",
    "summary": "The classical solution to the Helmholtz wave equation in spherical coordinates is well known and has found many important applications in wave propagation, scattering, and imaging in optics and acoustics. The separable solution is comprised of spherical Bessel functions in the radial direction and spherical harmonics in the angular directions. The nature of the spherical Bessel functions includes a long asymptotic oscillatory tail at large radii, not conducive to applications where a tight concentration of wave amplitude around a ring is desired, for example in toroidal configurations. However, we have found that certain practical bandpass spectral shapes, centered around a peak frequency, can create a superposition of spherical Bessel functions that effectively concentrate the wave amplitude around a defined ring at the time instant of coherent addition, avoiding the long tail asymptotic oscillations of the single frequency solution. Theoretical solutions are shown for different bandpass spectra applied to the spherical Bessel functions, along with numerical solutions of transient wave propagation using practical hemispherical source shapes. These findings introduce a framework by which ring or toroidal concentrated waves can be produced with a simple bandpass superposition applied to hemispherical source shapes and with reference to the classical solutions in spherical coordinates.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.11700v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "3D printing by two-photon polymerization of hollow microneedles for interstitial fluid extraction",
    "author": "Tiago Elias Abi-Ramia Silva, Stephan Kohler, Nicolas Bartzsch, Felix Beuschlein, Andreas T. Guentner",
    "summary": "Dermal interstitial fluid (ISF) is a rich source of biomarkers (e.g., glucose) that can be used for continuous health monitoring with wearable sensors. Hollow microneedle devices are a promising solution to extract ISF on demand by penetrating the skin with minimal pain. However, they rely on inserting bio-incompatible materials (e.g., silicon) into individuals, limiting the application time. Here, the direct 3D printing of polymer hollow microneedles on silicon-based microfluidic devices and the successful in-vivo extraction of ISF are demonstrated. Our additive manufacturing approach enables the versatile combination of materials and rapid prototyping of microneedle geometry. After improving the design through finite element modeling, a hollow microneedle geometry was printed by two-photon polymerization and experimentally characterized with mechanical and fluidic tests. Microneedles were fabricated with high accuracy (i.e., 997 +/- 2 um) and reliably interfaced with the microfluidic chip (i.e., centerline alignment within 5% of diameter). The needles demonstrated sufficient mechanical strength (i.e., 411 +/- 3 mN per needle) to endure at least 10 consecutive insertions into simulated skin. Biocompatibility and ISF extraction were demonstrated in an in-vivo 72-hour test, showing the safety and reliability of our approach. Such a platform is promising for minimally invasive, continuous monitoring of biomarkers in ISF, aiding in medical diagnoses and personalized health treatments.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.11631v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Defining myocardial fiber bundle architecture in atrial digital twins",
    "author": "Roberto Piersanti, Ryan Bradley, Syed Yusuf Alid, Alfio Quarteroni, Luca Dede', Natalia A. Trayanova",
    "summary": "A key component in developing atrial digital twins (ADT) - virtual representations of patients' atria - is the accurate prescription of myocardial fibers which are essential for the tissue characterization. Due to the difficulty of reconstructing atrial fibers from medical imaging, a widely used strategy for fiber generation in ADT relies on mathematical models. Existing methodologies utilze semi-automatic approaches, are tailored to specific morphologies, and lack rigorous validation against imaging fiber data. In this study, we introduce a novel atrial Laplace-Dirichlet-Rule-Based Method (LDRBM) for prescribing highly detailed myofiber orientations and providing robust regional annotation in bi-atrial morphologies of any complexity. The robustness of our approach is verified in eight extremely detailed bi-atrial geometries, derived from a sub-millimiter Diffusion-Tensor-Magnetic-Resonance Imaging (DTMRI) human atrial fiber dataset. We validate the LDRBM by quantitatively recreating each of the DTMRI fiber architectures: a comprehensive comparison with DTMRI ground truth data is conducted, investigating differences between electrophysiology (EP) simulations provided by either LDRBM and DTMRI fibers. Finally, we demonstrate that the novel LDRBM outperforms current state-of-the-art fiber models, confirming the exceptional accuracy of our methodology and the critical importance of incorporating detailed fiber orientations in EP simulations. Ultimately, this work represents a fundamental step toward the development of physics-based digital twins of the human atria, establishing a new standard for prescribing fibers in ADT.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.11601v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Deep vectorised operators for pulsatile hemodynamics estimation in coronary arteries from a steady-state prior",
    "author": "Julian Suk, Guido Nannini, Patryk Rygiel, Christoph Brune, Gianluca Pontone, Alberto Redaelli, Jelmer M. Wolterink",
    "summary": "Cardiovascular hemodynamic fields provide valuable medical decision markers for coronary artery disease. Computational fluid dynamics (CFD) is the gold standard for accurate, non-invasive evaluation of these quantities in vivo. In this work, we propose a time-efficient surrogate model, powered by machine learning, for the estimation of pulsatile hemodynamics based on steady-state priors. We introduce deep vectorised operators, a modelling framework for discretisation independent learning on infinite-dimensional function spaces. The underlying neural architecture is a neural field conditioned on hemodynamic boundary conditions. Importantly, we show how relaxing the requirement of point-wise action to permutation-equivariance leads to a family of models that can be parametrised by message passing and self-attention layers. We evaluate our approach on a dataset of 74 stenotic coronary arteries extracted from coronary computed tomography angiography (CCTA) with patient-specific pulsatile CFD simulations as ground truth. We show that our model produces accurate estimates of the pulsatile velocity and pressure while being agnostic to re-sampling of the source domain (discretisation independence). This shows that deep vectorised operators are a powerful modelling tool for cardiovascular hemodynamics estimation in coronary arteries and beyond.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.11920v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data",
    "author": "Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Luis M\u00e1rquez Carpintero, M\u00f3nica Pina-Navarro, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li",
    "summary": "Large Language Models~(LLMs) have demonstrated capabilities across various applications but face challenges such as hallucination, limited reasoning abilities, and factual inconsistencies, especially when tackling complex, domain-specific tasks like question answering~(QA). While Knowledge Graphs~(KGs) have been shown to help mitigate these issues, research on the integration of LLMs with background KGs remains limited. In particular, user accessibility and the flexibility of the underlying KG have not been thoroughly explored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based Interaction and Graphical Representation), a platform for knowledge management through natural language interaction. It integrates knowledge extraction, integration, and real-time visualization. AGENTiGraph employs a multi-agent architecture to dynamically interpret user intents, manage tasks, and integrate new knowledge, ensuring adaptability to evolving user requirements and data contexts. Our approach demonstrates superior performance in knowledge graph interactions, particularly for complex domain-specific tasks. Experimental results on a dataset of 3,500 test cases show AGENTiGraph significantly outperforms state-of-the-art zero-shot baselines, achieving 95.12\\% accuracy in task classification and 90.45\\% success rate in task execution. User studies corroborate its effectiveness in real-world scenarios. To showcase versatility, we extended AGENTiGraph to legislation and healthcare domains, constructing specialized KGs capable of answering complex queries in legal and medical contexts.",
    "published": "2024-10-15",
    "link": "http://arxiv.org/abs/2410.11531v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "V2M: Visual 2-Dimensional Mamba for Image Representation Learning",
    "author": "Chengkun Wang, Wenzhao Zheng, Yuanhui Huang, Jie Zhou, Jiwen Lu",
    "summary": "Mamba has garnered widespread attention due to its flexible design and efficient hardware performance to process 1D sequences based on the state space model (SSM). Recent studies have attempted to apply Mamba to the visual domain by flattening 2D images into patches and then regarding them as a 1D sequence. To compensate for the 2D structure information loss (e.g., local similarity) of the original image, most existing methods focus on designing different orders to sequentially process the tokens, which could only alleviate this issue to some extent. In this paper, we propose a Visual 2-Dimensional Mamba (V2M) model as a complete solution, which directly processes image tokens in the 2D space. We first generalize SSM to the 2-dimensional space which generates the next state considering two adjacent states on both dimensions (e.g., columns and rows). We then construct our V2M based on the 2-dimensional SSM formulation and incorporate Mamba to achieve hardware-efficient parallel processing. The proposed V2M effectively incorporates the 2D locality prior yet inherits the efficiency and input-dependent scalability of Mamba. Extensive experimental results on ImageNet classification and downstream visual tasks including object detection and instance segmentation on COCO and semantic segmentation on ADE20K demonstrate the effectiveness of our V2M compared with other visual backbones.",
    "published": "2024-10-14",
    "link": "http://arxiv.org/abs/2410.10382v1",
    "code_url": "https://github.com/wangck20/v2m",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "GlobalMamba: Global Image Serialization for Vision Mamba",
    "author": "Chengkun Wang, Wenzhao Zheng, Jie Zhou, Jiwen Lu",
    "summary": "Vision mambas have demonstrated strong performance with linear complexity to the number of vision tokens. Their efficiency results from processing image tokens sequentially. However, most existing methods employ patch-based image tokenization and then flatten them into 1D sequences for causal processing, which ignore the intrinsic 2D structural correlations of images. It is also difficult to extract global information by sequential processing of local patches. In this paper, we propose a global image serialization method to transform the image into a sequence of causal tokens, which contain global information of the 2D image. We first convert the image from the spatial domain to the frequency domain using Discrete Cosine Transform (DCT) and then arrange the pixels with corresponding frequency ranges. We further transform each set within the same frequency band back to the spatial domain to obtain a series of images before tokenization. We construct a vision mamba model, GlobalMamba, with a causal input format based on the proposed global image serialization, which can better exploit the causal relations among image sequences. Extensive experiments demonstrate the effectiveness of our GlobalMamba, including image classification on ImageNet-1K, object detection on COCO, and semantic segmentation on ADE20K.",
    "published": "2024-10-14",
    "link": "http://arxiv.org/abs/2410.10316v1",
    "code_url": "https://github.com/wangck20/globalmamba",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Hi-Mamba: Hierarchical Mamba for Efficient Image Super-Resolution",
    "author": "Junbo Qiao, Jincheng Liao, Wei Li, Yulun Zhang, Yong Guo, Yi Wen, Zhangxizi Qiu, Jiao Xie, Jie Hu, Shaohui Lin",
    "summary": "State Space Models (SSM), such as Mamba, have shown strong representation ability in modeling long-range dependency with linear complexity, achieving successful applications from high-level to low-level vision tasks. However, SSM's sequential nature necessitates multiple scans in different directions to compensate for the loss of spatial dependency when unfolding the image into a 1D sequence. This multi-direction scanning strategy significantly increases the computation overhead and is unbearable for high-resolution image processing. To address this problem, we propose a novel Hierarchical Mamba network, namely, Hi-Mamba, for image super-resolution (SR). Hi-Mamba consists of two key designs: (1) The Hierarchical Mamba Block (HMB) assembled by a Local SSM (L-SSM) and a Region SSM (R-SSM) both with the single-direction scanning, aggregates multi-scale representations to enhance the context modeling ability. (2) The Direction Alternation Hierarchical Mamba Group (DA-HMG) allocates the isomeric single-direction scanning into cascading HMBs to enrich the spatial relationship modeling. Extensive experiments demonstrate the superiority of Hi-Mamba across five benchmark datasets for efficient SR. For example, Hi-Mamba achieves a significant PSNR improvement of 0.29 dB on Manga109 for $\\times3$ SR, compared to the strong lightweight MambaIR.",
    "published": "2024-10-14",
    "link": "http://arxiv.org/abs/2410.10140v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "A Holistic Weakly Supervised Approach for Liver Tumor Segmentation with Clinical Knowledge-Informed Label Smoothing",
    "author": "Hairong Wang, Lingchao Mao, Zihan Zhang, Jing Li",
    "summary": "Liver cancer is a leading cause of mortality worldwide, and accurate CT-based tumor segmentation is essential for diagnosis and treatment. Manual delineation is time-intensive, prone to variability, and highlights the need for reliable automation. While deep learning has shown promise for automated liver segmentation, precise liver tumor segmentation remains challenging due to the heterogeneous nature of tumors, imprecise tumor margins, and limited labeled data. We present a novel holistic weakly supervised framework that integrates clinical knowledge to address these challenges with (1) A knowledge-informed label smoothing technique that leverages clinical data to generate smooth labels, which regularizes model training reducing the risk of overfitting and enhancing model performance; (2) A global and local-view segmentation framework, breaking down the task into two simpler sub-tasks, allowing optimized preprocessing and training for each; and (3) Pre- and post-processing pipelines customized to the challenges of each subtask, which enhances tumor visibility and refines tumor boundaries. We evaluated the proposed method on the HCC-TACE-Seg dataset and showed that these three key components complementarily contribute to the improved performance. Lastly, we prototyped a tool for automated liver tumor segmentation and diagnosis summary generation called MedAssistLiver. The app and code are published at https://github.com/lingchm/medassist-liver-cancer.",
    "published": "2024-10-13",
    "link": "http://arxiv.org/abs/2410.10005v1",
    "code_url": "https://github.com/lingchm/medassist-liver-cancer",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "SlimSeiz: Efficient Channel-Adaptive Seizure Prediction Using a Mamba-Enhanced Network",
    "author": "Guorui Lu, Jing Peng, Bingyuan Huang, Chang Gao, Todor Stefanov, Yong Hao, Qinyu Chen",
    "summary": "Epileptic seizures cause abnormal brain activity, and their unpredictability can lead to accidents, underscoring the need for long-term seizure prediction. Although seizures can be predicted by analyzing electroencephalogram (EEG) signals, existing methods often require too many electrode channels or larger models, limiting mobile usability. This paper introduces a SlimSeiz framework that utilizes adaptive channel selection with a lightweight neural network model. SlimSeiz operates in two states: the first stage selects the optimal channel set for seizure prediction using machine learning algorithms, and the second stage employs a lightweight neural network based on convolution and Mamba for prediction. On the Children's Hospital Boston-MIT (CHB-MIT) EEG dataset, SlimSeiz can reduce channels from 22 to 8 while achieving a satisfactory result of 94.8% accuracy, 95.5% sensitivity, and 94.0% specificity with only 21.2K model parameters, matching or outperforming larger models' performance. We also validate SlimSeiz on a new EEG dataset, SRH-LEI, collected from Shanghai Renji Hospital, demonstrating its effectiveness across different patients. The code and SRH-LEI dataset are available at https://github.com/guoruilu/SlimSeiz.",
    "published": "2024-10-13",
    "link": "http://arxiv.org/abs/2410.09998v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models",
    "author": "Sathya Kamesh Bhethanabhotla, Omar Swelam, Julien Siems, David Salinas, Frank Hutter",
    "summary": "This paper introduces Mamba4Cast, a zero-shot foundation model for time series forecasting. Based on the Mamba architecture and inspired by Prior-data Fitted Networks (PFNs), Mamba4Cast generalizes robustly across diverse time series tasks without the need for dataset specific fine-tuning. Mamba4Cast's key innovation lies in its ability to achieve strong zero-shot performance on real-world datasets while having much lower inference times than time series foundation models based on the transformer architecture. Trained solely on synthetic data, the model generates forecasts for entire horizons in a single pass, outpacing traditional auto-regressive approaches. Our experiments show that Mamba4Cast performs competitively against other state-of-the-art foundation models in various data sets while scaling significantly better with the prediction length. The source code can be accessed at https://github.com/automl/Mamba4Cast.",
    "published": "2024-10-12",
    "link": "http://arxiv.org/abs/2410.09385v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Parameter-Efficient Fine-Tuning of State Space Models",
    "author": "Kevin Galim, Wonjun Kang, Yuchen Zeng, Hyung Il Koo, Kangwook Lee",
    "summary": "Deep State Space Models (SSMs), such as Mamba (Gu & Dao, 2024), have emerged as powerful tools for language modeling, offering high performance with efficient inference and linear scaling in sequence length. However, the application of parameter-efficient fine-tuning (PEFT) methods to SSM-based models remains largely unexplored. This paper aims to systematically study two key questions: (i) How do existing PEFT methods perform on SSM-based models? (ii) Which modules are most effective for fine-tuning? We conduct an empirical benchmark of four basic PEFT methods on SSM-based models. Our findings reveal that prompt-based methods (e.g., prefix-tuning) are no longer effective, an empirical result further supported by theoretical analysis. In contrast, LoRA remains effective for SSM-based models. We further investigate the optimal application of LoRA within these models, demonstrating both theoretically and experimentally that applying LoRA to linear projection matrices without modifying SSM modules yields the best results, as LoRA is not effective at tuning SSM modules. To further improve performance, we introduce LoRA with Selective Dimension tuning (SDLoRA), which selectively updates certain channels and states on SSM modules while applying LoRA to linear projection matrices. Extensive experimental results show that this approach outperforms standard LoRA.",
    "published": "2024-10-11",
    "link": "http://arxiv.org/abs/2410.09016v1",
    "code_url": "https://github.com/furiosa-ai/ssm-peft",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient",
    "author": "Wenlong Wang, Ivana Dusparic, Yucheng Shi, Ke Zhang, Vinny Cahill",
    "summary": "Model-based reinforcement learning (RL) offers a solution to the data inefficiency that plagues most model-free RL algorithms. However, learning a robust world model often demands complex and deep architectures, which are expensive to compute and train. Within the world model, dynamics models are particularly crucial for accurate predictions, and various dynamics-model architectures have been explored, each with its own set of challenges. Currently, recurrent neural network (RNN) based world models face issues such as vanishing gradients and difficulty in capturing long-term dependencies effectively. In contrast, use of transformers suffers from the well-known issues of self-attention mechanisms, where both memory and computational complexity scale as $O(n^2)$, with $n$ representing the sequence length.   To address these challenges we propose a state space model (SSM) based world model, specifically based on Mamba, that achieves $O(n)$ memory and computational complexity while effectively capturing long-term dependencies and facilitating the use of longer training sequences efficiently. We also introduce a novel sampling method to mitigate the suboptimality caused by an incorrect world model in the early stages of training, combining it with the aforementioned technique to achieve a normalised score comparable to other state-of-the-art model-based RL algorithms using only a 7 million trainable parameter world model. This model is accessible and can be trained on an off-the-shelf laptop. Our code is available at https://github.com/realwenlongwang/drama.git.",
    "published": "2024-10-11",
    "link": "http://arxiv.org/abs/2410.08893v1",
    "code_url": "https://github.com/realwenlongwang/drama",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Moyun: A Diffusion-Based Model for Style-Specific Chinese Calligraphy Generation",
    "author": "Kaiyuan Liu, Jiahao Mei, Hengyu Zhang, Yihuai Zhang, Xingjiao Wu, Daoguo Dong, Liang He",
    "summary": "Although Chinese calligraphy generation has achieved style transfer, generating calligraphy by specifying the calligrapher, font, and character style remains challenging. To address this, we propose a new Chinese calligraphy generation model 'Moyun' , which replaces the Unet in the Diffusion model with Vision Mamba and introduces the TripleLabel control mechanism to achieve controllable calligraphy generation. The model was tested on our large-scale dataset 'Mobao' of over 1.9 million images, and the results demonstrate that 'Moyun' can effectively control the generation process and produce calligraphy in the specified style. Even for calligraphy the calligrapher has not written, 'Moyun' can generate calligraphy that matches the style of the calligrapher.",
    "published": "2024-10-10",
    "link": "http://arxiv.org/abs/2410.07618v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Stuffed Mamba: State Collapse and State Capacity of RNN-Based Long-Context Modeling",
    "author": "Yingfa Chen, Xinrong Zhang, Shengding Hu, Xu Han, Zhiyuan Liu, Maosong Sun",
    "summary": "One essential advantage of recurrent neural networks (RNNs) over transformer-based language models is their linear computational complexity concerning the sequence length, which makes them much faster in handling long sequences during inference. However, most publicly available RNNs (e.g., Mamba and RWKV) are trained on sequences with less than 10K tokens, and their effectiveness in longer contexts remains largely unsatisfying so far. In this paper, we study the cause of the inability to process long context for RNNs and suggest critical mitigations. We examine two practical concerns when applying state-of-the-art RNNs to long contexts: (1) the inability to extrapolate to inputs longer than the training length and (2) the upper bound of memory capacity. Addressing the first concern, we first investigate *state collapse* (SC), a phenomenon that causes severe performance degradation on sequence lengths not encountered during training. With controlled experiments, we attribute this to overfitting due to the recurrent state being overparameterized for the training length. For the second concern, we train a series of Mamba-2 models on long documents to empirically estimate the recurrent state capacity in language modeling and passkey retrieval. Then, three SC mitigation methods are proposed to improve Mamba-2's length generalizability, allowing the model to process more than 1M tokens without SC. We also find that the recurrent state capacity in passkey retrieval scales exponentially to the state size, and we empirically train a Mamba-2 370M with near-perfect passkey retrieval accuracy on 256K context length. This suggests a promising future for RNN-based long-context modeling.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.07145v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Iterative Optimization Annotation Pipeline and ALSS-YOLO-Seg for Efficient Banana Plantation Segmentation in UAV Imagery",
    "author": "Ang He, Ximei Wu, Xing Xu, Jing Chen, Xiaobin Guo, Sheng Xu",
    "summary": "Precise segmentation of Unmanned Aerial Vehicle (UAV)-captured images plays a vital role in tasks such as crop yield estimation and plant health assessment in banana plantations. By identifying and classifying planted areas, crop area can be calculated, which is indispensable for accurate yield predictions. However, segmenting banana plantation scenes requires a substantial amount of annotated data, and manual labeling of these images is both time-consuming and labor-intensive, limiting the development of large-scale datasets. Furthermore, challenges such as changing target sizes, complex ground backgrounds, limited computational resources, and correct identification of crop categories make segmentation even more difficult. To address these issues, we proposed a comprehensive solution. Firstly, we designed an iterative optimization annotation pipeline leveraging SAM2's zero-shot capabilities to generate high-quality segmentation annotations, thereby reducing the cost and time associated with data annotation significantly. Secondly, we developed ALSS-YOLO-Seg, an efficient lightweight segmentation model optimized for UAV imagery. The model's backbone includes an Adaptive Lightweight Channel Splitting and Shuffling (ALSS) module to improve information exchange between channels and optimize feature extraction, aiding accurate crop identification. Additionally, a Multi-Scale Channel Attention (MSCA) module combines multi-scale feature extraction with channel attention to tackle challenges of varying target sizes and complex ground backgrounds.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.07955v1",
    "code_url": "https://github.com/helloworlder8/computer_vision",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Joint Fine-tuning and Conversion of Pretrained Speech and Language Models towards Linear Complexity",
    "author": "Mutian He, Philip N. Garner",
    "summary": "Architectures such as Linformer and Mamba have recently emerged as competitive linear time replacements for transformers. However, corresponding large pretrained models are often unavailable, especially in non-text domains. To remedy this, we present a Cross-Architecture Layerwise Distillation (CALD) approach that jointly converts a transformer model to a linear time substitute and fine-tunes it to a target task. We also compare several means to guide the fine-tuning to optimally retain the desired inference capability from the original model. The methods differ in their use of the target model and the trajectory of the parameters. In a series of empirical studies on language processing, language modeling, and speech processing, we show that CALD can effectively recover the result of the original model, and that the guiding strategy contributes to the result. Some reasons for the variation are suggested.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.06846v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "QuadMamba: Learning Quadtree-based Selective Scan for Visual State Space Model",
    "author": "Fei Xie, Weijia Zhang, Zhongdao Wang, Chao Ma",
    "summary": "Recent advancements in State Space Models, notably Mamba, have demonstrated superior performance over the dominant Transformer models, particularly in reducing the computational complexity from quadratic to linear. Yet, difficulties in adapting Mamba from language to vision tasks arise due to the distinct characteristics of visual data, such as the spatial locality and adjacency within images and large variations in information granularity across visual tokens. Existing vision Mamba approaches either flatten tokens into sequences in a raster scan fashion, which breaks the local adjacency of images, or manually partition tokens into windows, which limits their long-range modeling and generalization capabilities. To address these limitations, we present a new vision Mamba model, coined QuadMamba, that effectively captures local dependencies of varying granularities via quadtree-based image partition and scan. Concretely, our lightweight quadtree-based scan module learns to preserve the 2D locality of spatial regions within learned window quadrants. The module estimates the locality score of each token from their features, before adaptively partitioning tokens into window quadrants. An omnidirectional window shifting scheme is also introduced to capture more intact and informative features across different local regions. To make the discretized quadtree partition end-to-end trainable, we further devise a sequence masking strategy based on Gumbel-Softmax and its straight-through gradient estimator. Extensive experiments demonstrate that QuadMamba achieves state-of-the-art performance in various vision tasks, including image classification, object detection, instance segmentation, and semantic segmentation. The code is in https://github.com/VISION-SJTU/QuadMamba.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.06806v2",
    "code_url": "https://github.com/vision-sjtu/quadmamba",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Towards Universality: Studying Mechanistic Similarity Across Language Model Architectures",
    "author": "Junxuan Wang, Xuyang Ge, Wentao Shu, Qiong Tang, Yunhua Zhou, Zhengfu He, Xipeng Qiu",
    "summary": "The hypothesis of Universality in interpretability suggests that different neural networks may converge to implement similar algorithms on similar tasks. In this work, we investigate two mainstream architectures for language modeling, namely Transformers and Mambas, to explore the extent of their mechanistic similarity. We propose to use Sparse Autoencoders (SAEs) to isolate interpretable features from these models and show that most features are similar in these two models. We also validate the correlation between feature similarity and Universality. We then delve into the circuit-level analysis of Mamba models and find that the induction circuits in Mamba are structurally analogous to those in Transformers. We also identify a nuanced difference we call \\emph{Off-by-One motif}: The information of one token is written into the SSM state in its next position. Whilst interaction between tokens in Transformers does not exhibit such trend.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.06672v2",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Mamba-based Segmentation Model for Speaker Diarization",
    "author": "Alexis Plaquet, Naohiro Tawara, Marc Delcroix, Shota Horiguchi, Atsushi Ando, Shoko Araki",
    "summary": "Mamba is a newly proposed architecture which behaves like a recurrent neural network (RNN) with attention-like capabilities. These properties are promising for speaker diarization, as attention-based models have unsuitable memory requirements for long-form audio, and traditional RNN capabilities are too limited. In this paper, we propose to assess the potential of Mamba for diarization by comparing the state-of-the-art neural segmentation of the pyannote pipeline with our proposed Mamba-based variant. Mamba's stronger processing capabilities allow usage of longer local windows, which significantly improve diarization quality by making the speaker embedding extraction more reliable. We find Mamba to be a superior alternative to both traditional RNN and the tested attention-based model. Our proposed Mamba-based system achieves state-of-the-art performance on three widely used diarization datasets.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.06459v2",
    "code_url": "https://github.com/nttcslab-sp/mamba-diarization",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "DeMo: Decoupling Motion Forecasting into Directional Intentions and Dynamic States",
    "author": "Bozhou Zhang, Nan Song, Li Zhang",
    "summary": "Accurate motion forecasting for traffic agents is crucial for ensuring the safety and efficiency of autonomous driving systems in dynamically changing environments. Mainstream methods adopt a one-query-one-trajectory paradigm, where each query corresponds to a unique trajectory for predicting multi-modal trajectories. While straightforward and effective, the absence of detailed representation of future trajectories may yield suboptimal outcomes, given that the agent states dynamically evolve over time. To address this problem, we introduce DeMo, a framework that decouples multi-modal trajectory queries into two types: mode queries capturing distinct directional intentions and state queries tracking the agent's dynamic states over time. By leveraging this format, we separately optimize the multi-modality and dynamic evolutionary properties of trajectories. Subsequently, the mode and state queries are integrated to obtain a comprehensive and detailed representation of the trajectories. To achieve these operations, we additionally introduce combined Attention and Mamba techniques for global information aggregation and state sequence modeling, leveraging their respective strengths. Extensive experiments on both the Argoverse 2 and nuScenes benchmarks demonstrate that our DeMo achieves state-of-the-art performance in motion forecasting.",
    "published": "2024-10-08",
    "link": "http://arxiv.org/abs/2410.05982v1",
    "code_url": "https://github.com/fudan-zvg/demo",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "EMMA: Empowering Multi-modal Mamba with Structural and Hierarchical Alignment",
    "author": "Yifei Xing, Xiangyuan Lan, Ruiping Wang, Dongmei Jiang, Wenjun Huang, Qingfang Zheng, Yaowei Wang",
    "summary": "Mamba-based architectures have shown to be a promising new direction for deep learning models owing to their competitive performance and sub-quadratic deployment speed. However, current Mamba multi-modal large language models (MLLM) are insufficient in extracting visual features, leading to imbalanced cross-modal alignment between visual and textural latents, negatively impacting performance on multi-modal tasks. In this work, we propose Empowering Multi-modal Mamba with Structural and Hierarchical Alignment (EMMA), which enables the MLLM to extract fine-grained visual information. Specifically, we propose a pixel-wise alignment module to autoregressively optimize the learning and processing of spatial image-level features along with textual tokens, enabling structural alignment at the image level. In addition, to prevent the degradation of visual information during the cross-model alignment process, we propose a multi-scale feature fusion (MFF) module to combine multi-scale visual features from intermediate layers, enabling hierarchical alignment at the feature level. Extensive experiments are conducted across a variety of multi-modal benchmarks. Our model shows lower latency than other Mamba-based MLLMs and is nearly four times faster than transformer-based MLLMs of similar scale during inference. Due to better cross-modal alignment, our model exhibits lower degrees of hallucination and enhanced sensitivity to visual details, which manifests in superior performance across diverse multi-modal benchmarks. Code will be provided.",
    "published": "2024-10-08",
    "link": "http://arxiv.org/abs/2410.05938v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "TIMBA: Time series Imputation with Bi-directional Mamba Blocks and Diffusion models",
    "author": "Javier Sol\u00eds-Garc\u00eda, Bel\u00e9n Vega-M\u00e1rquez, Juan A. Nepomuceno, Isabel A. Nepomuceno-Chamorro",
    "summary": "The problem of imputing multivariate time series spans a wide range of fields, from clinical healthcare to multi-sensor systems. Initially, Recurrent Neural Networks (RNNs) were employed for this task; however, their error accumulation issues led to the adoption of Transformers, leveraging attention mechanisms to mitigate these problems. Concurrently, the promising results of diffusion models in capturing original distributions have positioned them at the forefront of current research, often in conjunction with Transformers. In this paper, we propose replacing time-oriented Transformers with State-Space Models (SSM), which are better suited for temporal data modeling. Specifically, we utilize the latest SSM variant, S6, which incorporates attention-like mechanisms. By embedding S6 within Mamba blocks, we develop a model that integrates SSM, Graph Neural Networks, and node-oriented Transformers to achieve enhanced spatiotemporal representations. Implementing these architectural modifications, previously unexplored in this field, we present Time series Imputation with Bi-directional mamba blocks and diffusion models (TIMBA). TIMBA achieves superior performance in almost all benchmark scenarios and performs comparably in others across a diverse range of missing value situations and three real-world datasets. We also evaluate how the performance of our model varies with different amounts of missing values and analyse its performance on downstream tasks. In addition, we provide the original code to replicate the results.",
    "published": "2024-10-08",
    "link": "http://arxiv.org/abs/2410.05916v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Remote Sensing Image Segmentation Using Vision Mamba and Multi-Scale Multi-Frequency Feature Fusion",
    "author": "Yice Cao, Chenchen Liu, Zhenhua Wu, Wenxin Yao, Liu Xiong, Jie Chen, Zhixiang Huang",
    "summary": "As remote sensing imaging technology continues to advance and evolve, processing high-resolution and diversified satellite imagery to improve segmentation accuracy and enhance interpretation efficiency emerg as a pivotal area of investigation within the realm of remote sensing. Although segmentation algorithms based on CNNs and Transformers achieve significant progress in performance, balancing segmentation accuracy and computational complexity remains challenging, limiting their wide application in practical tasks. To address this, this paper introduces state space model (SSM) and proposes a novel hybrid semantic segmentation network based on vision Mamba (CVMH-UNet). This method designs a cross-scanning visual state space block (CVSSBlock) that uses cross 2D scanning (CS2D) to fully capture global information from multiple directions, while by incorporating convolutional neural network branches to overcome the constraints of Vision Mamba (VMamba) in acquiring local information, this approach facilitates a comprehensive analysis of both global and local features. Furthermore, to address the issue of limited discriminative power and the difficulty in achieving detailed fusion with direct skip connections, a multi-frequency multi-scale feature fusion block (MFMSBlock) is designed. This module introduces multi-frequency information through 2D discrete cosine transform (2D DCT) to enhance information utilization and provides additional scale local detail information through point-wise convolution branches. Finally, it aggregates multi-scale information along the channel dimension, achieving refined feature fusion. Findings from experiments conducted on renowned datasets of remote sensing imagery demonstrate that proposed CVMH-UNet achieves superior segmentation performance while maintaining low computational complexity, outperforming surpassing current leading-edge segmentation algorithms.",
    "published": "2024-10-08",
    "link": "http://arxiv.org/abs/2410.05624v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "A Deep Learning-Based Approach for Mangrove Monitoring",
    "author": "Lucas Jos\u00e9 Vel\u00f4so de Souza, Ingrid Valverde Reis Zreik, Adrien Salem-Sermanet, Nac\u00e9ra Seghouani, Lionel Pourchier",
    "summary": "Mangroves are dynamic coastal ecosystems that are crucial to environmental health, economic stability, and climate resilience. The monitoring and preservation of mangroves are of global importance, with remote sensing technologies playing a pivotal role in these efforts. The integration of cutting-edge artificial intelligence with satellite data opens new avenues for ecological monitoring, potentially revolutionizing conservation strategies at a time when the protection of natural resources is more crucial than ever. The objective of this work is to provide a comprehensive evaluation of recent deep-learning models on the task of mangrove segmentation. We first introduce and make available a novel open-source dataset, MagSet-2, incorporating mangrove annotations from the Global Mangrove Watch and satellite images from Sentinel-2, from mangrove positions all over the world. We then benchmark three architectural groups, namely convolutional, transformer, and mamba models, using the created dataset. The experimental outcomes further validate the deep learning community's interest in the Mamba model, which surpasses other architectures in all metrics.",
    "published": "2024-10-07",
    "link": "http://arxiv.org/abs/2410.05443v1",
    "code_url": "https://github.com/svjlucas/mangroveai",
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Falcon Mamba: The First Competitive Attention-free 7B Language Model",
    "author": "Jingwei Zuo, Maksim Velikanov, Dhia Eddine Rhaiem, Ilyas Chahed, Younes Belkada, Guillaume Kunsch, Hakim Hacid",
    "summary": "In this technical report, we present Falcon Mamba 7B, a new base large language model based on the novel Mamba architecture. Falcon Mamba 7B is trained on 5.8 trillion tokens with carefully selected data mixtures. As a pure Mamba-based model, Falcon Mamba 7B surpasses leading open-weight models based on Transformers, such as Mistral 7B, Llama3.1 8B, and Falcon2 11B. It is on par with Gemma 7B and outperforms models with different architecture designs, such as RecurrentGemma 9B and RWKV-v6 Finch 7B/14B. Currently, Falcon Mamba 7B is the best-performing Mamba model in the literature at this scale, surpassing both existing Mamba and hybrid Mamba-Transformer models, according to the Open LLM Leaderboard. Due to its architecture, Falcon Mamba 7B is significantly faster at inference and requires substantially less memory for long sequence generation. Despite recent studies suggesting that hybrid Mamba-Transformer models outperform pure architecture designs, we demonstrate that even the pure Mamba design can achieve similar, or even superior results compared to the Transformer and hybrid designs. We make the weights of our implementation of Falcon Mamba 7B publicly available on https://huggingface.co/tiiuae/falcon-mamba-7b, under a permissive license.",
    "published": "2024-10-07",
    "link": "http://arxiv.org/abs/2410.05355v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "IGroupSS-Mamba: Interval Group Spatial-Spectral Mamba for Hyperspectral Image Classification",
    "author": "Yan He, Bing Tu, Puzhao Jiang, Bo Liu, Jun Li, Antonio Plaza",
    "summary": "Hyperspectral image (HSI) classification has garnered substantial attention in remote sensing fields. Recent Mamba architectures built upon the Selective State Space Models (S6) have demonstrated enormous potential in long-range sequence modeling. However, the high dimensionality of hyperspectral data and information redundancy pose challenges to the application of Mamba in HSI classification, suffering from suboptimal performance and computational efficiency. In light of this, this paper investigates a lightweight Interval Group Spatial-Spectral Mamba framework (IGroupSS-Mamba) for HSI classification, which allows for multi-directional and multi-scale global spatial-spectral information extraction in a grouping and hierarchical manner. Technically, an Interval Group S6 Mechanism (IGSM) is developed as the core component, which partitions high-dimensional features into multiple non-overlapping groups at intervals, and then integrates a unidirectional S6 for each group with a specific scanning direction to achieve non-redundant sequence modeling. Compared to conventional applying multi-directional scanning to all bands, this grouping strategy leverages the complementary strengths of different scanning directions while decreasing computational costs. To adequately capture the spatial-spectral contextual information, an Interval Group Spatial-Spectral Block (IGSSB) is introduced, in which two IGSM-based spatial and spectral operators are cascaded to characterize the global spatial-spectral relationship along the spatial and spectral dimensions, respectively. IGroupSS-Mamba is constructed as a hierarchical structure stacked by multiple IGSSB blocks, integrating a pixel aggregation-based downsampling strategy for multiscale spatial-spectral semantic learning from shallow to deep stages. Extensive experiments demonstrate that IGroupSS-Mamba outperforms the state-of-the-art methods.",
    "published": "2024-10-07",
    "link": "http://arxiv.org/abs/2410.05100v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Fundamental Limitations on Subquadratic Alternatives to Transformers",
    "author": "Josh Alman, Hantao Yu",
    "summary": "The Transformer architecture is widely deployed in many popular and impactful Large Language Models. At its core is the attention mechanism for calculating correlations between pairs of tokens. Performing an attention computation takes quadratic time in the input size, and had become the time bottleneck for transformer operations. In order to circumvent this, researchers have used a variety of approaches, including designing heuristic algorithms for performing attention computations faster, and proposing alternatives to the attention mechanism which can be computed more quickly. For instance, state space models such as Mamba were designed to replace attention with an almost linear time alternative.   In this paper, we prove that any such approach cannot perform important tasks that Transformer is able to perform (assuming a popular conjecture from fine-grained complexity theory). We focus on document similarity tasks, where one is given as input many documents and would like to find a pair which is (approximately) the most similar. We prove that Transformer is able to perform this task, and we prove that this task cannot be performed in truly subquadratic time by any algorithm. Thus, any model which can be evaluated in subquadratic time - whether because of subquadratic-time heuristics for attention, faster attention replacements like Mamba, or any other reason - cannot perform this task. In other words, in order to perform tasks that (implicitly or explicitly) involve document similarity, one may as well use Transformer and cannot avoid its quadratic running time.",
    "published": "2024-10-05",
    "link": "http://arxiv.org/abs/2410.04271v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Mamba Capsule Routing Towards Part-Whole Relational Camouflaged Object Detection",
    "author": "Dingwen Zhang, Liangbo Cheng, Yi Liu, Xinggang Wang, Junwei Han",
    "summary": "The part-whole relational property endowed by Capsule Networks (CapsNets) has been known successful for camouflaged object detection due to its segmentation integrity. However, the previous Expectation Maximization (EM) capsule routing algorithm with heavy computation and large parameters obstructs this trend. The primary attribution behind lies in the pixel-level capsule routing. Alternatively, in this paper, we propose a novel mamba capsule routing at the type level. Specifically, we first extract the implicit latent state in mamba as capsule vectors, which abstract type-level capsules from pixel-level versions. These type-level mamba capsules are fed into the EM routing algorithm to get the high-layer mamba capsules, which greatly reduce the computation and parameters caused by the pixel-level capsule routing for part-whole relationships exploration. On top of that, to retrieve the pixel-level capsule features for further camouflaged prediction, we achieve this on the basis of the low-layer pixel-level capsules with the guidance of the correlations from adjacent-layer type-level mamba capsules. Extensive experiments on three widely used COD benchmark datasets demonstrate that our method significantly outperforms state-of-the-arts. Code has been available on https://github.com/Liangbo-Cheng/mamba\\_capsule.",
    "published": "2024-10-05",
    "link": "http://arxiv.org/abs/2410.03987v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Oscillatory State-Space Models",
    "author": "T. Konstantin Rusch, Daniela Rus",
    "summary": "We propose Linear Oscillatory State-Space models (LinOSS) for efficiently learning on long sequences. Inspired by cortical dynamics of biological neural networks, we base our proposed LinOSS model on a system of forced harmonic oscillators. A stable discretization, integrated over time using fast associative parallel scans, yields the proposed state-space model. We prove that LinOSS produces stable dynamics only requiring nonnegative diagonal state matrix. This is in stark contrast to many previous state-space models relying heavily on restrictive parameterizations. Moreover, we rigorously show that LinOSS is universal, i.e., it can approximate any continuous and causal operator mapping between time-varying functions, to desired accuracy. In addition, we show that an implicit-explicit discretization of LinOSS perfectly conserves the symmetry of time reversibility of the underlying dynamics. Together, these properties enable efficient modeling of long-range interactions, while ensuring stable and accurate long-horizon forecasting. Finally, our empirical results, spanning a wide range of time-series tasks from mid-range to very long-range classification and regression, as well as long-horizon forecasting, demonstrate that our proposed LinOSS model consistently outperforms state-of-the-art sequence models. Notably, LinOSS outperforms Mamba by nearly 2x and LRU by 2.5x on a sequence modeling task with sequences of length 50k.",
    "published": "2024-10-04",
    "link": "http://arxiv.org/abs/2410.03943v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "In-vivo high-resolution \u03c7-separation at 7T",
    "author": "Jiye Kim, Minjun Kim, Sooyeon Ji, Kyeongseon Min, Hwihun Jeong, Hyeong-Geol Shin, Chungseok Oh, Sina Straub, Seong-Gi Kim, Jongho Lee",
    "summary": "A recently introduced quantitative susceptibility mapping (QSM) technique, $\\chi$-separation, offers the capability to separate paramagnetic ($\\chi_{\\text{para}}$) and diamagnetic ($\\chi_{\\text{dia}}$) susceptibility distribution within the brain. In-vivo high-resolution mapping of iron and myelin distribution, estimated by $\\chi$-separation, could provide a deeper understanding of brain substructures, assisting the investigation of their functions and alterations. This can be achieved using 7T MRI, which benefits from a high signal-to-noise ratio and susceptibility effects. However, applying $\\chi$-separation at 7T presents difficulties due to the requirement of an $R_2$ map, coupled with issues such as high specific absorption rate (SAR), large $B_1$ transmit field inhomogeneities, and prolonged scan time.   To address these challenges, we developed a novel deep neural network, R2PRIMEnet7T, designed to convert a 7T $R_2^*$ map into a 3T $R_2'$ map. Building on this development, we present a new pipeline for $\\chi$-separation at 7T, enabling us to generate high-resolution $\\chi$-separation maps from multi-echo gradient-echo data. The proposed method is compared with alternative pipelines, such as an end-to-end network and linearly-scaled $R_2'$, and is validated against $\\chi$-separation maps at 3T, demonstrating its accuracy. The 7T $\\chi$-separation maps generated by the proposed method exhibit similar contrasts to those from 3T, while 7T high-resolution maps offer enhanced clarity and detail. Quantitative analysis confirms that the proposed method surpasses the alternative pipelines. The proposed method results well delineate the detailed brain structures associated with iron and myelin. This new pipeline holds promise for analyzing iron and myelin concentration changes in various neurodegenerative diseases through precise structural examination.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12239v2",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "The Disparate Benefits of Deep Ensembles",
    "author": "Kajetan Schweighofer, Adrian Arnaiz-Rodriguez, Sepp Hochreiter, Nuria Oliver",
    "summary": "Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a simple way to boost predictive performance. However, their impact on algorithmic fairness is not well understood yet. Algorithmic fairness investigates how a model's performance varies across different groups, typically defined by protected attributes such as age, gender, or race. In this work, we investigate the interplay between the performance gains from Deep Ensembles and fairness. Our analysis reveals that they unevenly favor different groups in what we refer to as a disparate benefits effect. We empirically investigate this effect with Deep Ensembles applied to popular facial analysis and medical imaging datasets, where protected group attributes are given and find that it occurs for multiple established group fairness metrics, including statistical parity and equal opportunity. Furthermore, we identify the per-group difference in predictive diversity of ensemble members as the potential cause of the disparate benefits effect. Finally, we evaluate different approaches to reduce unfairness due to the disparate benefits effect. Our findings show that post-processing is an effective method to mitigate this unfairness while preserving the improved performance of Deep Ensembles.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13831v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning",
    "author": "Xiaodan Xing, Junzhi Ning, Yang Nan, Guang Yang",
    "summary": "Deep generative models have significantly advanced medical imaging analysis by enhancing dataset size and quality. Beyond mere data augmentation, our research in this paper highlights an additional, significant capacity of deep generative models: their ability to reveal and demonstrate patterns in medical images. We employ a generative structure with hybrid conditions, combining clinical data and segmentation masks to guide the image synthesis process. Furthermore, we innovatively transformed the tabular clinical data into textual descriptions. This approach simplifies the handling of missing values and also enables us to leverage large pre-trained vision-language models that investigate the relations between independent clinical entries and comprehend general terms, such as gender and smoking status. Our approach differs from and presents a more challenging task than traditional medical report-guided synthesis due to the less visual correlation of our clinical information with the images. To overcome this, we introduce a text-visual embedding mechanism that strengthens the conditions, ensuring the network effectively utilizes the provided information. Our pipeline is generalizable to both GAN-based and diffusion models. Experiments on chest CT, particularly focusing on the smoking status, demonstrated a consistent intensity shift in the lungs which is in agreement with clinical observations, indicating the effectiveness of our method in capturing and visualizing the impact of specific attributes on medical image patterns. Our methods offer a new avenue for the early detection and precise visualization of complex clinical conditions with deep generative models. All codes are https://github.com/junzhin/DGM-VLC.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13823v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Optimizing Probabilistic Conformal Prediction with Vectorized Non-Conformity Scores",
    "author": "Minxing Zheng, Shixiang Zhu",
    "summary": "Generative models have shown significant promise in critical domains such as medical diagnosis, autonomous driving, and climate science, where reliable decision-making hinges on accurate uncertainty quantification. While probabilistic conformal prediction (PCP) offers a powerful framework for this purpose, its coverage efficiency -- the size of the uncertainty set -- is limited when dealing with complex underlying distributions and a finite number of generated samples. In this paper, we propose a novel PCP framework that enhances efficiency by first vectorizing the non-conformity scores with ranked samples and then optimizing the shape of the prediction set by varying the quantiles for samples at the same rank. Our method delivers valid coverage while producing discontinuous and more efficient prediction sets, making it particularly suited for high-stakes applications. We demonstrate the effectiveness of our approach through experiments on both synthetic and real-world datasets.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13735v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "HEALTH-PARIKSHA: Assessing RAG Models for Health Chatbots in Real-World Multilingual Settings",
    "author": "Varun Gumma, Anandhita Raghunath, Mohit Jain, Sunayana Sitaram",
    "summary": "Assessing the capabilities and limitations of large language models (LLMs) has garnered significant interest, yet the evaluation of multiple models in real-world scenarios remains rare. Multilingual evaluation often relies on translated benchmarks, which typically do not capture linguistic and cultural nuances present in the source language. This study provides an extensive assessment of 24 LLMs on real world data collected from Indian patients interacting with a medical chatbot in Indian English and 4 other Indic languages. We employ a uniform Retrieval Augmented Generation framework to generate responses, which are evaluated using both automated techniques and human evaluators on four specific metrics relevant to our application. We find that models vary significantly in their performance and that instruction tuned Indic models do not always perform well on Indic language queries. Further, we empirically show that factual correctness is generally lower for responses to Indic queries compared to English queries. Finally, our qualitative work shows that code-mixed and culturally relevant queries in our dataset pose challenges to evaluated models.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13671v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Multimodal growth and development assessment model",
    "author": "Ying Li, Zichen Song, Zijie Gong, Sitan Huang, Jiewei Ge",
    "summary": "With the development of social economy and the improvement of people's attention to health, the growth and development of children and adolescents has become an important indicator to measure the level of national health. Therefore, accurate and timely assessment of children's growth and development has become increasingly important. At the same time, global health inequalities, especially child malnutrition and stunting in developing countries, urgently require effective assessment tools to monitor and intervene. In recent years, the rapid development of technologies such as big data, artificial intelligence, and cloud computing, and the cross-integration of multiple disciplines such as biomedicine, statistics, and computer science have promoted the rapid development of large-scale models for growth and development assessment. However, there are still problems such as too single evaluation factors, inaccurate diagnostic results, and inability to give accurate and reasonable recommendations. The multi-modal growth and development assessment model uses the public data set of RSNA ( North American College of Radiology ) as the training set, and the data set of the Department of Pediatrics of Huaibei People's Hospital as the open source test set. The embedded ICL module enables the model to quickly adapt and identify the tasks that need to be done to ensure that under the premise of considering multiple evaluation factors, accurate diagnosis results and reasonable medical recommendations are given, so as to provide solutions to the above problems and promote the development of the medical field.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13647v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling",
    "author": "Yakun Zhu, Shaohang Wei, Xu Wang, Kui Xue, Xiaofan Zhang, Shaoting Zhang",
    "summary": "Integrating tools into Large Language Models (LLMs) has facilitated the widespread application. Despite this, in specialized downstream task contexts, reliance solely on tools is insufficient to fully address the complexities of the real world. This particularly restricts the effective deployment of LLMs in fields such as medicine. In this paper, we focus on the downstream tasks of medical calculators, which use standardized tests to assess an individual's health status. We introduce MeNTi, a universal agent architecture for LLMs. MeNTi integrates a specialized medical toolkit and employs meta-tool and nested calling mechanisms to enhance LLM tool utilization. Specifically, it achieves flexible tool selection and nested tool calling to address practical issues faced in intricate medical scenarios, including calculator selection, slot filling, and unit conversion. To assess the capabilities of LLMs for quantitative assessment throughout the clinical process of calculator scenarios, we introduce CalcQA. This benchmark requires LLMs to use medical calculators to perform calculations and assess patient health status. CalcQA is constructed by professional physicians and includes 100 case-calculator pairs, complemented by a toolkit of 281 medical tools. The experimental results demonstrate significant performance improvements with our framework. This research paves new directions for applying LLMs in demanding scenarios of medicine.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13610v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope",
    "author": "Wei Liu, Kerem Delikoyun, Qianyu Chen, Alperen Yildiz, Si Ko Myo, Win Sen Kuan, John Tshon Yit Soong, Matthew Edward Cove, Oliver Hayden, Hweekuan Lee",
    "summary": "Off-axis digital holographic microscopy is a high-throughput, label-free imaging technology that provides three-dimensional, high-resolution information about samples, particularly useful in large-scale cellular imaging. However, the hologram reconstruction process poses a significant bottleneck for timely data analysis. To address this challenge, we propose a novel reconstruction approach that integrates deep learning with the physical principles of off-axis holography. We initialized part of the network weights based on the physical principle and then fine-tuned them via weakly supersized learning. Our off-axis hologram network (OAH-Net) retrieves phase and amplitude images with errors that fall within the measurement error range attributable to hardware, and its reconstruction speed significantly surpasses the microscope's acquisition rate. Crucially, OAH-Net demonstrates remarkable external generalization capabilities on unseen samples with distinct patterns and can be seamlessly integrated with other models for downstream tasks to achieve end-to-end real-time hologram analysis. This capability further expands off-axis holography's applications in both biological and medical studies.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13592v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Three-Input Ciphertext Multiplication for Homomorphic Encryption",
    "author": "Sajjad Akherati, Yok Jye Tang, Xinmiao Zhang",
    "summary": "Homomorphic encryption (HE) allows computations to be directly carried out on ciphertexts and is essential to privacy-preserving computing, such as neural network inference, medical diagnosis, and financial data analysis. Only addition and 2-input multiplication are defined over ciphertexts in popular HE schemes. However, many HE applications involve non-linear functions and they need to be approximated using high-order polynomials to maintain precision. To reduce the complexity of these computations, this paper proposes 3-input ciphertext multiplication. One extra evaluation key is introduced to carry out the relinearization step of ciphertext multiplication, and new formulas are proposed to combine computations and share intermediate results. Compared to using two consecutive 2- input multiplications, computing the product of three ciphertexts utilizing the proposed scheme leads to almost a half of the latency, 29% smaller silicon area, and lower noise without scarifying the throughput.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13545v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?",
    "author": "Che Liu, Zhongwei Wan, Haozhe Wang, Yinda Chen, Talha Qaiser, Chen Jin, Fariba Yousefi, Nikolay Burlutskiy, Rossella Arcucci",
    "summary": "Medical Vision-Language Pre-training (MedVLP) has made significant progress in enabling zero-shot tasks for medical image understanding. However, training MedVLP models typically requires large-scale datasets with paired, high-quality image-text data, which are scarce in the medical domain. Recent advancements in Large Language Models (LLMs) and diffusion models have made it possible to generate large-scale synthetic image-text pairs. This raises the question: *Can MedVLP succeed using purely synthetic data?* To address this, we use off-the-shelf generative models to create synthetic radiology reports and paired Chest X-ray (CXR) images, and propose an automated pipeline to build a diverse, high-quality synthetic dataset, enabling a rigorous study that isolates model and training settings, focusing entirely from the data perspective. Our results show that MedVLP models trained *exclusively on synthetic data* outperform those trained on real data by **3.8%** in averaged AUC on zero-shot classification. Moreover, using a combination of synthetic and real data leads to a further improvement of **9.07%**. Additionally, MedVLP models trained on synthetic or mixed data consistently outperform those trained on real data in zero-shot grounding, as well as in fine-tuned classification and segmentation tasks. Our analysis suggests MedVLP trained on well-designed synthetic data can outperform models trained on real datasets, which may be limited by low-quality samples and long-tailed distributions.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13523v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "SemSim: Revisiting Weak-to-Strong Consistency from a Semantic Similarity Perspective for Semi-supervised Medical Image Segmentation",
    "author": "Shiao Xie, Hongyi Wang, Ziwei Niu, Hao Sun, Shuyi Ouyang, Yen-Wei Chen, Lanfen Lin",
    "summary": "Semi-supervised learning (SSL) for medical image segmentation is a challenging yet highly practical task, which reduces reliance on large-scale labeled dataset by leveraging unlabeled samples. Among SSL techniques, the weak-to-strong consistency framework, popularized by FixMatch, has emerged as a state-of-the-art method in classification tasks. Notably, such a simple pipeline has also shown competitive performance in medical image segmentation. However, two key limitations still persist, impeding its efficient adaptation: (1) the neglect of contextual dependencies results in inconsistent predictions for similar semantic features, leading to incomplete object segmentation; (2) the lack of exploitation of semantic similarity between labeled and unlabeled data induces considerable class-distribution discrepancy. To address these limitations, we propose a novel semi-supervised framework based on FixMatch, named SemSim, powered by two appealing designs from semantic similarity perspective: (1) rectifying pixel-wise prediction by reasoning about the intra-image pair-wise affinity map, thus integrating contextual dependencies explicitly into the final prediction; (2) bridging labeled and unlabeled data via a feature querying mechanism for compact class representation learning, which fully considers cross-image anatomical similarities. As the reliable semantic similarity extraction depends on robust features, we further introduce an effective spatial-aware fusion module (SFM) to explore distinctive information from multiple scales. Extensive experiments show that SemSim yields consistent improvements over the state-of-the-art methods across three public segmentation benchmarks.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13486v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Day-Night Adaptation: An Innovative Source-free Adaptation Framework for Medical Image Segmentation",
    "author": "Ziyang Chen, Yiwen Ye, Yongsheng Pan, Yong Xia",
    "summary": "Distribution shifts widely exist in medical images acquired from different medical centers, hindering the deployment of semantic segmentation models trained on data from one center (source domain) to another (target domain). While unsupervised domain adaptation (UDA) has shown significant promise in mitigating these shifts, it poses privacy risks due to sharing data between centers. To facilitate adaptation while preserving data privacy, source-free domain adaptation (SFDA) and test-time adaptation (TTA) have emerged as effective paradigms, relying solely on target domain data. However, the scenarios currently addressed by SFDA and TTA are limited, making them less suitable for clinical applications. In a more realistic clinical scenario, the pre-trained model is deployed in a medical centre to assist with clinical tasks during the day and rest at night. During the daytime process, TTA can be employed to enhance inference performance. During the nighttime process, after collecting the test data from the day, the model can be fine-tuned utilizing SFDA to further adapt to the target domain. With above insights, we propose a novel adaptation framework called Day-Night Adaptation (DyNA). This framework adapts the model to the target domain through day-night loops without requiring access to source data. Specifically, we implement distinct adaptation strategies for daytime and nighttime to better meet the demands of clinical settings. During the daytime, model parameters are frozen, and a specific low-frequency prompt is trained for each test sample. Additionally, we construct a memory bank for prompt initialization and develop a warm-up mechanism to enhance prompt training. During nighttime, we integrate a global student model into the traditional teacher-student self-training paradigm to fine-tune the model while ensuring training stability...",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13472v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MedINST: Meta Dataset of Biomedical Instructions",
    "author": "Wenhan Han, Meng Fang, Zihan Zhang, Yu Yin, Zirui Song, Ling Chen, Mykola Pechenizkiy, Qingyu Chen",
    "summary": "The integration of large language model (LLM) techniques in the field of medical analysis has brought about significant advancements, yet the scarcity of large, diverse, and well-annotated datasets remains a major challenge. Medical data and tasks, which vary in format, size, and other parameters, require extensive preprocessing and standardization for effective use in training LLMs. To address these challenges, we introduce MedINST, the Meta Dataset of Biomedical Instructions, a novel multi-domain, multi-task instructional meta-dataset. MedINST comprises 133 biomedical NLP tasks and over 7 million training samples, making it the most comprehensive biomedical instruction dataset to date. Using MedINST as the meta dataset, we curate MedINST32, a challenging benchmark with different task difficulties aiming to evaluate LLMs' generalization ability. We fine-tune several LLMs on MedINST and evaluate on MedINST32, showcasing enhanced cross-task generalization.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13458v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Augmentation Policy Generation for Image Classification Using Large Language Models",
    "author": "Ant Duru, Alptekin Temizel",
    "summary": "Automated data augmentation methods have significantly improved the performance and generalization capability of deep learning models in image classification. Yet, most state-of-the-art methods are optimized on common benchmark datasets, limiting their applicability to more diverse or domain-specific data, such as medical datasets. In this paper, we propose a strategy that uses large language models to automatically generate efficient augmentation policies, customized to fit the specific characteristics of any dataset and model architecture. The proposed method iteratively interacts with an LLM to obtain and refine the augmentation policies on model performance feedback, creating a dataset-agnostic data augmentation pipeline. The proposed method was evaluated on medical imaging datasets, showing a clear improvement over state-of-the-art methods. The proposed approach offers an adaptive and scalable solution. Although it increases computational cost, it significantly boosts model robustness, automates the process, and minimizes the need for human involvement during model development.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13453v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Unsupervised Skull Segmentation via Contrastive MR-to-CT Modality Translation",
    "author": "Kamil Kwarciak, Mateusz Daniol, Daria Hemmerling, Marek Wodzinski",
    "summary": "The skull segmentation from CT scans can be seen as an already solved problem. However, in MR this task has a significantly greater complexity due to the presence of soft tissues rather than bones. Capturing the bone structures from MR images of the head, where the main visualization objective is the brain, is very demanding. The attempts that make use of skull stripping seem to not be well suited for this task and fail to work in many cases. On the other hand, supervised approaches require costly and time-consuming skull annotations. To overcome the difficulties we propose a fully unsupervised approach, where we do not perform the segmentation directly on MR images, but we rather perform a synthetic CT data generation via MR-to-CT translation and perform the segmentation there. We address many issues associated with unsupervised skull segmentation including the unpaired nature of MR and CT datasets (contrastive learning), low resolution and poor quality (super-resolution), and generalization capabilities. The research has a significant value for downstream tasks requiring skull segmentation from MR volumes such as craniectomy or surgery planning and can be seen as an important step towards the utilization of synthetic data in medical imaging.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13427v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Statistical testing on generative AI anomaly detection tools in Alzheimer's Disease diagnosis",
    "author": "Rosemary He, Ichiro Takeuchi",
    "summary": "Alzheimer's Disease is challenging to diagnose due to our limited understanding of its mechanism and large heterogeneity among patients. Neurodegeneration is studied widely as a biomarker for clinical diagnosis, which can be measured from time series MRI progression. On the other hand, generative AI has shown promise in anomaly detection in medical imaging and used for tasks including tumor detection. However, testing the reliability of such data-driven methods is non-trivial due to the issue of double-dipping in hypothesis testing. In this work, we propose to solve this issue with selective inference and develop a reliable generative AI method for Alzheimer's prediction. We show that compared to traditional statistical methods with highly inflated p-values, selective inference successfully controls the false discovery rate under the desired alpha level while retaining statistical power. In practice, our pipeline could assist clinicians in Alzheimer's diagnosis and early intervention.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13363v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "On the new and accurate (Goudsmit-Saunderson) model for describing e-/e+ multiple Coulomb scattering (Geant4 Technical Note)",
    "author": "Mihaly Novak",
    "summary": "A new model, for the accurate simulation of multiple Coulomb scattering (MSC) of e-/e+, has been implemented in Geant4 recently and made available with version Geant4-10.4. The model is based on Goudsmit-Saunderson (GS) angular distributions computed by utilising the screen Rutherford (SR) DCS and follows very closely the formulation developed by Kawrakow [1, 2] and utilised in the EGSnrc toolkit [3]. Corrections, for taking into accountenergy loss [2] neglected by the GS theory, spin-relativistic effects [3] not included in the SR but might be accounted on the basis of Mott DCS as well as the so-called scattering power correction [4], i.e. appropriately incorporating deflections due to sub-threshold delta ray productions, are all included similarly to the EGSnrc model [3]. Furthermore, an accurate electron-step algorithm [5, 6, 2] is utilised for path length correction, i.e. for calculating the post-step position in each condensed history simulation steps such that the corresponding single-scattering longitudinal and lateral (post step point) distributions are very well reproduced. An e-/e+ stepping algorithm, including the simulation step-limit due to the MSC and boundary crossing [2]), free from step-size artefacts, makes the model complete. Details on this new model, including all the above-mentioned components and corrections, are provided in this Geant4 technical note.   It must be noted, that a Goudsmit-Saunderson model for MSC was available before Geant4-10.4., documented in [7], that has been completely replaced by the model described in this technical note (keeping only the G4GoudsmitSaundersonMscModel name of the C++ class from that previous version)",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13361v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Representation Learning of Structured Data for Medical Foundation Models",
    "author": "Vijay Prakash Dwivedi, Viktor Schlegel, Andy T. Liu, Thanh-Tung Nguyen, Abhinav Ramesh Kashyap, Jeng Wei, Wei-Hsian Yin, Stefan Winkler, Robby T. Tan",
    "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across various domains, including healthcare. However, their ability to effectively represent structured non-textual data, such as the alphanumeric medical codes used in records like ICD-10 or SNOMED-CT, is limited and has been particularly exposed in recent research. This paper examines the challenges LLMs face in processing medical codes due to the shortcomings of current tokenization methods. As a result, we introduce the UniStruct architecture to design a multimodal medical foundation model of unstructured text and structured data, which addresses these challenges by adapting subword tokenization techniques specifically for the structured medical codes. Our approach is validated through model pre-training on both an extensive internal medical database and a public repository of structured medical records. Trained on over 1 billion tokens on the internal medical database, the proposed model achieves up to a 23% improvement in evaluation metrics, with around 2% gain attributed to our proposed tokenization. Additionally, when evaluated on the EHRSHOT public benchmark with a 1/1000 fraction of the pre-training data, the UniStruct model improves performance on over 42% of the downstream tasks. Our approach not only enhances the representation and generalization capabilities of patient-centric models but also bridges a critical gap in representation learning models' ability to handle complex structured medical data, alongside unstructured text.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13351v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Technical Note: Vendor-Specific Approach for Standardized Uptake Value Calculation",
    "author": "Maksym Fritsak, Hubert S. Gabry\u015b, Preethi Mohan, Matthias Guckenberger, Stephanie Tanadini-Lang",
    "summary": "The Standardized Uptake Value (SUV) is a critical metric in positron emission tomography (PET) imaging, used to assess metabolic activity. However, calculating SUV from DICOM files presents challenges due to vendor-specific DICOM attributes and variations in the encoding of radiotracer accumulation times. This technical note introduces a robust, vendor-specific SUV calculation strategy that addresses inconsistencies in current methodologies. We also integrate this strategy into an open-source software solution, Z-Rad, capable of converting raw PET DICOM data into body-weight normalized SUV NIfTI files.   Our SUV calculation strategy was developed by reviewing DICOM conformance statements from GE, Philips, and Siemens. Validation was conducted using real-world PET datasets, and the proposed strategy was compared to existing software solutions.   Our SUV calculation approach demonstrated improved accuracy, particularly in resolving time-related discrepancies in the studied data. Our analysis also identified inconsistencies in the SUV calculation methods used by popular commercial and open-source software solutions, which do not fully account for vendor-specific DICOM attributes and PET image acquisition times. These limitations resulted in errors in SUV estimation reaching 33\\% when comparing our strategy to studied software.   The proposed vendor-specific SUV calculation strategy significantly enhances accuracy in PET imaging by addressing key inconsistencies caused by variations in DICOM attributes and image acquisition times across different vendors. This method effectively reduces SUV calculation errors and has been integrated into an open-source software, Z-Rad.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13348v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Active inference and deep generative modeling for cognitive ultrasound",
    "author": "Ruud JG van Sloun",
    "summary": "Ultrasound (US) has the unique potential to offer access to medical imaging to anyone, everywhere. Devices have become ultra-portable and cost-effective, akin to the stethoscope. Nevertheless US image quality and diagnostic efficacy are still highly operator- and patient-dependent. In difficult-to-image patients, image quality is often insufficient for reliable diagnosis. In this paper, we put forth that US imaging systems can be recast as information-seeking agents that engage in reciprocal interactions with their anatomical environment. Such agents autonomously adapt their transmit-receive sequences to fully personalize imaging and actively maximize information gain in-situ. To that end, we will show that the sequence of pulse-echo experiments that a US system performs can be interpreted as a perception-action loop: the action is the data acquisition, probing tissue with acoustic waves and recording reflections at the detection array, and perception is the inference of the anatomical and or functional state, potentially including associated diagnostic quantities. We then equip systems with a mechanism to actively reduce uncertainty and maximize diagnostic value across a sequence of experiments, treating action and perception jointly using Bayesian inference given generative models of the environment and action-conditional pulse-echo observations. Since the representation capacity of the generative models dictates both the quality of inferred anatomical states and the effectiveness of inferred sequences of future imaging actions, we will be greatly leveraging the enormous advances in deep generative modelling that are currently disrupting many fields and society at large. Finally, we show some examples of cognitive, closed-loop, US systems that perform active beamsteering and adaptive scanline selection, based on deep generative models that track anatomical belief states.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13310v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling",
    "author": "Ruohan Wang, Zilong Wang, Ziyang Song, David Buckeridge, Yue Li",
    "summary": "Automatic subphenotyping from electronic health records (EHRs)provides numerous opportunities to understand diseases with unique subgroups and enhance personalized medicine for patients. However, existing machine learning algorithms either focus on specific diseases for better interpretability or produce coarse-grained phenotype topics without considering nuanced disease patterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer sub-phenotype topics from thousands of disease using multi-modal EHR data. Specifically, MixEHR-Nest detects multiple subtopics from each phenotype topic, whose prior is guided by the expert-curated phenotype concepts such as Phenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We evaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting of over 38 thousand patients from intensive care unit (ICU) from Beth Israel Deaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare administrative database PopHR, comprising 1.3 million patients from Montreal, Canada. Experimental results demonstrate that MixEHR-Nest can identify subphenotypes with distinct patterns within each phenotype, which are predictive for disease progression and severity. Consequently, MixEHR-Nest distinguishes between type 1 and type 2 diabetes by inferring subphenotypes using CCS codes, which do not differentiate these two subtype concepts. Additionally, MixEHR-Nest not only improved the prediction accuracy of short-term mortality of ICU patients and initial insulin treatment in diabetic patients but also revealed the contributions of subphenotypes. For longitudinal analysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under the same phenotypes, such as asthma, leukemia, epilepsy, and depression. The MixEHR-Nest software is available at GitHub: https://github.com/li-lab-mcgill/MixEHR-Nest.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13217v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback",
    "author": "Zonghai Yao, Aditya Parashar, Huixue Zhou, Won Seok Jang, Feiyun Ouyang, Zhichao Yang, Hong Yu",
    "summary": "Automatic question generation (QG) is essential for AI and NLP, particularly in intelligent tutoring, dialogue systems, and fact verification. Generating multiple-choice questions (MCQG) for professional exams, like the United States Medical Licensing Examination (USMLE), is particularly challenging, requiring domain expertise and complex multi-hop reasoning for high-quality questions. However, current large language models (LLMs) like GPT-4 struggle with professional MCQG due to outdated knowledge, hallucination issues, and prompt sensitivity, resulting in unsatisfactory quality and difficulty. To address these challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique and Correction) framework for converting medical cases into high-quality USMLE-style questions. By integrating expert-driven prompt engineering with iterative self-critique and self-correction feedback, MCQG-SRefine significantly enhances human expert satisfaction regarding both the quality and difficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based automatic metric to replace the complex and costly expert evaluation process, ensuring reliable and expert-aligned assessments.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13191v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Scalable Drift Monitoring in Medical Imaging AI",
    "author": "Jameson Merkow, Felix J. Dorfner, Xiyu Yang, Alexander Ersoy, Giridhar Dasegowda, Mannudeep Kalra, Matthew P. Lungren, Christopher P. Bridge, Ivan Tarapov",
    "summary": "The integration of artificial intelligence (AI) into medical imaging has advanced clinical diagnostics but poses challenges in managing model drift and ensuring long-term reliability. To address these challenges, we develop MMC+, an enhanced framework for scalable drift monitoring, building upon the CheXstray framework that introduced real-time drift detection for medical imaging AI models using multi-modal data concordance. This work extends the original framework's methodologies, providing a more scalable and adaptable solution for real-world healthcare settings and offers a reliable and cost-effective alternative to continuous performance monitoring addressing limitations of both continuous and periodic monitoring methods. MMC+ introduces critical improvements to the original framework, including more robust handling of diverse data streams, improved scalability with the integration of foundation models like MedImageInsight for high-dimensional image embeddings without site-specific training, and the introduction of uncertainty bounds to better capture drift in dynamic clinical environments. Validated with real-world data from Massachusetts General Hospital during the COVID-19 pandemic, MMC+ effectively detects significant data shifts and correlates them with model performance changes. While not directly predicting performance degradation, MMC+ serves as an early warning system, indicating when AI systems may deviate from acceptable performance bounds and enabling timely interventions. By emphasizing the importance of monitoring diverse data streams and evaluating data shifts alongside model performance, this work contributes to the broader adoption and integration of AI solutions in clinical settings.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13174v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Adversarial Neural Networks in Medical Imaging Advancements and Challenges in Semantic Segmentation",
    "author": "Houze Liu, Bo Zhang, Yanlin Xiang, Yuxiang Hu, Aoran Shen, Yang Lin",
    "summary": "Recent advancements in artificial intelligence (AI) have precipitated a paradigm shift in medical imaging, particularly revolutionizing the domain of brain imaging. This paper systematically investigates the integration of deep learning -- a principal branch of AI -- into the semantic segmentation of brain images. Semantic segmentation serves as an indispensable technique for the delineation of discrete anatomical structures and the identification of pathological markers, essential for the diagnosis of complex neurological disorders. Historically, the reliance on manual interpretation by radiologists, while noteworthy for its accuracy, is plagued by inherent subjectivity and inter-observer variability. This limitation becomes more pronounced with the exponential increase in imaging data, which traditional methods struggle to process efficiently and effectively. In response to these challenges, this study introduces the application of adversarial neural networks, a novel AI approach that not only automates but also refines the semantic segmentation process. By leveraging these advanced neural networks, our approach enhances the precision of diagnostic outputs, reducing human error and increasing the throughput of imaging data analysis. The paper provides a detailed discussion on how adversarial neural networks facilitate a more robust, objective, and scalable solution, thereby significantly improving diagnostic accuracies in neurological evaluations. This exploration highlights the transformative impact of AI on medical imaging, setting a new benchmark for future research and clinical practice in neurology.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13099v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models",
    "author": "Peng Xia, Kangyu Zhu, Haoran Li, Tianze Wang, Weijia Shi, Sheng Wang, Linjun Zhang, James Zou, Huaxiu Yao",
    "summary": "Artificial Intelligence (AI) has demonstrated significant potential in healthcare, particularly in disease diagnosis and treatment planning. Recent progress in Medical Large Vision-Language Models (Med-LVLMs) has opened up new possibilities for interactive diagnostic tools. However, these models often suffer from factual hallucination, which can lead to incorrect diagnoses. Fine-tuning and retrieval-augmented generation (RAG) have emerged as methods to address these issues. However, the amount of high-quality data and distribution shifts between training data and deployment data limit the application of fine-tuning methods. Although RAG is lightweight and effective, existing RAG-based approaches are not sufficiently general to different medical domains and can potentially cause misalignment issues, both between modalities and between the model and the ground truth. In this paper, we propose a versatile multimodal RAG system, MMed-RAG, designed to enhance the factuality of Med-LVLMs. Our approach introduces a domain-aware retrieval mechanism, an adaptive retrieved contexts selection method, and a provable RAG-based preference fine-tuning strategy. These innovations make the RAG process sufficiently general and reliable, significantly improving alignment when introducing retrieved contexts. Experimental results across five medical datasets (involving radiology, ophthalmology, pathology) on medical VQA and report generation demonstrate that MMed-RAG can achieve an average improvement of 43.8% in the factual accuracy of Med-LVLMs. Our data and code are available in https://github.com/richard-peng-xia/MMed-RAG.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.13085v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "UniCoN: Universal Conditional Networks for Multi-Age Embryonic Cartilage Segmentation with Sparsely Annotated Data",
    "author": "Nishchal Sapkota, Yejia Zhang, Zihao Zhao, Maria Gomez, Yuhan Hsi, Jordan A. Wilson, Kazuhiko Kawasaki, Greg Holmes, Meng Wu, Ethylin Wang Jabs, Joan T. Richtsmeier, Susan M. Motch Perrine, Danny Z. Chen",
    "summary": "Osteochondrodysplasia, affecting 2-3% of newborns globally, is a group of bone and cartilage disorders that often result in head malformations, contributing to childhood morbidity and reduced quality of life. Current research on this disease using mouse models faces challenges since it involves accurately segmenting the developing cartilage in 3D micro-CT images of embryonic mice. Tackling this segmentation task with deep learning (DL) methods is laborious due to the big burden of manual image annotation, expensive due to the high acquisition costs of 3D micro-CT images, and difficult due to embryonic cartilage's complex and rapidly changing shapes. While DL approaches have been proposed to automate cartilage segmentation, most such models have limited accuracy and generalizability, especially across data from different embryonic age groups. To address these limitations, we propose novel DL methods that can be adopted by any DL architectures -- including CNNs, Transformers, or hybrid models -- which effectively leverage age and spatial information to enhance model performance. Specifically, we propose two new mechanisms, one conditioned on discrete age categories and the other on continuous image crop locations, to enable an accurate representation of cartilage shape changes across ages and local shape details throughout the cranial region. Extensive experiments on multi-age cartilage segmentation datasets show significant and consistent performance improvements when integrating our conditional modules into popular DL segmentation architectures. On average, we achieve a 1.7% Dice score increase with minimal computational overhead and a 7.5% improvement on unseen data. These results highlight the potential of our approach for developing robust, universal models capable of handling diverse datasets with limited annotated data, a key challenge in DL-based medical image analysis.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.13043v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Design and Feasibility of a Community Motorcycle Ambulance System in the Philippines",
    "author": "Aaron Rodriguez, Aidan Chen, Ryan Rodriguez",
    "summary": "This study investigates the potential for motorcycle ambulance (motorlance) deployment in Metro Manila and Iloilo City to improve emergency medical care in high-traffic, underserved regions of the Philippines. VSee, a humanitarian technology company, has organized numerous free clinics in the Philippines and identified a critical need for improved emergency services. Motorlances offer a fast, affordable alternative to traditional ambulances, particularly in congested urban settings and remote rural locations. Pilot programs in Malawi, Thailand, and Iran have demonstrated significant improvements in response times and cost-efficiency with motorlance systems. This study presents a framework for motorlance operation and identifies three potential pilot locations: Mandaluyong, Smokey Mountain, and Iloilo City. Site visits, driver interviews, and user surveys indicate public trust in the motorlance concept and positive reception to potential motorlance deployment. Cost analysis verifies the financial feasibility of motorlance systems. Future work will focus on implementing a physical pilot in Mandaluyong, with the aim of expanding service to similar regions contingent on the Mandaluyong pilot's success.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.13026v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Leveraging LLMs for Translating and Classifying Mental Health Data",
    "author": "Konstantinos Skianis, A. Seza Do\u011fru\u00f6z, John Pavlopoulos",
    "summary": "Large language models (LLMs) are increasingly used in medical fields. In mental health support, the early identification of linguistic markers associated with mental health conditions can provide valuable support to mental health professionals, and reduce long waiting times for patients. Despite the benefits of LLMs for mental health support, there is limited research on their application in mental health systems for languages other than English. Our study addresses this gap by focusing on the detection of depression severity in Greek through user-generated posts which are automatically translated from English. Our results show that GPT3.5-turbo is not very successful in identifying the severity of depression in English, and it has a varying performance in Greek as well. Our study underscores the necessity for further research, especially in languages with less resources. Also, careful implementation is necessary to ensure that LLMs are used effectively in mental health platforms, and human supervision remains crucial to avoid misdiagnosis.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12985v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Gradient Map-Assisted Head and Neck Tumor Segmentation: A Pre-RT to Mid-RT Approach in MRI-Guided Radiotherapy",
    "author": "Jintao Ren, Kim Hochreuter, Mathis Ersted Rasmussen, Jesper Folsted Kallehauge, Stine Sofia Korreman",
    "summary": "Radiation therapy (RT) is a vital part of treatment for head and neck cancer, where accurate segmentation of gross tumor volume (GTV) is essential for effective treatment planning. This study investigates the use of pre-RT tumor regions and local gradient maps to enhance mid-RT tumor segmentation for head and neck cancer in MRI-guided adaptive radiotherapy. By leveraging pre-RT images and their segmentations as prior knowledge, we address the challenge of tumor localization in mid-RT segmentation. A gradient map of the tumor region from the pre-RT image is computed and applied to mid-RT images to improve tumor boundary delineation. Our approach demonstrated improved segmentation accuracy for both primary GTV (GTVp) and nodal GTV (GTVn), though performance was limited by data constraints. The final DSCagg scores from the challenge's test set evaluation were 0.534 for GTVp, 0.867 for GTVn, and a mean score of 0.70. This method shows potential for enhancing segmentation and treatment planning in adaptive radiotherapy. Team: DCPT-Stine's group.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12941v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "UMambaAdj: Advancing GTV Segmentation for Head and Neck Cancer in MRI-Guided RT with UMamba and nnU-Net ResEnc Planner",
    "author": "Jintao Ren, Kim Hochreuter, Jesper Folsted Kallehauge, Stine Sofia Korreman",
    "summary": "Magnetic Resonance Imaging (MRI) plays a crucial role in MRI-guided adaptive radiotherapy for head and neck cancer (HNC) due to its superior soft-tissue contrast. However, accurately segmenting the gross tumor volume (GTV), which includes both the primary tumor (GTVp) and lymph nodes (GTVn), remains challenging. Recently, two deep learning segmentation innovations have shown great promise: UMamba, which effectively captures long-range dependencies, and the nnU-Net Residual Encoder (ResEnc), which enhances feature extraction through multistage residual blocks. In this study, we integrate these strengths into a novel approach, termed 'UMambaAdj'. Our proposed method was evaluated on the HNTS-MRG 2024 challenge test set using pre-RT T2-weighted MRI images, achieving an aggregated Dice Similarity Coefficient (DSCagg) of 0.751 for GTVp and 0.842 for GTVn, with a mean DSCagg of 0.796. This approach demonstrates potential for more precise tumor delineation in MRI-guided adaptive radiotherapy, ultimately improving treatment outcomes for HNC patients. Team: DCPT-Stine's group.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12940v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "DEeR: Deviation Eliminating and Noise Regulating for Privacy-preserving Federated Low-rank Adaptation",
    "author": "Meilu Zhu, Axiu Mao, Jun Liu, Yixuan Yuan",
    "summary": "Integrating low-rank adaptation (LoRA) with federated learning (FL) has received widespread attention recently, aiming to adapt pretrained foundation models (FMs) to downstream medical tasks via privacy-preserving decentralized training. However, owing to the direct combination of LoRA and FL, current methods generally undergo two problems, i.e., aggregation deviation, and differential privacy (DP) noise amplification effect. To address these problems, we propose a novel privacy-preserving federated finetuning framework called \\underline{D}eviation \\underline{E}liminating and Nois\\underline{e} \\underline{R}egulating (DEeR). Specifically, we firstly theoretically prove that the necessary condition to eliminate aggregation deviation is guaranteing the equivalence between LoRA parameters of clients. Based on the theoretical insight, a deviation eliminator is designed to utilize alternating minimization algorithm to iteratively optimize the zero-initialized and non-zero-initialized parameter matrices of LoRA, ensuring that aggregation deviation always be zeros during training. Furthermore, we also conduct an in-depth analysis of the noise amplification effect and find that this problem is mainly caused by the ``linear relationship'' between DP noise and LoRA parameters. To suppress the noise amplification effect, we propose a noise regulator that exploits two regulator factors to decouple relationship between DP and LoRA, thereby achieving robust privacy protection and excellent finetuning performance. Additionally, we perform comprehensive ablated experiments to verify the effectiveness of the deviation eliminator and noise regulator. DEeR shows better performance on public medical datasets in comparison with state-of-the-art approaches. The code is available at https://github.com/CUHK-AIM-Group/DEeR.",
    "published": "2024-10-16",
    "link": "http://arxiv.org/abs/2410.12926v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images",
    "author": "Kejun Ren, Xin Wu, Lianming Xu, Li Wang",
    "summary": "Unmanned aerial vehicle (UAV) remote sensing is widely applied in fields such as emergency response, owing to its advantages of rapid information acquisition and low cost. However, due to the effects of shooting distance and imaging mechanisms, the objects in the images present challenges such as small size, dense distribution, and low inter-class differentiation. To this end, we propose a multimodal remote sensing detection network that employs a quad-directional selective scanning fusion strategy called RemoteDet-Mamba. RemoteDet-Mamba simultaneously facilitates the learning of single-modal local features and the integration of patch-level global features across modalities, enhancing the distinguishability for small objects and utilizing local information to improve discrimination between different classes. Additionally, the use of Mamba's serial processing significantly increases detection speed. Experimental results on the DroneVehicle dataset demonstrate the effectiveness of RemoteDet-Mamba, which achieves superior detection accuracy compared to state-of-the-art methods while maintaining computational efficiency and parameter count.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13532v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone",
    "author": "Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang",
    "summary": "Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability to estimate uncertainty of imputation results. Meanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1)~\\textit{~The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity.} 2)~\\textit{The architecture of denoising modules can not handle the inter-variable and bidirectional dependencies in the time series imputation problem effectively.} To address the first challenge, we integrate the computational efficient state space model, namely Mamba, as the backbone denosing module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for bidirectional modeling and inter-variable relation understanding. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple datasets, different missing scenarios and missing ratios.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13338v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Quamba: A Post-Training Quantization Recipe for Selective State Space Models",
    "author": "Hung-Yueh Chiang, Chi-Chih Chang, Natalia Frumkin, Kai-Chiang Wu, Diana Marculescu",
    "summary": "State Space Models (SSMs) have emerged as an appealing alternative to Transformers for large language models, achieving state-of-the-art accuracy with constant memory complexity which allows for holding longer context lengths than attention-based networks. The superior computational efficiency of SSMs in long sequence modeling positions them favorably over Transformers in many scenarios. However, improving the efficiency of SSMs on request-intensive cloud-serving and resource-limited edge applications is still a formidable task. SSM quantization is a possible solution to this problem, making SSMs more suitable for wide deployment, while still maintaining their accuracy. Quantization is a common technique to reduce the model size and to utilize the low bit-width acceleration features on modern computing units, yet existing quantization techniques are poorly suited for SSMs. Most notably, SSMs have highly sensitive feature maps within the selective scan mechanism (i.e., linear recurrence) and massive outliers in the output activations which are not present in the output of token-mixing in the self-attention modules. To address this issue, we propose a static 8-bit per-tensor SSM quantization method which suppresses the maximum values of the input activations to the selective SSM for finer quantization precision and quantizes the output activations in an outlier-free space with Hadamard transform. Our 8-bit weight-activation quantized Mamba 2.8B SSM benefits from hardware acceleration and achieves a 1.72x lower generation latency on an Nvidia Orin Nano 8G, with only a 0.9% drop in average accuracy on zero-shot tasks. The experiments demonstrate the effectiveness and practical applicability of our approach for deploying SSM-based models of all sizes on both cloud and edge platforms.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13229v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "RecurFormer: Not All Transformer Heads Need Self-Attention",
    "author": "Ruiqing Yan, Linghan Zheng, Xingbo Du, Han Zou, Yufeng Guo, Jianfei Yang",
    "summary": "Transformer-based large language models (LLMs) excel in modeling complex language patterns but face significant computational costs during inference, especially with long inputs due to the attention mechanism's memory overhead. We observe that certain attention heads exhibit a distribution where the attention weights concentrate on tokens near the query token, termed as recency aware, which focuses on local and short-range dependencies. Leveraging this insight, we propose RecurFormer, a novel architecture that replaces these attention heads with linear recurrent neural networks (RNNs), specifically the Mamba architecture. This replacement reduces the cache size without evicting tokens, thus maintaining generation quality. RecurFormer retains the ability to model long-range dependencies through the remaining attention heads and allows for reusing pre-trained Transformer-based LLMs weights with continual training. Experiments demonstrate that RecurFormer matches the original model's performance while significantly enhancing inference efficiency. Our approach provides a practical solution to the computational challenges of Transformer-based LLMs inference, making it highly attractive for tasks involving long inputs.",
    "published": "2024-10-10",
    "link": "http://arxiv.org/abs/2410.12850v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  }
]