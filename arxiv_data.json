[
  {
    "title": "Robust infrared small target detection using self-supervised and a contrario paradigms",
    "author": "Alina Ciocarlan, Sylvie Le H\u00e9garat-Mascle, Sidonie Lefebvre, Arnaud Woiselle",
    "summary": "Detecting small targets in infrared images poses significant challenges in defense applications due to the presence of complex backgrounds and the small size of the targets. Traditional object detection methods often struggle to balance high detection rates with low false alarm rates, especially when dealing with small objects. In this paper, we introduce a novel approach that combines a contrario paradigm with Self-Supervised Learning (SSL) to improve Infrared Small Target Detection (IRSTD). On the one hand, the integration of an a contrario criterion into a YOLO detection head enhances feature map responses for small and unexpected objects while effectively controlling false alarms. On the other hand, we explore SSL techniques to overcome the challenges of limited annotated data, common in IRSTD tasks. Specifically, we benchmark several representative SSL strategies for their effectiveness in improving small object detection performance. Our findings show that instance discrimination methods outperform masked image modeling strategies when applied to YOLO-based small object detection. Moreover, the combination of the a contrario and SSL paradigms leads to significant performance improvements, narrowing the gap with state-of-the-art segmentation methods and even outperforming them in frugal settings. This two-pronged approach offers a robust solution for improving IRSTD performance, particularly under challenging conditions.",
    "published": "2024-10-09",
    "link": "http://arxiv.org/abs/2410.07437v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "Gradient is All You Need: Gradient-Based Attention Fusion for Infrared Small Target Detection",
    "author": "Chen Hu, Yian Huang, Kexuan Li, Luping Zhang, Yiming Zhu, Yufei Peng, Tian Pu, Zhenming Peng",
    "summary": "Infrared small target detection (IRSTD) is widely used in civilian and military applications. However, IRSTD encounters several challenges, including the tendency for small and dim targets to be obscured by complex backgrounds. To address this issue, we propose the Gradient Network (GaNet), which aims to extract and preserve edge and gradient information of small targets. GaNet employs the Gradient Transformer (GradFormer) module, simulating central difference convolutions (CDC) to extract and integrate gradient features with deeper features. Furthermore, we propose a global feature extraction model (GFEM) that offers a comprehensive perspective to prevent the network from focusing solely on details while neglecting the background information. We compare the network with state-of-the-art (SOTA) approaches, and the results demonstrate that our method performs effectively. Our source code is available at https://github.com/greekinRoma/Gradient-Transformer.",
    "published": "2024-09-29",
    "link": "http://arxiv.org/abs/2409.19599v1",
    "code_url": null,
    "category": "ISTD-\"infrared small target\""
  },
  {
    "title": "The Disparate Benefits of Deep Ensembles",
    "author": "Kajetan Schweighofer, Adrian Arnaiz-Rodriguez, Sepp Hochreiter, Nuria Oliver",
    "summary": "Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a simple way to boost predictive performance. However, their impact on algorithmic fairness is not well understood yet. Algorithmic fairness investigates how a model's performance varies across different groups, typically defined by protected attributes such as age, gender, or race. In this work, we investigate the interplay between the performance gains from Deep Ensembles and fairness. Our analysis reveals that they unevenly favor different groups in what we refer to as a disparate benefits effect. We empirically investigate this effect with Deep Ensembles applied to popular facial analysis and medical imaging datasets, where protected group attributes are given and find that it occurs for multiple established group fairness metrics, including statistical parity and equal opportunity. Furthermore, we identify the per-group difference in predictive diversity of ensemble members as the potential cause of the disparate benefits effect. Finally, we evaluate different approaches to reduce unfairness due to the disparate benefits effect. Our findings show that post-processing is an effective method to mitigate this unfairness while preserving the improved performance of Deep Ensembles.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13831v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Deep Generative Models Unveil Patterns in Medical Images Through Vision-Language Conditioning",
    "author": "Xiaodan Xing, Junzhi Ning, Yang Nan, Guang Yang",
    "summary": "Deep generative models have significantly advanced medical imaging analysis by enhancing dataset size and quality. Beyond mere data augmentation, our research in this paper highlights an additional, significant capacity of deep generative models: their ability to reveal and demonstrate patterns in medical images. We employ a generative structure with hybrid conditions, combining clinical data and segmentation masks to guide the image synthesis process. Furthermore, we innovatively transformed the tabular clinical data into textual descriptions. This approach simplifies the handling of missing values and also enables us to leverage large pre-trained vision-language models that investigate the relations between independent clinical entries and comprehend general terms, such as gender and smoking status. Our approach differs from and presents a more challenging task than traditional medical report-guided synthesis due to the less visual correlation of our clinical information with the images. To overcome this, we introduce a text-visual embedding mechanism that strengthens the conditions, ensuring the network effectively utilizes the provided information. Our pipeline is generalizable to both GAN-based and diffusion models. Experiments on chest CT, particularly focusing on the smoking status, demonstrated a consistent intensity shift in the lungs which is in agreement with clinical observations, indicating the effectiveness of our method in capturing and visualizing the impact of specific attributes on medical image patterns. Our methods offer a new avenue for the early detection and precise visualization of complex clinical conditions with deep generative models. All codes are https://github.com/junzhin/DGM-VLC.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13823v1",
    "code_url": "https://github.com/junzhin/dgm-vlc",
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "RemoteDet-Mamba: A Hybrid Mamba-CNN Network for Multi-modal Object Detection in Remote Sensing Images",
    "author": "Kejun Ren, Xin Wu, Lianming Xu, Li Wang",
    "summary": "Unmanned aerial vehicle (UAV) remote sensing is widely applied in fields such as emergency response, owing to its advantages of rapid information acquisition and low cost. However, due to the effects of shooting distance and imaging mechanisms, the objects in the images present challenges such as small size, dense distribution, and low inter-class differentiation. To this end, we propose a multimodal remote sensing detection network that employs a quad-directional selective scanning fusion strategy called RemoteDet-Mamba. RemoteDet-Mamba simultaneously facilitates the learning of single-modal local features and the integration of patch-level global features across modalities, enhancing the distinguishability for small objects and utilizing local information to improve discrimination between different classes. Additionally, the use of Mamba's serial processing significantly increases detection speed. Experimental results on the DroneVehicle dataset demonstrate the effectiveness of RemoteDet-Mamba, which achieves superior detection accuracy compared to state-of-the-art methods while maintaining computational efficiency and parameter count.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13532v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone",
    "author": "Hongfan Gao, Wangmeng Shen, Xiangfei Qiu, Ronghui Xu, Jilin Hu, Bin Yang",
    "summary": "Probabilistic time series imputation has been widely applied in real-world scenarios due to its ability to estimate uncertainty of imputation results. Meanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great success in probabilistic time series imputation tasks with its power to model complex distributions. However, current DDPM-based probabilistic time series imputation methodologies are confronted with two types of challenges: 1)~\\textit{~The backbone modules of the denoising parts are not capable of achieving sequence modeling with low time complexity.} 2)~\\textit{The architecture of denoising modules can not handle the inter-variable and bidirectional dependencies in the time series imputation problem effectively.} To address the first challenge, we integrate the computational efficient state space model, namely Mamba, as the backbone denosing module for DDPMs. To tackle the second challenge, we carefully devise several SSM-based blocks for bidirectional modeling and inter-variable relation understanding. Experimental results demonstrate that our approach can achieve state-of-the-art time series imputation results on multiple datasets, different missing scenarios and missing ratios.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.13338v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Less is More: Selective Reduction of CT Data for Self-Supervised Pre-Training of Deep Learning Models with Contrastive Learning Improves Downstream Classification Performance",
    "author": "Daniel Wolf, Tristan Payer, Catharina Silvia Lisson, Christoph Gerhard Lisson, Meinrad Beer, Michael G\u00f6tz, Timo Ropinski",
    "summary": "Self-supervised pre-training of deep learning models with contrastive learning is a widely used technique in image analysis. Current findings indicate a strong potential for contrastive pre-training on medical images. However, further research is necessary to incorporate the particular characteristics of these images. We hypothesize that the similarity of medical images hinders the success of contrastive learning in the medical imaging domain. To this end, we investigate different strategies based on deep embedding, information theory, and hashing in order to identify and reduce redundancy in medical pre-training datasets. The effect of these different reduction strategies on contrastive learning is evaluated on two pre-training datasets and several downstream classification tasks. In all of our experiments, dataset reduction leads to a considerable performance gain in downstream tasks, e.g., an AUC score improvement from 0.78 to 0.83 for the COVID CT Classification Grand Challenge, 0.97 to 0.98 for the OrganSMNIST Classification Challenge and 0.73 to 0.83 for a brain hemorrhage classification task. Furthermore, pre-training is up to nine times faster due to the dataset reduction. In conclusion, the proposed approach highlights the importance of dataset quality and provides a transferable approach to improve contrastive pre-training for classification downstream tasks on medical images.",
    "published": "2024-10-18",
    "link": "http://arxiv.org/abs/2410.14524v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Ultrasound matrix imaging for transcranial in-vivo localization microscopy",
    "author": "Flavien Bureau, Louise Denis, Antoine Coudert, Mathias Fink, Olivier Couture, Alexandre Aubry",
    "summary": "Transcranial ultrasound imaging is usually limited by skull-induced attenuation and high-order aberrations. By using contrast agents such as microbubbles in combination with ultrafast imaging, not only can the signal-to-noise ratio be improved, but super-resolution images down to the micrometer scale of the brain vessels can be obtained. However, ultrasound localization microscopy (ULM) remains impacted by wave-front distortions that limit the microbubble detection rate and hamper their localization. In this work, we show how matrix imaging, which relies on the prior recording of the reflection matrix, can provide a solution to those fundamental issues. As an experimental proof-of-concept, an in-vivo reconstruction of deep brain microvessels is performed on three anesthetized sheeps. The compensation of wave distortions is shown to drastically enhance the contrast and resolution of ULM. This experimental study thus opens up promising perspectives for a transcranial and non-ionizing observation of human cerebral microvascular pathologies, such as stroke.",
    "published": "2024-10-18",
    "link": "http://arxiv.org/abs/2410.14499v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MambaSCI: Efficient Mamba-UNet for Quad-Bayer Patterned Video Snapshot Compressive Imaging",
    "author": "Zhenghao Pan, Haijin Zeng, Jiezhang Cao, Yongyong Chen, Kai Zhang, Yong Xu",
    "summary": "Color video snapshot compressive imaging (SCI) employs computational imaging techniques to capture multiple sequential video frames in a single Bayer-patterned measurement. With the increasing popularity of quad-Bayer pattern in mainstream smartphone cameras for capturing high-resolution videos, mobile photography has become more accessible to a wider audience. However, existing color video SCI reconstruction algorithms are designed based on the traditional Bayer pattern. When applied to videos captured by quad-Bayer cameras, these algorithms often result in color distortion and ineffective demosaicing, rendering them impractical for primary equipment. To address this challenge, we propose the MambaSCI method, which leverages the Mamba and UNet architectures for efficient reconstruction of quad-Bayer patterned color video SCI. To the best of our knowledge, our work presents the first algorithm for quad-Bayer patterned SCI reconstruction, and also the initial application of the Mamba model to this task. Specifically, we customize Residual-Mamba-Blocks, which residually connect the Spatial-Temporal Mamba (STMamba), Edge-Detail-Reconstruction (EDR) module, and Channel Attention (CA) module. Respectively, STMamba is used to model long-range spatial-temporal dependencies with linear complexity, EDR is for better edge-detail reconstruction, and CA is used to compensate for the missing channel information interaction in Mamba model. Experiments demonstrate that MambaSCI surpasses state-of-the-art methods with lower computational and memory costs. PyTorch style pseudo-code for the core modules is provided in the supplementary materials.",
    "published": "2024-10-18",
    "link": "http://arxiv.org/abs/2410.14214v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Provable Benefits of Complex Parameterizations for Structured State Space Models",
    "author": "Yuval Ran-Milo, Eden Lumbroso, Edo Cohen-Karlik, Raja Giryes, Amir Globerson, Nadav Cohen",
    "summary": "Structured state space models (SSMs), the core engine behind prominent neural networks such as S4 and Mamba, are linear dynamical systems adhering to a specified structure, most notably diagonal. In contrast to typical neural network modules, whose parameterizations are real, SSMs often use complex parameterizations. Theoretically explaining the benefits of complex parameterizations for SSMs is an open problem. The current paper takes a step towards its resolution, by establishing formal gaps between real and complex diagonal SSMs. Firstly, we prove that while a moderate dimension suffices in order for a complex SSM to express all mappings of a real SSM, a much higher dimension is needed for a real SSM to express mappings of a complex SSM. Secondly, we prove that even if the dimension of a real SSM is high enough to express a given mapping, typically, doing so requires the parameters of the real SSM to hold exponentially large values, which cannot be learned in practice. In contrast, a complex SSM can express any given mapping with moderate parameter values. Experiments corroborate our theory, and suggest a potential extension of the theory that accounts for selectivity, a new architectural feature yielding state of the art performance.",
    "published": "2024-10-17",
    "link": "http://arxiv.org/abs/2410.14067v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance",
    "author": "Zhangwei Gao, Zhe Chen, Erfei Cui, Yiming Ren, Weiyun Wang, Jinguo Zhu, Hao Tian, Shenglong Ye, Junjun He, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai, Wenhai Wang",
    "summary": "Multimodal large language models (MLLMs) have demonstrated impressive performance in vision-language tasks across a broad spectrum of domains. However, the large model scale and associated high computational costs pose significant challenges for training and deploying MLLMs on consumer-grade GPUs or edge devices, thereby hindering their widespread application. In this work, we introduce Mini-InternVL, a series of MLLMs with parameters ranging from 1B to 4B, which achieves 90% of the performance with only 5% of the parameters. This significant improvement in efficiency and effectiveness makes our models more accessible and applicable in various real-world scenarios. To further promote the adoption of our models, we develop a unified adaptation framework for Mini-InternVL, which enables our models to transfer and outperform specialized models in downstream tasks, including autonomous driving, medical images, and remote sensing. We believe that our study can provide valuable insights and resources to advance the development of efficient and effective MLLMs. Code is available at https://github.com/OpenGVLab/InternVL.",
    "published": "2024-10-21",
    "link": "http://arxiv.org/abs/2410.16261v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report",
    "author": "Samrajya Thapa, Koushik Howlader, Subhankar Bhattacharjee, Wei le",
    "summary": "In this paper, we introduce a novel Multi-Modal Contrastive Pre-training Framework that synergistically combines X-rays, electrocardiograms (ECGs), and radiology/cardiology reports. Our approach leverages transformers to encode these diverse modalities into a unified representation space, aiming to enhance diagnostic accuracy and facilitate comprehensive patient assessments. We utilize LoRA-Peft to significantly reduce trainable parameters in the LLM and incorporate recent linear attention dropping strategy in the Vision Transformer(ViT) for smoother attention. Furthermore, we provide novel multimodal attention explanations and retrieval for our model. To the best of our knowledge, we are the first to propose an integrated model that combines X-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing contrastive loss, MoRE effectively aligns modality-specific features into a coherent embedding, which supports various downstream tasks such as zero-shot classification and multimodal retrieval. Employing our proposed methodology, we achieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and PtbXl downstream datasets, surpassing existing multimodal approaches. Our proposed framework shows significant improvements in capturing intricate inter-modal relationships and its robustness in medical diagnosis that establishes a framework for future research in multimodal learning in the healthcare sector.",
    "published": "2024-10-21",
    "link": "http://arxiv.org/abs/2410.16239v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "LMHaze: Intensity-aware Image Dehazing with a Large-scale Multi-intensity Real Haze Dataset",
    "author": "Ruikun Zhang, Hao Yang, Yan Yang, Ying Fu, Liyuan Pan",
    "summary": "Image dehazing has drawn a significant attention in recent years. Learning-based methods usually require paired hazy and corresponding ground truth (haze-free) images for training. However, it is difficult to collect real-world image pairs, which prevents developments of existing methods. Although several works partially alleviate this issue by using synthetic datasets or small-scale real datasets. The haze intensity distribution bias and scene homogeneity in existing datasets limit the generalization ability of these methods, particularly when encountering images with previously unseen haze intensities. In this work, we present LMHaze, a large-scale, high-quality real-world dataset. LMHaze comprises paired hazy and haze-free images captured in diverse indoor and outdoor environments, spanning multiple scenarios and haze intensities. It contains over 5K high-resolution image pairs, surpassing the size of the biggest existing real-world dehazing dataset by over 25 times. Meanwhile, to better handle images with different haze intensities, we propose a mixture-of-experts model based on Mamba (MoE-Mamba) for dehazing, which dynamically adjusts the model parameters according to the haze intensity. Moreover, with our proposed dataset, we conduct a new large multimodal model (LMM)-based benchmark study to simulate human perception for evaluating dehazed images. Experiments demonstrate that LMHaze dataset improves the dehazing performance in real scenarios and our dehazing method provides better results compared to state-of-the-art methods.",
    "published": "2024-10-21",
    "link": "http://arxiv.org/abs/2410.16095v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "START: A Generalized State Space Model with Saliency-Driven Token-Aware Transformation",
    "author": "Jintao Guo, Lei Qi, Yinghuan Shi, Yang Gao",
    "summary": "Domain Generalization (DG) aims to enable models to generalize to unseen target domains by learning from multiple source domains. Existing DG methods primarily rely on convolutional neural networks (CNNs), which inherently learn texture biases due to their limited receptive fields, making them prone to overfitting source domains. While some works have introduced transformer-based methods (ViTs) for DG to leverage the global receptive field, these methods incur high computational costs due to the quadratic complexity of self-attention. Recently, advanced state space models (SSMs), represented by Mamba, have shown promising results in supervised learning tasks by achieving linear complexity in sequence length during training and fast RNN-like computation during inference. Inspired by this, we investigate the generalization ability of the Mamba model under domain shifts and find that input-dependent matrices within SSMs could accumulate and amplify domain-specific features, thus hindering model generalization. To address this issue, we propose a novel SSM-based architecture with saliency-based token-aware transformation (namely START), which achieves state-of-the-art (SOTA) performances and offers a competitive alternative to CNNs and ViTs. Our START can selectively perturb and suppress domain-specific features in salient tokens within the input-dependent matrices of SSMs, thus effectively reducing the discrepancy between different domains. Extensive experiments on five benchmarks demonstrate that START outperforms existing SOTA DG methods with efficient linear complexity. Our code is available at https://github.com/lingeringlight/START.",
    "published": "2024-10-21",
    "link": "http://arxiv.org/abs/2410.16020v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Frontiers in Intelligent Colonoscopy",
    "author": "Ge-Peng Ji, Jingyi Liu, Peng Xu, Nick Barnes, Fahad Shahbaz Khan, Salman Khan, Deng-Ping Fan",
    "summary": "Colonoscopy is currently one of the most sensitive screening methods for colorectal cancer. This study investigates the frontiers of intelligent colonoscopy techniques and their prospective implications for multimodal medical applications. With this goal, we begin by assessing the current data-centric and model-centric landscapes through four tasks for colonoscopic scene perception, including classification, detection, segmentation, and vision-language understanding. This assessment enables us to identify domain-specific challenges and reveals that multimodal research in colonoscopy remains open for further exploration. To embrace the coming multimodal era, we establish three foundational initiatives: a large-scale multimodal instruction tuning dataset ColonINST, a colonoscopy-designed multimodal language model ColonGPT, and a multimodal benchmark. To facilitate ongoing monitoring of this rapidly evolving field, we provide a public website for the latest updates: https://github.com/ai4colonoscopy/IntelliScope.",
    "published": "2024-10-22",
    "link": "http://arxiv.org/abs/2410.17241v1",
    "code_url": "https://github.com/ai4colonoscopy/intelliscope",
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Automated Spinal MRI Labelling from Reports Using a Large Language Model",
    "author": "Robin Y. Park, Rhydian Windsor, Amir Jamaludin, Andrew Zisserman",
    "summary": "We propose a general pipeline to automate the extraction of labels from radiology reports using large language models, which we validate on spinal MRI reports. The efficacy of our labelling method is measured on five distinct conditions: spinal cancer, stenosis, spondylolisthesis, cauda equina compression and herniation. Using open-source models, our method equals or surpasses GPT-4 on a held-out set of reports. Furthermore, we show that the extracted labels can be used to train imaging models to classify the identified conditions in the accompanying MR scans. All classifiers trained using automated labels achieve comparable performance to models trained using scans manually annotated by clinicians. Code can be found at https://github.com/robinyjpark/AutoLabelClassifier.",
    "published": "2024-10-22",
    "link": "http://arxiv.org/abs/2410.17235v1",
    "code_url": "https://github.com/robinyjpark/autolabelclassifier",
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "SpikMamba: When SNN meets Mamba in Event-based Human Action Recognition",
    "author": "Jiaqi Chen, Yan Yang, Shizhuo Deng, Da Teng, Liyuan Pan",
    "summary": "Human action recognition (HAR) plays a key role in various applications such as video analysis, surveillance, autonomous driving, robotics, and healthcare. Most HAR algorithms are developed from RGB images, which capture detailed visual information. However, these algorithms raise concerns in privacy-sensitive environments due to the recording of identifiable features. Event cameras offer a promising solution by capturing scene brightness changes sparsely at the pixel level, without capturing full images. Moreover, event cameras have high dynamic ranges that can effectively handle scenarios with complex lighting conditions, such as low light or high contrast environments. However, using event cameras introduces challenges in modeling the spatially sparse and high temporal resolution event data for HAR. To address these issues, we propose the SpikMamba framework, which combines the energy efficiency of spiking neural networks and the long sequence modeling capability of Mamba to efficiently capture global features from spatially sparse and high a temporal resolution event data. Additionally, to improve the locality of modeling, a spiking window-based linear attention mechanism is used. Extensive experiments show that SpikMamba achieves remarkable recognition performance, surpassing the previous state-of-the-art by 1.45%, 7.22%, 0.15%, and 3.92% on the PAF, HARDVS, DVS128, and E-FAction datasets, respectively. The code is available at https://github.com/Typistchen/SpikMamba.",
    "published": "2024-10-22",
    "link": "http://arxiv.org/abs/2410.16746v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Explaining Bayesian Networks in Natural Language using Factor Arguments. Evaluation in the medical domain",
    "author": "Jaime Sevilla, Nikolay Babakov, Ehud Reiter, Alberto Bugarin",
    "summary": "In this paper, we propose a model for building natural language explanations for Bayesian Network Reasoning in terms of factor arguments, which are argumentation graphs of flowing evidence, relating the observed evidence to a target variable we want to learn about. We introduce the notion of factor argument independence to address the outstanding question of defining when arguments should be presented jointly or separately and present an algorithm that, starting from the evidence nodes and a target node, produces a list of all independent factor arguments ordered by their strength. Finally, we implemented a scheme to build natural language explanations of Bayesian Reasoning using this approach. Our proposal has been validated in the medical domain through a human-driven evaluation study where we compare the Bayesian Network Reasoning explanations obtained using factor arguments with an alternative explanation method. Evaluation results indicate that our proposed explanation approach is deemed by users as significantly more useful for understanding Bayesian Network Reasoning than another existing explanation method it is compared to.",
    "published": "2024-10-23",
    "link": "http://arxiv.org/abs/2410.18060v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "AI driven health recommender",
    "author": "K. Vignesh, B. Pranavi, Ch. Sreenidhi",
    "summary": "As AI emerged as highest valued technology, We used that to create a web application that makes a patient work easier .It detects the disease name based on the symptoms given by the patient and recommends medication for respective disease, precautions to take, diet to follow and workouts to do, so the disease can be minimized. The web application is made with clean and Realtime data by using Machine learning as root. We used flask to create a user-friendly platform.",
    "published": "2024-10-23",
    "link": "http://arxiv.org/abs/2410.17991v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "CAMEL-Bench: A Comprehensive Arabic LMM Benchmark",
    "author": "Sara Ghaboura, Ahmed Heakl, Omkar Thawakar, Ali Alharthi, Ines Riahi, Abduljalil Saif, Jorma Laaksonen, Fahad S. Khan, Salman Khan, Rao M. Anwer",
    "summary": "Recent years have witnessed a significant interest in developing large multimodal models (LMMs) capable of performing various visual reasoning and understanding tasks. This has led to the introduction of multiple LMM benchmarks to evaluate LMMs on different tasks. However, most existing LMM evaluation benchmarks are predominantly English-centric. In this work, we develop a comprehensive LMM evaluation benchmark for the Arabic language to represent a large population of over 400 million speakers. The proposed benchmark, named CAMEL-Bench, comprises eight diverse domains and 38 sub-domains including, multi-image understanding, complex visual perception, handwritten document understanding, video understanding, medical imaging, plant diseases, and remote sensing-based land use understanding to evaluate broad scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions that are filtered from a larger pool of samples, where the quality is manually verified by native speakers to ensure reliable model assessment. We conduct evaluations of both closed-source, including GPT-4 series, and open-source LMMs. Our analysis reveals the need for substantial improvement, especially among the best open-source models, with even the closed-source GPT-4o achieving an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.",
    "published": "2024-10-24",
    "link": "http://arxiv.org/abs/2410.18976v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques",
    "author": "David Ortiz-Perez, Manuel Benavent-Lledo, Jose Garcia-Rodriguez, David Tom\u00e1s, M. Flores Vizcaya-Moreno",
    "summary": "Cognitive decline is a natural part of aging, often resulting in reduced cognitive abilities. In some cases, however, this decline is more pronounced, typically due to disorders such as Alzheimer's disease. Early detection of anomalous cognitive decline is crucial, as it can facilitate timely professional intervention. While medical data can help in this detection, it often involves invasive procedures. An alternative approach is to employ non-intrusive techniques such as speech or handwriting analysis, which do not necessarily affect daily activities. This survey reviews the most relevant methodologies that use deep learning techniques to automate the cognitive decline estimation task, including audio, text, and visual processing. We discuss the key features and advantages of each modality and methodology, including state-of-the-art approaches like Transformer architecture and foundation models. In addition, we present works that integrate different modalities to develop multimodal models. We also highlight the most significant datasets and the quantitative results from studies using these resources. From this review, several conclusions emerge. In most cases, the textual modality achieves the best results and is the most relevant for detecting cognitive decline. Moreover, combining various approaches from individual modalities into a multimodal model consistently enhances performance across nearly all scenarios.",
    "published": "2024-10-24",
    "link": "http://arxiv.org/abs/2410.18972v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Taipan: Efficient and Expressive State Space Language Models with Selective Attention",
    "author": "Chien Van Nguyen, Huy Huu Nguyen, Thang M. Pham, Ruiyi Zhang, Hanieh Deilamsalehy, Puneet Mathur, Ryan A. Rossi, Trung Bui, Viet Dac Lai, Franck Dernoncourt, Thien Huu Nguyen",
    "summary": "Efficient long-context language modeling remains a significant challenge in Natural Language Processing (NLP). While Transformers dominate language tasks, they struggle with long sequences due to quadratic computational complexity in training and linearly scaling memory costs during inference. Recent State Space Models (SSMs) such as Mamba offer alternatives with constant memory usage, but they underperform in tasks requiring extensive in-context retrieval. We introduce Taipan, a novel hybrid architecture that combines Mamba-2 with Selective Attention Layers (SALs). These SALs identify tokens requiring long-range interactions, remove less important features, and then augment their representations using the attention module. This approach balances Mamba's efficiency with Transformer-like performance in memory-intensive tasks. By constraining the attention budget, Taipan extends accurate predictions to context lengths of up to 1 million tokens while preserving computational efficiency. Our experiments demonstrate Taipan's superior performance across various scales and tasks, offering a promising solution for efficient long-context language modeling.",
    "published": "2024-10-24",
    "link": "http://arxiv.org/abs/2410.18572v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Deep Learning for Classification of Inflammatory Bowel Disease Activity in Whole Slide Images of Colonic Histopathology",
    "author": "Amit Das, Tanmay Shukla, Naofumi Tomita, Ryland Richards, Laura Vidis, Bing Ren, Saeed Hassanpour",
    "summary": "Grading inflammatory bowel disease (IBD) activity using standardized histopathological scoring systems remains challenging due to resource constraints and inter-observer variability. In this study, we developed a deep learning model to classify activity grades in hematoxylin and eosin-stained whole slide images (WSIs) from patients with IBD, offering a robust approach for general pathologists. We utilized 2,077 WSIs from 636 patients treated at Dartmouth-Hitchcock Medical Center in 2018 and 2019, scanned at 40x magnification (0.25 micron/pixel). Board-certified gastrointestinal pathologists categorized the WSIs into four activity classes: inactive, mildly active, moderately active, and severely active. A transformer-based model was developed and validated using five-fold cross-validation to classify IBD activity. Using HoVerNet, we examined neutrophil distribution across activity grades. Attention maps from our model highlighted areas contributing to its prediction. The model classified IBD activity with weighted averages of 0.871 [95% Confidence Interval (CI): 0.860-0.883] for the area under the curve, 0.695 [95% CI: 0.674-0.715] for precision, 0.697 [95% CI: 0.678-0.716] for recall, and 0.695 [95% CI: 0.674-0.714] for F1-score. Neutrophil distribution was significantly different across activity classes. Qualitative evaluation of attention maps by a gastrointestinal pathologist suggested their potential for improved interpretability. Our model demonstrates robust diagnostic performance and could enhance consistency and efficiency in IBD activity assessment.",
    "published": "2024-10-25",
    "link": "http://arxiv.org/abs/2410.19690v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Electromechanical Dynamics of the Heart: A Study of Cardiac Hysteresis During Physical Stress Test",
    "author": "Sajjad Karimi, Shirin Karimi, Amit J. Shah, Gari D. Clifford, Reza Sameni",
    "summary": "Cardiovascular diseases are best diagnosed using multiple modalities that assess both the heart's electrical and mechanical functions. While effective, imaging techniques like echocardiography and nuclear imaging are costly and not widely accessible. More affordable technologies, such as simultaneous electrocardiography (ECG) and phonocardiography (PCG), may provide valuable insights into electromechanical coupling and could be useful for prescreening in low-resource settings.   Using physical stress test data from the EPHNOGRAM ECG-PCG dataset, collected from 23 healthy male subjects (age: 25.4+/-1.9 yrs), we investigated electromechanical intervals (RR, QT, systolic, and diastolic) and their interactions during exercise, along with hysteresis between cardiac electrical activity and mechanical responses.   Time delay analysis revealed distinct temporal relationships between QT, systolic, and diastolic intervals, with RR as the primary driver. The diastolic interval showed near-synchrony with RR, while QT responded to RR interval changes with an average delay of 10.5s, and the systolic interval responded more slowly, with an average delay of 28.3s. We examined QT-RR, systolic-RR, and diastolic-RR hysteresis, finding narrower loops for diastolic RR and wider loops for systolic RR. Significant correlations (average:0.75) were found between heart rate changes and hysteresis loop areas, suggesting the equivalent circular area diameter as a promising biomarker for cardiac function under exercise stress.   Deep learning models, including Long Short-Term Memory and Convolutional Neural Networks, estimated the QT, systolic, and diastolic intervals from RR data, confirming the nonlinear relationship between RR and other intervals. Findings highlight a significant cardiac memory effect, linking ECG and PCG morphology and timing to heart rate history.",
    "published": "2024-10-25",
    "link": "http://arxiv.org/abs/2410.19667v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Multi-Agent Reinforcement Learning with Selective State-Space Models",
    "author": "Jemma Daniel, Ruan de Kock, Louay Ben Nessir, Sasha Abramowitz, Omayma Mahjoub, Wiem Khlifi, Claude Formanek, Arnu Pretorius",
    "summary": "The Transformer model has demonstrated success across a wide range of domains, including in Multi-Agent Reinforcement Learning (MARL) where the Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field. The Transformer model has demonstrated success across a wide range of domains, including in Multi-Agent Reinforcement Learning (MARL) where the Multi-Agent Transformer (MAT) has emerged as a leading algorithm in the field. However, a significant drawback of Transformer models is their quadratic computational complexity relative to input size, making them computationally expensive when scaling to larger inputs. This limitation restricts MAT's scalability in environments with many agents. Recently, State-Space Models (SSMs) have gained attention due to their computational efficiency, but their application in MARL remains unexplored. In this work, we investigate the use of Mamba, a recent SSM, in MARL and assess whether it can match the performance of MAT while providing significant improvements in efficiency. We introduce a modified version of MAT that incorporates standard and bi-directional Mamba blocks, as well as a novel \"cross-attention\" Mamba block. Extensive testing shows that our Multi-Agent Mamba (MAM) matches the performance of MAT across multiple standard multi-agent environments, while offering superior scalability to larger agent scenarios. This is significant for the MARL community, because it indicates that SSMs could replace Transformers without compromising performance, whilst also supporting more effective scaling to higher numbers of agents. Our project page is available at https://sites.google.com/view/multi-agent-mamba .",
    "published": "2024-10-25",
    "link": "http://arxiv.org/abs/2410.19382v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "MambaCPU: Enhanced Correlation Mining with State Space Models for CPU Performance Prediction",
    "author": "Xiaoman Liu",
    "summary": "CPU performance prediction, which involves forecasting the performance scores of a CPU based on its hardware characteristics during the operation process, is a critical technology for computational system design and resource management. However, this research field currently faces two significant challenges. First, collecting real-world data is challenging due to the wide variety of CPU products on the market and the highly specialized nature of relevant hardware characteristics. Second, existing methods based on hardware simulation models or machine learning exhibit notable shortcomings, such as lengthy simulation test cycles, low prediction accuracy, and the ignoration of characteristic correlations. To bridge these gaps, we first collect, preprocess, and standardize historical data from the 4th Generation Intel Xeon Scalable Processors across multiple benchmark suites to create a new dataset, named PerfCastDB. Subsequently, we design a novel network MambaCPU (MaC) as the baseline for the PerfCastDB dataset. This model leverages the mamba structure to mine the global dependencies and correlations between multiple characteristics. The intra- and inter-group attention mechanisms are subsequently utilized to refine the correlations within and across the characteristic type groups. These techniques enhance the analysis and mining capability of Mac for the complex multivariate correlations. Comparative experiments on the PerfCastDB dataset demonstrate that MaC achieves superior results compared to existing methods, validating its effectiveness. Furthermore, we have open-sourced part of the dataset and the MaC code at \\url{https://github.com/xiaoman-liu/MaC} to facilitate the subsequent research.",
    "published": "2024-10-25",
    "link": "http://arxiv.org/abs/2410.19297v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Belief in the Machine: Investigating Epistemological Blind Spots of Language Models",
    "author": "Mirac Suzgun, Tayfun Gur, Federico Bianchi, Daniel E. Ho, Thomas Icard, Dan Jurafsky, James Zou",
    "summary": "As language models (LMs) become integral to fields like healthcare, law, and journalism, their ability to differentiate between fact, belief, and knowledge is essential for reliable decision-making. Failure to grasp these distinctions can lead to significant consequences in areas such as medical diagnosis, legal judgments, and dissemination of fake news. Despite this, current literature has largely focused on more complex issues such as theory of mind, overlooking more fundamental epistemic challenges. This study systematically evaluates the epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13 tasks. Our results reveal key limitations. First, while LMs achieve 86% accuracy on factual scenarios, their performance drops significantly with false scenarios, particularly in belief-related tasks. Second, LMs struggle with recognizing and affirming personal beliefs, especially when those beliefs contradict factual data, which raises concerns for applications in healthcare and counseling, where engaging with a person's beliefs is critical. Third, we identify a salient bias in how LMs process first-person versus third-person beliefs, performing better on third-person tasks (80.7%) compared to first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the factive nature of knowledge, namely, that knowledge inherently requires truth. Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the deeper reasoning. These findings highlight significant concerns about current LMs' ability to reason about truth, belief, and knowledge while emphasizing the need for advancements in these areas before broad deployment in critical sectors.",
    "published": "2024-10-28",
    "link": "http://arxiv.org/abs/2410.21195v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Extrapolating Prospective Glaucoma Fundus Images through Diffusion Model in Irregular Longitudinal Sequences",
    "author": "Zhihao Zhao, Junjie Yang, Shahrooz Faghihroohi, Yinzheng Zhao, Daniel Zapp, Kai Huang, Nassir Navab, M. Ali Nasseri",
    "summary": "The utilization of longitudinal datasets for glaucoma progression prediction offers a compelling approach to support early therapeutic interventions. Predominant methodologies in this domain have primarily focused on the direct prediction of glaucoma stage labels from longitudinal datasets. However, such methods may not adequately encapsulate the nuanced developmental trajectory of the disease. To enhance the diagnostic acumen of medical practitioners, we propose a novel diffusion-based model to predict prospective images by extrapolating from existing longitudinal fundus images of patients. The methodology delineated in this study distinctively leverages sequences of images as inputs. Subsequently, a time-aligned mask is employed to select a specific year for image generation. During the training phase, the time-aligned mask resolves the issue of irregular temporal intervals in longitudinal image sequence sampling. Additionally, we utilize a strategy of randomly masking a frame in the sequence to establish the ground truth. This methodology aids the network in continuously acquiring knowledge regarding the internal relationships among the sequences throughout the learning phase. Moreover, the introduction of textual labels is instrumental in categorizing images generated within the sequence. The empirical findings from the conducted experiments indicate that our proposed model not only effectively generates longitudinal data but also significantly improves the precision of downstream classification tasks.",
    "published": "2024-10-28",
    "link": "http://arxiv.org/abs/2410.21130v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Exploring contextual modeling with linear complexity for point cloud segmentation",
    "author": "Yong Xien Chng, Xuchong Qiu, Yizeng Han, Yifan Pu, Jiewei Cao, Gao Huang",
    "summary": "Point cloud segmentation is an important topic in 3D understanding that has traditionally has been tackled using either the CNN or Transformer. Recently, Mamba has emerged as a promising alternative, offering efficient long-range contextual modeling capabilities without the quadratic complexity associated with Transformer's attention mechanisms. However, despite Mamba's potential, early efforts have all failed to achieve better performance than the best CNN-based and Transformer-based methods. In this work, we address this challenge by identifying the key components of an effective and efficient point cloud segmentation architecture. Specifically, we show that: 1) Spatial locality and robust contextual understanding are critical for strong performance, and 2) Mamba features linear computational complexity, offering superior data and inference efficiency compared to Transformers, while still being capable of delivering strong contextual understanding. Additionally, we further enhance the standard Mamba specifically for point cloud segmentation by identifying its two key shortcomings. First, the enforced causality in the original Mamba is unsuitable for processing point clouds that have no such dependencies. Second, its unidirectional scanning strategy imposes a directional bias, hampering its ability to capture the full context of unordered point clouds in a single pass. To address these issues, we carefully remove the causal convolutions and introduce a novel Strided Bidirectional SSM to enhance the model's capability to capture spatial relationships. Our efforts culminate in the development of a novel architecture named MEEPO, which effectively integrates the strengths of CNN and Mamba. MEEPO surpasses the previous state-of-the-art method, PTv3, by up to +0.8 mIoU on multiple key benchmark datasets, while being 42.1% faster and 5.53x more memory efficient.",
    "published": "2024-10-28",
    "link": "http://arxiv.org/abs/2410.21211v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "SepMamba: State-space models for speaker separation using Mamba",
    "author": "Thor H\u00f8jhus Avenstrup, Boldizs\u00e1r Elek, Istv\u00e1n L\u00e1szl\u00f3 M\u00e1di, Andr\u00e1s Bence Schin, Morten M\u00f8rup, Bj\u00f8rn Sand Jensen, Kenny Falk\u00e6r Olsen",
    "summary": "Deep learning-based single-channel speaker separation has improved significantly in recent years largely due to the introduction of the transformer-based attention mechanism. However, these improvements come at the expense of intense computational demands, precluding their use in many practical applications. As a computationally efficient alternative with similar modeling capabilities, Mamba was recently introduced. We propose SepMamba, a U-Net-based architecture composed primarily of bidirectional Mamba layers. We find that our approach outperforms similarly-sized prominent models - including transformer-based models - on the WSJ0 2-speaker dataset while enjoying a significant reduction in computational cost, memory usage, and forward pass time. We additionally report strong results for causal variants of SepMamba. Our approach provides a computationally favorable alternative to transformer-based architectures for deep speech separation.",
    "published": "2024-10-28",
    "link": "http://arxiv.org/abs/2410.20997v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "NCA-Morph: Medical Image Registration with Neural Cellular Automata",
    "author": "Amin Ranem, John Kalkhof, Anirban Mukhopadhyay",
    "summary": "Medical image registration is a critical process that aligns various patient scans, facilitating tasks like diagnosis, surgical planning, and tracking. Traditional optimization based methods are slow, prompting the use of Deep Learning (DL) techniques, such as VoxelMorph and Transformer-based strategies, for faster results. However, these DL methods often impose significant resource demands. In response to these challenges, we present NCA-Morph, an innovative approach that seamlessly blends DL with a bio-inspired communication and networking approach, enabled by Neural Cellular Automata (NCAs). NCA-Morph not only harnesses the power of DL for efficient image registration but also builds a network of local communications between cells and respective voxels over time, mimicking the interaction observed in living systems. In our extensive experiments, we subject NCA-Morph to evaluations across three distinct 3D registration tasks, encompassing Brain, Prostate and Hippocampus images from both healthy and diseased patients. The results showcase NCA-Morph's ability to achieve state-of-the-art performance. Notably, NCA-Morph distinguishes itself as a lightweight architecture with significantly fewer parameters; 60% and 99.7% less than VoxelMorph and TransMorph. This characteristic positions NCA-Morph as an ideal solution for resource-constrained medical applications, such as primary care settings and operating rooms.",
    "published": "2024-10-29",
    "link": "http://arxiv.org/abs/2410.22265v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "MAPUNetR: A Hybrid Vision Transformer and U-Net Architecture for Efficient and Interpretable Medical Image Segmentation",
    "author": "Ovais Iqbal Shah, Danish Raza Rizvi, Aqib Nazir Mir",
    "summary": "Medical image segmentation is pivotal in healthcare, enhancing diagnostic accuracy, informing treatment strategies, and tracking disease progression. This process allows clinicians to extract critical information from visual data, enabling personalized patient care. However, developing neural networks for segmentation remains challenging, especially when preserving image resolution, which is essential in detecting subtle details that influence diagnoses. Moreover, the lack of transparency in these deep learning models has slowed their adoption in clinical practice. Efforts in model interpretability are increasingly focused on making these models' decision-making processes more transparent. In this paper, we introduce MAPUNetR, a novel architecture that synergizes the strengths of transformer models with the proven U-Net framework for medical image segmentation. Our model addresses the resolution preservation challenge and incorporates attention maps highlighting segmented regions, increasing accuracy and interpretability. Evaluated on the BraTS 2020 dataset, MAPUNetR achieved a dice score of 0.88 and a dice coefficient of 0.92 on the ISIC 2018 dataset. Our experiments show that the model maintains stable performance and potential as a powerful tool for medical image segmentation in clinical practice.",
    "published": "2024-10-29",
    "link": "http://arxiv.org/abs/2410.22223v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Advancing Efficient Brain Tumor Multi-Class Classification -- New Insights from the Vision Mamba Model in Transfer Learning",
    "author": "Yinyi Lai, Anbo Cao, Yuan Gao, Jiaqi Shang, Zongyu Li, Jia Guo",
    "summary": "Early and accurate diagnosis of brain tumors is crucial for improving patient survival rates. However, the detection and classification of brain tumors are challenging due to their diverse types and complex morphological characteristics. This study investigates the application of pre-trained models for brain tumor classification, with a particular focus on deploying the Mamba model. We fine-tuned several mainstream transfer learning models and applied them to the multi-class classification of brain tumors. By comparing these models to those trained from scratch, we demonstrated the significant advantages of transfer learning, especially in the medical imaging field, where annotated data is often limited. Notably, we introduced the Vision Mamba (Vim), a novel network architecture, and applied it for the first time in brain tumor classification, achieving exceptional classification accuracy. Experimental results indicate that the Vim model achieved 100% classification accuracy on an independent test set, emphasizing its potential for tumor classification tasks. These findings underscore the effectiveness of transfer learning in brain tumor classification and reveal that, compared to existing state-of-the-art models, the Vim model is lightweight, efficient, and highly accurate, offering a new perspective for clinical applications. Furthermore, the framework proposed in this study for brain tumor classification, based on transfer learning and the Vision Mamba model, is broadly applicable to other medical imaging classification problems.",
    "published": "2024-10-29",
    "link": "http://arxiv.org/abs/2410.21872v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "ECMamba: Consolidating Selective State Space Model with Retinex Guidance for Efficient Multiple Exposure Correction",
    "author": "Wei Dong, Han Zhou, Yulun Zhang, Xiaohong Liu, Jun Chen",
    "summary": "Exposure Correction (EC) aims to recover proper exposure conditions for images captured under over-exposure or under-exposure scenarios. While existing deep learning models have shown promising results, few have fully embedded Retinex theory into their architecture, highlighting a gap in current methodologies. Additionally, the balance between high performance and efficiency remains an under-explored problem for exposure correction task. Inspired by Mamba which demonstrates powerful and highly efficient sequence modeling, we introduce a novel framework based on Mamba for Exposure Correction (ECMamba) with dual pathways, each dedicated to the restoration of reflectance and illumination map, respectively. Specifically, we firstly derive the Retinex theory and we train a Retinex estimator capable of mapping inputs into two intermediary spaces, each approximating the target reflectance and illumination map, respectively. This setup facilitates the refined restoration process of the subsequent Exposure Correction Mamba Module (ECMM). Moreover, we develop a novel 2D Selective State-space layer guided by Retinex information (Retinex-SS2D) as the core operator of ECMM. This architecture incorporates an innovative 2D scanning strategy based on deformable feature aggregation, thereby enhancing both efficiency and effectiveness. Extensive experiment results and comprehensive ablation studies demonstrate the outstanding performance and the importance of each component of our proposed ECMamba. Code is available at https://github.com/LowlevelAI/ECMamba.",
    "published": "2024-10-28",
    "link": "http://arxiv.org/abs/2410.21535v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Revisiting MAE pre-training for 3D medical image segmentation",
    "author": "Tassilo Wald, Constantin Ulrich, Stanislav Lukyanenko, Andrei Goncharov, Alberto Paderno, Leander Maerkisch, Paul F. J\u00e4ger, Klaus Maier-Hein",
    "summary": "Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the potential of vast, untapped clinical datasets, for various downstream applications that suffer from the scarcity of labeled data. While SSL has revolutionized fields like natural language processing and computer vision, their adoption in 3D medical image computing has been limited by three key pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D medical image analysis, and insufficient evaluation practices. We address these issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and ii) using a Residual Encoder U-Net architecture within the state-of-the-art nnU-Net framework. iii) A robust development framework, incorporating 5 development and 8 testing brain MRI segmentation datasets, allowed performance-driven design decisions to optimize the simple concept of Masked Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses previous SSL methods but also outperforms the strong nnU-Net baseline by an average of approximately 3 Dice points. Furthermore, our model demonstrates exceptional stability, achieving the highest average rank of 2 out of 7 methods, compared to the second-best method's mean rank of 3.",
    "published": "2024-10-30",
    "link": "http://arxiv.org/abs/2410.23132v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "The Auger-Meitner Radioisotope Microscope: an instrument for characterization of Auger electron multiplicities and energy distributions",
    "author": "Patrick R. Stollenwerk, Stephen H. Southworth, Francesco Granato, Amy Renne, Brahim Mustapha, Kevin G. Bailey, Peter Mueller, Jerry Nolen, Thomas P. O'Connor, Junqi Xie, Linda Young, Matthew R. Dietrich",
    "summary": "We describe a new instrument, the Argonne Auger-Meitner Radioisotope Microscope (ARM), capable of characterizing the Auger-Meitner electron emission of radionuclides, including candidates relevant in nuclear medicine. Our approach relies on event-by-event coincidence ion, electron time-of-flight and spatial readout measurement to determine correlated electron multiplicity and energy distributions of Auger-Meitner decays. We present a proof-of-principle measurement with the ARM using X-ray photoionization of stable krypton beyond the K-edge and identify a bifurcation in the electron multiplicity distribution depending on the emission of K-LX electrons. Extension of the ARM to the characterization of radioactive sources of Auger-Meitner electron emissions is enabled by the combination of two recent developments: (1) cryogenic buffer gas beam technology, which enables well-defined initial conditions, gas-phase, high activity introduction of Auger-Meitner emitters into the detection region, and (2) large-area micro-channel plate detectors with multi-hit detection capabilities, which enables the simultaneous detection of many electrons emitted in a single decay.   The ARM will generate new experimental data on Auger-Meitner multiplicities that can be used to benchmark atomic relaxation and decay models. As the multiplicities are binned by energy, this data will provide insight into the low-energy regime of Auger-Meitner electrons where intensity calculations are most challenging and experimental data is limited. In particular, accurate multiplicity data of the low-energy regime can be used to inform oncological dosimetry models, where electron energies less than 500 eV are known to be effective in damaging DNA and cell membranes.",
    "published": "2024-10-30",
    "link": "http://arxiv.org/abs/2410.23103v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Adaptive Multi Scale Document Binarisation Using Vision Mamba",
    "author": "Mohd. Azfar, Siddhant Bharadwaj, Ashwin Sasikumar",
    "summary": "Enhancing and preserving the readability of document images, particularly historical ones, is crucial for effective document image analysis. Numerous models have been proposed for this task, including convolutional-based, transformer-based, and hybrid convolutional-transformer architectures. While hybrid models address the limitations of purely convolutional or transformer-based methods, they often suffer from issues like quadratic time complexity. In this work, we propose a Mamba-based architecture for document binarisation, which efficiently handles long sequences by scaling linearly and optimizing memory usage. Additionally, we introduce novel modifications to the skip connections by incorporating Difference of Gaussians (DoG) features, inspired by conventional signal processing techniques. These multiscale high-frequency features enable the model to produce high-quality, detailed outputs.",
    "published": "2024-10-30",
    "link": "http://arxiv.org/abs/2410.22811v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "A Large Recurrent Action Model: xLSTM enables Fast Inference for Robotics Tasks",
    "author": "Thomas Schmied, Thomas Adler, Vihang Patil, Maximilian Beck, Korbinian P\u00f6ppel, Johannes Brandstetter, G\u00fcnter Klambauer, Razvan Pascanu, Sepp Hochreiter",
    "summary": "In recent years, there has been a trend in the field of Reinforcement Learning (RL) towards large action models trained offline on large-scale datasets via sequence modeling. Existing models are primarily based on the Transformer architecture, which result in powerful agents. However, due to slow inference times, Transformer-based approaches are impractical for real-time applications, such as robotics. Recently, modern recurrent architectures, such as xLSTM and Mamba, have been proposed that exhibit parallelization benefits during training similar to the Transformer architecture while offering fast inference. In this work, we study the aptitude of these modern recurrent architectures for large action models. Consequently, we propose a Large Recurrent Action Model (LRAM) with an xLSTM at its core that comes with linear-time inference complexity and natural sequence length extrapolation abilities. Experiments on 432 tasks from 6 domains show that LRAM compares favorably to Transformers in terms of performance and speed.",
    "published": "2024-10-29",
    "link": "http://arxiv.org/abs/2410.22391v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Federated Black-Box Adaptation for Semantic Segmentation",
    "author": "Jay N. Paranjape, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel",
    "summary": "Federated Learning (FL) is a form of distributed learning that allows multiple institutions or clients to collaboratively learn a global model to solve a task. This allows the model to utilize the information from every institute while preserving data privacy. However, recent studies show that the promise of protecting the privacy of data is not upheld by existing methods and that it is possible to recreate the training data from the different institutions. This is done by utilizing gradients transferred between the clients and the global server during training or by knowing the model architecture at the client end. In this paper, we propose a federated learning framework for semantic segmentation without knowing the model architecture nor transferring gradients between the client and the server, thus enabling better privacy preservation. We propose BlackFed - a black-box adaptation of neural networks that utilizes zero order optimization (ZOO) to update the client model weights and first order optimization (FOO) to update the server weights. We evaluate our approach on several computer vision and medical imaging datasets to demonstrate its effectiveness. To the best of our knowledge, this work is one of the first works in employing federated learning for segmentation, devoid of gradients or model information exchange. Code: https://github.com/JayParanjape/blackfed/tree/master",
    "published": "2024-10-31",
    "link": "http://arxiv.org/abs/2410.24181v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Impact of normal lung volume choices on radiation pneumonitis risk prediction in locally advanced NSCLC radiotherapy",
    "author": "Alyssa Gadsby, Tian Liu, Robert Samstein, Jiahan Zhang, Yang Lei, Kenneth E. Rosenzweig, Ming Chao",
    "summary": "This study is to evaluate the impact of different normal lung volumes on radiation pneumonitis (RP) prediction in patients with locally advanced non-small-cell-lung-cancer (LA-NSCLC) receiving radiotherapy. Three dosimetric variables (V20, V5, and mean lung dose (MLD)) were calculated using treatment plans from 442 patients with LA-NSCLC enrolled in NRG Oncology RTOG 0617. Three lung volumes were defined based on the treatment plan: total lung excluding gross-tumor-target (TL-GTV), total lung excluding clinical-target-volume (TL-CTV), and total lung excluding planning-target-volume (TL-PTV). Binary classification was used for clinical endpoints: no-RP2 (N = 377) for patients with acute RP grades 0 or 1, and RP2 (N = 65) for patients with acute grades 2 or higher. The impact of lung volume definition on RP prediction was investigated with statistical analyses and two supervised machine learning (ML) models: logistic regression (LR) and random forest (RF). Balanced data was generated for comparison to prediction obtained with the imbalanced data. Areas under curve (AUCs) and the Shapley Additive eXplanations (SHAP) were used to examine ML performance and explain the contribution of each feature to the prediction, respectively. Statistical analyses revealed that V20 and MLD were associated with RP but no difference among different lung volume definitions. Mean AUC values from 10-fold cross validation using imbalanced and balanced datasets were < 0.6 except that RF from the latter dataset yielded AUC values > 0.7. SHAP values indicated that MLD and V20 were the most prominent features in RP prediction. In all assessments, no difference among various volume definitions was found. Different lung volumes showed insignificant impact on RP prediction. Low AUC values suggest limited effectiveness of these dosimetric variables in predicting RP risk and more powerful predictors are needed.",
    "published": "2024-10-31",
    "link": "http://arxiv.org/abs/2410.24120v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Dynamical similarity analysis uniquely captures how computations develop in RNNs",
    "author": "Quentin Guilhot, Jascha Achterberg, Micha\u0142 W\u00f3jcik, Rui Ponte Costa",
    "summary": "Methods for analyzing representations in neural systems are increasingly popular tools in neuroscience and mechanistic interpretability. Measures comparing neural activations across conditions, architectures, and species give scalable ways to understand information transformation within different neural networks. However, recent findings show that some metrics respond to spurious signals, leading to misleading results. Establishing benchmark test cases is thus essential for identifying the most reliable metric and potential improvements. We propose that compositional learning in recurrent neural networks (RNNs) can provide a test case for dynamical representation alignment metrics. Implementing this case allows us to evaluate if metrics can identify representations that develop throughout learning and determine if representations identified by metrics reflect the network's actual computations. Building both attractor and RNN based test cases, we show that the recently proposed Dynamical Similarity Analysis (DSA) is more noise robust and reliably identifies behaviorally relevant representations compared to prior metrics (Procrustes, CKA). We also demonstrate how such test cases can extend beyond metric evaluation to study new architectures. Specifically, testing DSA in modern (Mamba) state space models suggests that these models, unlike RNNs, may not require changes in recurrent dynamics due to their expressive hidden states. Overall, we develop test cases that showcase how DSA's enhanced ability to detect dynamical motifs makes it highly effective for identifying ongoing computations in RNNs and revealing how networks learn tasks.",
    "published": "2024-10-31",
    "link": "http://arxiv.org/abs/2410.24070v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "MLLA-UNet: Mamba-like Linear Attention in an Efficient U-Shape Model for Medical Image Segmentation",
    "author": "Yufeng Jiang, Zongxi Li, Xiangyan Chen, Haoran Xie, Jing Cai",
    "summary": "Recent advancements in medical imaging have resulted in more complex and diverse images, with challenges such as high anatomical variability, blurred tissue boundaries, low organ contrast, and noise. Traditional segmentation methods struggle to address these challenges, making deep learning approaches, particularly U-shaped architectures, increasingly prominent. However, the quadratic complexity of standard self-attention makes Transformers computationally prohibitive for high-resolution images. To address these challenges, we propose MLLA-UNet (Mamba-Like Linear Attention UNet), a novel architecture that achieves linear computational complexity while maintaining high segmentation accuracy through its innovative combination of linear attention and Mamba-inspired adaptive mechanisms, complemented by an efficient symmetric sampling structure for enhanced feature processing. Our architecture effectively preserves essential spatial features while capturing long-range dependencies at reduced computational complexity. Additionally, we introduce a novel sampling strategy for multi-scale feature fusion. Experiments demonstrate that MLLA-UNet achieves state-of-the-art performance on six challenging datasets with 24 different segmentation tasks, including but not limited to FLARE22, AMOS CT, and ACDC, with an average DSC of 88.32%. These results underscore the superiority of MLLA-UNet over existing methods. Our contributions include the novel 2D segmentation architecture and its empirical validation. The code is available via https://github.com/csyfjiang/MLLA-UNet.",
    "published": "2024-10-31",
    "link": "http://arxiv.org/abs/2410.23738v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis",
    "author": "Neel Dey, Benjamin Billot, Hallee E. Wong, Clinton J. Wang, Mengwei Ren, P. Ellen Grant, Adrian V. Dalca, Polina Golland",
    "summary": "Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets. As a result, we set new standards across both multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images.",
    "published": "2024-11-04",
    "link": "http://arxiv.org/abs/2411.02372v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking",
    "author": "Shahab Kavousinejad",
    "summary": "Nanorobots are a promising development in targeted drug delivery and the treatment of neurological disorders, with potential for crossing the blood-brain barrier (BBB). These small devices leverage advancements in nanotechnology and bioengineering for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease. Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer cells through biomarker analysis. This study presents a new reinforcement learning (RL) framework for optimizing nanorobot navigation in complex biological environments, focusing on cancer cell detection by analyzing the concentration gradients of surrounding biomarkers. We utilize a computer simulation model to explore the behavior of nanorobots in a three-dimensional space with cancer cells and biological barriers. The proposed method uses Q-learning to refine movement strategies based on real-time biomarker concentration data, enabling nanorobots to autonomously navigate to cancerous tissues for targeted drug delivery. This research lays the groundwork for future laboratory experiments and clinical applications, with implications for personalized medicine and less invasive cancer treatments. The integration of intelligent nanorobots could revolutionize therapeutic strategies, reducing side effects and enhancing treatment effectiveness for cancer patients. Further research will investigate the practical deployment of these technologies in medical settings, aiming to unlock the full potential of nanorobotics in healthcare.",
    "published": "2024-11-04",
    "link": "http://arxiv.org/abs/2411.02345v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "LE-PDE++: Mamba for accelerating PDEs Simulations",
    "author": "Aoming Liang, Zhaoyang Mu, Qi liu, Ruipeng Li, Mingming Ge, Dixia Fan",
    "summary": "Partial Differential Equations are foundational in modeling science and natural systems such as fluid dynamics and weather forecasting. The Latent Evolution of PDEs method is designed to address the computational intensity of classical and deep learning-based PDE solvers by proposing a scalable and efficient alternative. To enhance the efficiency and accuracy of LE-PDE, we incorporate the Mamba model, an advanced machine learning model known for its predictive efficiency and robustness in handling complex dynamic systems with a progressive learning strategy. The LE-PDE was tested on several benchmark problems. The method demonstrated a marked reduction in computational time compared to traditional solvers and standalone deep learning models while maintaining high accuracy in predicting system behavior over time. Our method doubles the inference speed compared to the LE-PDE while retaining the same level of parameter efficiency, making it well-suited for scenarios requiring long-term predictions.",
    "published": "2024-11-04",
    "link": "http://arxiv.org/abs/2411.01897v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Optical Flow Representation Alignment Mamba Diffusion Model for Medical Video Generation",
    "author": "Zhenbin Wang, Lei Zhang, Lituan Wang, Minjuan Zhu, Zhenwei Zhang",
    "summary": "Medical video generation models are expected to have a profound impact on the healthcare industry, including but not limited to medical education and training, surgical planning, and simulation. Current video diffusion models typically build on image diffusion architecture by incorporating temporal operations (such as 3D convolution and temporal attention). Although this approach is effective, its oversimplification limits spatio-temporal performance and consumes substantial computational resources. To counter this, we propose Medical Simulation Video Generator (MedSora), which incorporates three key elements: i) a video diffusion framework integrates the advantages of attention and Mamba, balancing low computational load with high-quality video generation, ii) an optical flow representation alignment method that implicitly enhances attention to inter-frame pixels, and iii) a video variational autoencoder (VAE) with frequency compensation addresses the information loss of medical features that occurs when transforming pixel space into latent features and then back to pixel frames. Extensive experiments and applications demonstrate that MedSora exhibits superior visual quality in generating medical videos, outperforming the most advanced baseline methods. Further results and code are available at https://wongzbb.github.io/MedSora",
    "published": "2024-11-03",
    "link": "http://arxiv.org/abs/2411.01647v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Using Assurance Cases to Guide Verification and Validation of Research Software",
    "author": "W. Spencer Smith, Jingyi Lin",
    "summary": "Research software engineers can use Assurance Cases (ACs) to guide Verification and Validation (VnV) efforts. An AC is a structured argument that a property like correctness holds. We illustrate how ACs can guide VnV activities via a case study of software for automatically extracting the 3D segmentation of the aorta from medical images of the chest. The AC argument suggests that the following evidence is required: comparison to a pseudo-oracle; traceability between requirements, design, code and tests; review of all artifacts by a domain expert with proper credentials; documentation of input assumptions; and a warning that only qualified people should use the software. The case study highlights that code is not the only artifact of interest for building confidence and that making an explicit distinction between software and user responsibilities is useful.",
    "published": "2024-11-05",
    "link": "http://arxiv.org/abs/2411.03291v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Inward-Outward Ring Permanent Magnet Array for Portable Magnetic Resonance Imaging (MRI)",
    "author": "Ting-Ou Liang, MinXuan Xu, Wenwei Yu, Shao Ying Huang",
    "summary": "Permanent magnet array (PMA) is a popular option to provide the main magnetic field in a dedicated portable magnetic resonance imaging (MRI) system because it does not need power or a cooling system and has a much stronger field strength compared to a resistive magnet. Aside from the popular Halbach array that has a transversal field direction, the Inward-Outward ring (IO ring) array is a promising candidate that offers a longitudinal field direction. In this article, a thorough study of IO ring arrays is conducted by examining the relation between the design parameters and its field patterns, its variants that lead to different applications and their properties. A detailed comparison between an IO ring array and Halbach array was conducted and reported. Moreover, the feasibility of building an IO ring array in a lab is demonstrated. The investigations strongly indicate that IO ring is a promising candidate that can offer high and homogeneous fields or a desired field pattern to portable MRI systems. With a longitudinal field direction, an IO ring array opens up opportunities to adopt MRI advanced technology and techniques in a portable system to improve image quality ans shorten scan time.",
    "published": "2024-11-05",
    "link": "http://arxiv.org/abs/2411.03249v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "ShadowMamba: State-Space Model with Boundary-Region Selective Scan for Shadow Removal",
    "author": "Xiujin Zhu, Chee-Onn Chow, Joon Huang Chuah",
    "summary": "Image shadow removal is a typical low-level vision problem, where the presence of shadows leads to abrupt changes in brightness in certain regions, affecting the accuracy of upstream tasks. Current shadow removal methods still face challenges such as residual boundary artifacts, and capturing feature information at shadow boundaries is crucial for removing shadows and eliminating residual boundary artifacts. Recently, Mamba has achieved remarkable success in computer vision by globally modeling long-sequence information with linear complexity. However, when applied to image shadow removal, the original Mamba scanning method overlooks the semantic continuity of shadow boundaries as well as the continuity of semantics within the same region. Based on the unique characteristics of shadow images, this paper proposes a novel selective scanning method called boundary-region selective scanning. This method scans boundary regions, shadow regions, and non-shadow regions independently, bringing pixels of the same region type closer together in the long sequence, especially focusing on the local information at the boundaries, which is crucial for shadow removal. This method combines with global scanning and channel scanning to jointly accomplish the shadow removal. We name our model ShadowMamba, the first Mamba-based model for shadow removal. Extensive experimental results show that our method outperforms current state-of-the-art models across most metrics on multiple datasets. The code for ShadowMamba is available at (Code will be released upon acceptance).",
    "published": "2024-11-05",
    "link": "http://arxiv.org/abs/2411.03260v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "A Mamba Foundation Model for Time Series Forecasting",
    "author": "Haoyu Ma, Yushu Chen, Wenlai Zhao, Jinzhe Yang, Yingsheng Ji, Xinghua Xu, Xiaozhu Liu, Hao Jing, Shengzhuo Liu, Guangwen Yang",
    "summary": "Time series foundation models have demonstrated strong performance in zero-shot learning, making them well-suited for predicting rapidly evolving patterns in real-world applications where relevant training data are scarce. However, most of these models rely on the Transformer architecture, which incurs quadratic complexity as input length increases. To address this, we introduce TSMamba, a linear-complexity foundation model for time series forecasting built on the Mamba architecture. The model captures temporal dependencies through both forward and backward Mamba encoders, achieving high prediction accuracy. To reduce reliance on large datasets and lower training costs, TSMamba employs a two-stage transfer learning process that leverages pretrained Mamba LLMs, allowing effective time series modeling with a moderate training set. In the first stage, the forward and backward backbones are optimized via patch-wise autoregressive prediction; in the second stage, the model trains a prediction head and refines other components for long-term forecasting. While the backbone assumes channel independence to manage varying channel numbers across datasets, a channel-wise compressed attention module is introduced to capture cross-channel dependencies during fine-tuning on specific multivariate datasets. Experiments show that TSMamba's zero-shot performance is comparable to state-of-the-art time series foundation models, despite using significantly less training data. It also achieves competitive or superior full-shot performance compared to task-specific prediction models. The code will be made publicly available.",
    "published": "2024-11-05",
    "link": "http://arxiv.org/abs/2411.02941v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "Investigation of Inward-Outward Ring Permanent Magnet Array for Portable Magnetic Resonance Imaging (MRI)",
    "author": "Ting-Ou Liang, MinXuan Xu, Wenwei Yu, Shao Ying Huang",
    "summary": "Permanent magnet array (PMA) is a popular option to provide the main magnetic field in a dedicated portable magnetic resonance imaging (MRI) system because it does not need power or a cooling system and has a much stronger field strength compared to a resistive magnet. Aside from the popular Halbach array that has a transversal field direction, the Inward-Outward ring (IO ring) array is a promising candidate that offers a longitudinal field direction with various design and engineering possibilities. In this article, a thorough study of IO ring arrays is conducted by examining the relation between the design parameters and its field patterns, its variants that lead to different applications and their properties. A detailed comparison between an IO ring array and Halbach array was conducted and reported. Moreover, the feasibility of building an IO ring array in a lab is demonstrated. The investigations strongly indicate that IO ring is a promising candidate that can offer high and homogeneous fields or a desired field pattern to portable MRI systems. With a longitudinal field direction, an IO ring array opens up opportunities to adopt MRI advanced technology and techniques in a portable system to improve image quality and shorten scan time.",
    "published": "2024-11-05",
    "link": "http://arxiv.org/abs/2411.03249v2",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?",
    "author": "Daniel P. Jeong, Saurabh Garg, Zachary C. Lipton, Michael Oberst",
    "summary": "Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions. In this paper, we compare seven public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting regime for medical question-answering (QA) tasks. For instance, across the tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 12.1% of cases, reach a (statistical) tie in 49.8% of cases, and are significantly worse than their base models in the remaining 38.2% of cases. Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately; and (iii) accounting for statistical uncertainty in comparisons. While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.",
    "published": "2024-11-06",
    "link": "http://arxiv.org/abs/2411.04118v1",
    "code_url": null,
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models",
    "author": "Maya Varma, Jean-Benoit Delbrouck, Zhihong Chen, Akshay Chaudhari, Curtis Langlotz",
    "summary": "Fine-tuned vision-language models (VLMs) often capture spurious correlations between image features and textual attributes, resulting in degraded zero-shot performance at test time. Existing approaches for addressing spurious correlations (i) primarily operate at the global image-level rather than intervening directly on fine-grained image features and (ii) are predominantly designed for unimodal settings. In this work, we present RaVL, which takes a fine-grained perspective on VLM robustness by discovering and mitigating spurious correlations using local image features rather than operating at the global image level. Given a fine-tuned VLM, RaVL first discovers spurious correlations by leveraging a region-level clustering approach to identify precise image features contributing to zero-shot classification errors. Then, RaVL mitigates the identified spurious correlation with a novel region-aware loss function that enables the VLM to focus on relevant regions and ignore spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with various model architectures, data domains, and learned spurious correlations. Our results show that RaVL accurately discovers (191% improvement over the closest baseline) and mitigates (8.2% improvement on worst-group image classification accuracy) spurious correlations. Qualitative evaluations on general-domain and medical-domain VLMs confirm our findings.",
    "published": "2024-11-06",
    "link": "http://arxiv.org/abs/2411.04097v1",
    "code_url": "https://github.com/stanford-aimi/ravl",
    "category": "segmentation-medical OR seg"
  },
  {
    "title": "Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks",
    "author": "Ryan Campbell, Nelson Lojo, Kesava Viswanadha, Christoffer Grondal Tryggestad, Derrick Han Sun, Sriteja Vijapurapu, August Rolfsen, Anant Sahai",
    "summary": "In-Context Learning (ICL) is a phenomenon where task learning occurs through a prompt sequence without the necessity of parameter updates. ICL in Multi-Headed Attention (MHA) with absolute positional embedding has been the focus of more study than other sequence model varieties. We examine implications of architectural differences between GPT-2 and LLaMa as well as LlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al. (2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the interplay between sequence transformation blocks and regressive performance in-context. We note that certain architectural changes cause degraded training efficiency/ICL accuracy by converging to suboptimal predictors or converging slower. We also find certain hybrids showing optimistic performance improvements, informing potential future ICL-focused architecture modifications. Additionally, we propose the \"ICL regression score\", a scalar metric describing a model's whole performance on a specific task. Compute limitations impose restrictions on our architecture-space, training duration, number of training runs, function class complexity, and benchmark complexity. To foster reproducible and extensible research, we provide a typed, modular, and extensible Python package on which we run all experiments.",
    "published": "2024-11-06",
    "link": "http://arxiv.org/abs/2411.03945v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  },
  {
    "title": "MambaPEFT: Exploring Parameter-Efficient Fine-Tuning for Mamba",
    "author": "Masakazu Yoshimura, Teruaki Hayashi, Yota Maeda",
    "summary": "An ecosystem of Transformer-based models has been established by building large models with extensive data. Parameter-efficient fine-tuning (PEFT) is a crucial technology for deploying these models to downstream tasks with minimal cost while achieving effective performance. Recently, Mamba, a State Space Model (SSM)-based model, has attracted attention as a potential alternative to Transformers. While many large-scale Mamba-based models have been proposed, efficiently adapting pre-trained Mamba-based models to downstream tasks remains unexplored. In this paper, we conduct an exploratory analysis of PEFT methods for Mamba. We investigate the effectiveness of existing PEFT methods for Transformers when applied to Mamba. We also modify these methods to better align with the Mamba architecture. Additionally, we propose new Mamba-specific PEFT methods that leverage the distinctive structure of Mamba. Our experiments indicate that PEFT performs more effectively for Mamba than Transformers. Lastly, we demonstrate how to effectively combine multiple PEFT methods and provide a framework that outperforms previous works. To ensure reproducibility, we will release the code after publication.",
    "published": "2024-11-06",
    "link": "http://arxiv.org/abs/2411.03855v1",
    "code_url": null,
    "category": "mamba-mamba OR seg"
  }
]